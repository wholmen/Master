\documentclass[twoside,english]{uiofysmaster}

\bibliography{references}
\usepackage{simplewick}
\usepackage{float}

% Adding nicer font to listings
\usepackage{ifxetex}
\ifxetex
  \usepackage{fontspec}
  \newfontfamily\listingsfontfamily[Scale=0.85]{Droid Sans Mono}
  \renewcommand{\listingsfont}{\listingsfontfamily}
\fi

\setlength{\parskip}{1em}

\author{Fredrik Wilhelm Holmen}
\title{A Study of Coupled-Cluster Methods for infinite matter}
\date{Autumn 2015}

\begin{document}
% set space around equations
\setlength{\belowdisplayskip}{12pt} \setlength{\belowdisplayshortskip}{12pt}
\setlength{\abovedisplayskip}{12pt} \setlength{\abovedisplayshortskip}{12pt}


\maketitle

\begin{abstract}
	In this thesis, we present the formalism of many-body methods, with an emphasis on the Coupled Cluster method with double excitations. The methods are tested on three physical systems, the pairing model, the infinite electron gas and the infinite nuclear matter to reproduce satisfactory results given in literature.  
\end{abstract}

\begin{acknowledgements}
	The work I have done in this thesis could never been done without the help of Morten Hjorth-Jensen, my advisor. You have taught me everyting I have used in this thesis, through your many great courses and personal interactions. I want to thank you for the amazing work you have done for the group Computational Physics and for the way you inspire everyone you meet. The material I present in this thesis are built heavily upon the work of others. A special thank you to Audun Skau Hansen. My work is influenced by your great thesis. 

	I would like to thank Henrik Sveinsson for being a great inspiration and a good friend. You taught me the value of hard work and high ambitions. It was you who sparked my interest in physics at Oslo katedralskole when I followed your path in natural sciences. I would also like to thank Bj\o rnar Pettersen and Marit Ingebrigtsen, two of my teachers at Oslo katedralskole. 

	The last five years have been an amazing experience. I have learned way more than I thought was possible, I have met great people and been given opportunities by the institute to develop my skills as a tutor. Much of the positive experience is owed to the community at Lillefy, the home of Fysikkforeningen and Fysisk Fagutvalg, where I have emptied countless cups of coffee. Vetle Wegner Ingeberg, Henrik Limseth, Torgeir Mo, Sigve Smedsrud Harang, Anders Lauvland have been my best friends for the last five years. You have selflessly shared your knowledge, good humour and beers. 

	I am thankful for my time at Computational Physics, a splendid master group, filled with brilliant and caring people. You have created a relaxed atmosphere, where interesting discussions and competitive card games light up the day. A special thank you to Marte Julie Sætra, Jonas van den Brink, Sean Bruce Miller and Emilie Fj\o rner for sharing my office and giving me loads of help. 

	Thank you My Tien Diep for always keeping my motivation high and reducing my nerdy obsessions to a tolerable level.

\end{acknowledgements}


\tableofcontents


\begin{chapter}{Introduction}
	This thesis is aiming to utilize many-body methods for computing the ground state energy for three different systems. The Pairing model, the homogeneous electron gas and the infinite nuclear matter. Well-performing many-body methods are very computationally costly, and a brute force implementation of configuration interaction, perturbation theory and coupled-cluster doubles theory is only a viable option for small systems. The thesis investigates how one can implement a more efficient solver for the coupled-cluster doubles equations to gain an understanding of large systems. 

	\begin{subsection}{Motivation}
		The Pairing model is an interesting model to solve, not because of it's direct representation of real matter, but because it lives in a small and finite Hilbert space. This allows us compute the exact ground state energy with full configuration interaction. The result is an important tool for comparing the performance of different solvers. Because it is a small and confined system, it is easy to calculate matrix elements by hand, leading to an exact solution for perturbation theory and coupled-cluster doubles results are known. The system is therefore exceptionally good at benchmarking the implementation of many-body methods. 

		Moving on to the homogeneous electron gas, we present an infinite system of electrons interacting with each other and a background charge. By only taking care of electron-electron interaction, we generate a system that can be dealt with using common tools of many-body quantum mechanics. This is one of the first systems to be evaluated by many-body methods, and the litterature present rich data for comparing results from my solver. 

		The main goal of nuclear physics, is to understand the fundamental physics of the nucleus, it's constituents and their interaction. We can generate experimental data on ground state energies, and by applying the known many-body quantum mechanics, we hope to reproduce these results and gain larger insights into the life of nuclear matter. By ahieving  results, it means the nucleus can be described by the shell model, with a set of occupied and unoccupied single-particle states and an interaction between particles. In quantum chemistry, an important goal is to compute precise energies for the nucleus. The problem with these systems is that they present various complications at the borders. By creating an infinite system of nuclear particles, we remove all borders and unknown finite-size effects, and we are left with a study of the interaction between particles. The search for the optimal effective interaction between nuclear matter is important, and hopefully, a study of infinite nuclear matter can give valuable insight search. 
	\end{subsection}

	\begin{subsection}{Goals for the Work}
		I have worked systematically to achieve goals set up by the introduction to the thesis. The main goals of this thesis can be summarized in a few points: 
		\begin{itemize}
			\item A first goal for the thesis has been to present the theory behind four many-body methods. Starting with fundamental many-body quantum mechanics and second quantization before deriving the equations for configuration interaction, Hartree-Fock theory, Reileigh-Schr\"{o}dinger perturbation theory and coupled-cluster doubles. 
			\item The second goal was to implement the Pairing model and the four solvers, coded in c++. The implementations could compute the ground state correlation energy to compare the efficiency of different solvers. The Pairing model could also serve as valuable benchmarking for the solvers.
			\item Next, I needed to present and implement the homogeneous electron gas system and the infinite nuclear matter system. Only the coupled-cluster doubles equations would be used to compute correlation energies for these systems. 
			\item The original, brute force, coupled-cluster solver is too slow to compute correlation energies for large basis sets. I needed to look at how matrix-matrix multiplication and symmetries of the system could be exploited to reduce the computational costs. Presenting and implementing a much more advanced and efficient coupled-cluster doubles code has been the hardest and most time-consuming part of the thesis. 
			\item Finally, the last goal has been to produce results for very large basis sets, needing a parallelized code to run on the local computational cluster, called Smaug. 
		\end{itemize}
	\end{subsection}

	\begin{subsection}{Structure}
		The first part of the thesis is purely a theoretical part, going through the formalism needed to develop many-body methods. My own contributions are presenented in the chapter on implementation, and in the developed code, open to everyone at gibhub.com \cite{WholmenGithub}.

		Chapter 2 gives a short introduction to quantum mechanics, with a main focus on presenting the many-body wave function, the many-body Hamiltonian and the calculations of matrix elements. 

		Chapter 3 presents the formalism \textit{second quantization}. A powerful formalism that simplifies notation by rewriting states as operators. Wick's theorem gives a powerful tool to perform fast computations of matrix elements. This chapter will also aim to formulate the main goal of post-Hartree Fock methods, the calculation of the \textit{correlation energy}. 

		Chapter 4 gives a brief introduction to the use of Feynman diagrams to represent states, operators and contractions.

		Chapter 5 presents a brief introduction to three many-body methods; first the full configuration interaction, then the perturbation theory and Hartree-Fock theory. 

		Chapter 6 gives a deeper introduction to coupled-cluster method and sets up the equations for coupled-cluster with double excitations. 

		Chapter 7 presents the Pairing model, first introducing the Hamiltonian and basis states. The chapter focuses on how I implemented Full Configuration Interaction, Hartree-Fock calculations and many-body perturbation theory to calculate the ground state energy. 

		Chapter 8 presents two different systems; the homogeneous electron gas and infinite nuclear matter with the Minnesota potential. 

		Chapter 9 gives a thourough explanation of the various computational elements of the coupled-cluster solver. First explaining the general concepts of the direct implementation, before delving into more advanced implementations exploiting symmetries and efficiency of matrix multiplication. 

		Chapter 10 contains all results produced for both the Pairing model, homogeneous electron gas and infinite nuclear matter, while chapter 11 summarizes the thesis with a conclusion. 
	\end{subsection}
\end{chapter}



\begin{chapter}{Quantum Mechanics}
 	
	\begin{section}{Postulates}
 		Quantum mechanics is built upon a few principles \cite{Audun,Griffiths,Sakurai,Susskind2014}, often called the postulates of quantum mechanics. 
 		\begin{enumerate}
 			\item \textbf{The Wave Function} \\
 			All information on a quantum system is given by the wave function $\Psi(x,t) $. The wave function represents the probability of measuring a particle within a small volume $\text{dx}$ and for a given time, $t$. As the probability cannot exceed $1$, the wave function must be normalized, namely
 			\begin{align}
 				\int_{-\infty}^\infty \Psi^*(x,t) \Psi(x,t) \text{dx} = 1
 			\end{align}
 			Using Dirac notation, we write the wave function as
 			\begin{align}
 				\left| \Psi \right>
 			\end{align}
 			Physical distinguishable states are orthogonal to each other. Using normalized states, they are orthonormal to each other, meaning that for two unambigously distuingishable states, we have
 			\begin{align}
 				\left< \lambda | \psi \right> = \delta_{\lambda \psi}
 			\end{align}
 			\item \textbf{Observables}\\
			All observables are represented by linear operators, written with a "hat", $\hat O$. These linear operators are bound to be hermitian. An observable could also be called measurable quality. The outcome of a quantum mechanical experiment is an observable. 
			\item \textbf{Measurements}\\
			The possible outcomes of an experminent are the eigenvalues of an operator that represents the observable, represented as a number $\lambda$. If a state is in the eigenstate $\left| \lambda \right>$, the only possible measurement of an experiment is the eigenvalue, $\lambda$. We write this as
 			\begin{align}
 				\hat O \left| \lambda \right> = \lambda \left| \lambda \right>
 			\end{align}
 			\item \textbf{Probabilities}\\
 			Given a state $\left| \alpha \right>$. The probability of observing $\lambda$ when measuring the observable $\hat O$ is given by 
 			\begin{align}
 				P(\lambda) = \left< \alpha | \lambda \right> \left< \lambda | \alpha \right> = | \left< \alpha | \lambda \right> |^2 
 			\end{align}
 			Which measures the overlap of the two states $\left| \alpha \right>$ and $\left| \lambda \right>$. If they are physically distinguishable, the probability is zero. If the probability is non-zero, we have "mixed states".
 			\item \textbf{Time development and the Schr\"{o}dinger equation}\\
 			Time developement for states are given by acting on the state with a unitary operator
 			\begin{align}
 				\left| \Psi(t) \right> = \hat U(t) \left| \Psi(0) \right>
 			\end{align}
 			This leads us to the time-independent Schr\"{o}dinger equation
 			\begin{align}
 				\hat H \left| \Psi(x,t) \right> = i \hbar \frac{\partial}{\partial t} \left| \Psi(x,t) \right> 
 			\end{align}
 			Where we have defined the Hamiltonian operator $\hat H$. The Hamiltonian will be used throughout the thesis, as its eigenvalues are the measurable energy. We will primarily focus on solving the \textit{time independent} Schr\"{o}dinger equation
 			\begin{align}
 				\hat H \left| \Psi(x) \right> = E \left| \Psi(x) \right> 
 			\end{align} 
 		\end{enumerate}
 	\end{section}

 	\begin{section}{The Many-Body Wave Function}
 		A single particle, in isolation, occupy the single particle wave function \cite{Audun,Crawford}
 		\begin{align}
 			\phi_i(\mathbf{x}_1)
 		\end{align}
 		Single particle wave functions are described by the small letter $\phi$, holding all relevant quantum numbers. The vector $\mathbf{x}_1$ holds information on translational position as well as spin for particle $1$. When aiming to describe a system consisting of many such particles, it is tempting to think of the many-body wave function as a function of each particle's wave function 
 		\begin{align}
 			\Phi = \Phi( \phi_1(\mathbf{x}_1), \phi_2(\mathbf{x}_2), ..., \phi_N(\mathbf{x}_N) )
 		\end{align}
 		Where we will use the large letters $\Psi$ and $\Phi$ as the many-body wave functions. This wave function will be sought in the combined Hilbert space of the single particle functions \cite{MHJSlides}
 		\begin{align}
 			\Phi \in \mathcal{H} = \mathcal{H}_1 \oplus \mathcal{H}_2 \oplus ... \oplus \mathcal{H}_N
 		\end{align}
 		Where $\mathcal{H}_i$ represent the Hilbert space for particle $i$. This combined space is referred to as the Fock space \cite{MHJSlides}. A first guess for the wave function can be the \textit{Hatree-product} of single particle functions \cite{Audun,ShavittAndBartlett,Szabo} 
 		\begin{align}
 			\Phi_h = \phi_1(\mathbf{x}_1), \phi_2(\mathbf{x}_2), ..., \phi_N(\mathbf{x}_N) = \prod_{i=1}^N \phi_i(\mathbf{x}_i)
 		\end{align}

 	\end{section}

 	\begin{section}{Pauli's Exclusion Principle}
 		Pauli's exclusion principle, also called the antisymmetry principle or the symmetrization requirement \cite{Szabo,Griffiths}, is quite often included as one of the underlying postulates of quantum mechanics. Guessing that the two-body wave function is on the form of a Hatree-product
 		\begin{align}
 			\Psi(\mathbf{x}_1,\mathbf{x}_2) = \phi_1({\mathbf{x}_1}) \phi_b(\mathbf{x}_2)
 		\end{align}
 		We are claiming that the two particles are distuinguishable, i.e. that electron $1$ occupy state $\phi_1$ and electron $2$ occupy $\phi_2$. All particles, however, are completely identical, with no way of separating them from each other \cite{Griffiths}. Therefore, one must require a different form on the wave function, one that does not commit the particles to specific wave functions. Introducing a general wave function
 		\begin{align}
 			\Psi(\mathbf{x}_1,\mathbf{x}_2) = A[\psi_1(\mathbf{x}_1) \psi_2(\mathbf{x}_2) \pm \mathbf{x}_2) \psi_2(\mathbf{x}_1)]
 		\end{align}
 		With $A$ given as a normalization factor. We notice the choice of sign. Particles with spin integers, named bosons, will require the use of the positive sign, and the wave function will therefore remain unchanged through the interchange of particles. Particles with spin half-integers, will require the use of a negative sign. All particles used in calculations in this thesis are fermions, namely electrons, neutrons or protons. We can introduce the specific antisymmetrization requirement for this thesis as
 		\begin{align}
 			\Psi(\mathbf{x}_1,\mathbf{x}_2) = -\Psi(\mathbf{x}_2,\mathbf{x}_1)
 		\end{align}
 		An exchange of particles can be represented through the use of a pertubation operator $\hat P$, which gives 
 		\begin{align}
 			\hat P \Psi(\mathbf{x}_1,\mathbf{x}_2) = \Psi(\mathbf{x}_2,\mathbf{x}_1)
 		\end{align}
 	\end{section}

	\begin{section}{Slater Determinant}
		The antisymmetrized wave function grows rapidly for every added particle, and we need to introduce a more convenient notation, called the Slater Determinant. Written in terms of the perturbation operator \cite{Audun}
		\begin{align}
			\Phi_{SD} = \frac{1}{\sqrt{N!}} \sum_\lambda^{N!} \hat P_\lambda (-1)^{n(\lambda)} \Phi_h		 	
		\end{align} 
		Where the perturbation operator $\hat P_{\lambda}$, performes every perturbation possible, and introducing a factor $-1$ every time a perturbation is performed. Introducing the anti-symmetry operator $\mathcal{A}$, we can write the shorthand equation
		\begin{align}
			\Phi_{SD} = \sqrt{N!}\mathcal{A}\Phi_h
			\label{equation:SlaterDeterminant}
		\end{align}
		Where we have defined $\mathcal{A}$ as \cite{MHJSlides}
		\begin{align}
			\mathcal{A} = \frac{1}{N!} \sum_\lambda (-1)^\lambda \hat P
		\end{align}
		This operator holds important properties, like commuting with the Hamiltonian operator
		\begin{align}
			\left[\hat H, \mathcal{A}\right] = 0
		\end{align}
		and 
		\begin{align}
			\mathcal{A}^2 = \mathcal{A}, \:\:\:\:\:\:\:\: \mathcal{A} = \mathcal{A}^\dagger
			\label{equation:OperatorA}
		\end{align}
		A more intuitive representation of the Slater determinant is on the matrix form 
		\begin{align}
			\Phi_{SD} = \frac{1}{ \sqrt{N!} } \left|\begin{matrix}
				\phi_1(\mathbf{x}_1) & \phi_2(\mathbf{x}_1) & \cdots & \phi_N(\mathbf{x}_1) \\
				\phi_1(\mathbf{x}_2) & \phi_2(\mathbf{x}_2) & \cdots & \phi_N(\mathbf{x}_2) \\
				\vdots & \vdots & \ddots & \vdots \\
				\phi_1(\mathbf{x}_N) & \phi_2(\mathbf{x}_N) & \cdots & \phi_N(\mathbf{x}_N) 
			\end{matrix} \right|
		\end{align}
		This way of writing the many-body wave function will represent linear a combination of products of the one-body wave functions $\phi_i$'s and all the electronic coordinates $\mathbf{x}_i$ distributed among them in all possible ways. Exchanging two lines will change the sign such that the Slater Determinant will respect the antisymmetric requirement. Introducing a convenient shorthand expression using Dirac-notation, consisting only of the diagonal elements, we can write the Slater determinant as \cite{Crawford}
		\begin{align}
			\left| \Phi \right > = \left| \phi_1(\mathbf{x}_1) \phi_2(\mathbf{x}_2) ... \phi_N({\mathbf{x}_N}) \right>  
		\end{align}
		Which will be the preferred representation of a Slater determinant until Second quantization is introduced. 
	\end{section}

	\begin{section}{An ansatz for the Wave Function}
		The true wave function, represented by
		\begin{align}
			\Psi
		\end{align}
		is rarely known. On the contrary, one of the goals of many-body quantum mechanics is to find an expression for $\Psi $. To find $\Psi$, one can introduce the Slater Determinant as a approximation to the wave function 
		\begin{align}
			\Psi \approx \Phi_{SD}
		\end{align}
		made up of a set of known single particle wave functions $\phi_i$. Choosing a set of single particle functions that lies close to the true state, will provide good results. Calculations will be made easier by using single particle states that are eigenstates of the one-body Hamiltonian operator. One could, for example, choose the hydrogen orbitals as single particle functions when calculating on electrons around an atom. We name $\Phi_{SD}$ the ansatz for the true wave function. 
	\end{section}

 	\begin{section}{The Hamiltonian}
 		The Hamiltonian operator represents the total energy for the system, namely the kinetic energy and the potential energy
 		\begin{align}
 			\hat H = \hat T + \hat V
 		\end{align}
 		Where we can write the kinetic energy as \cite{MHJSlides}
 		\begin{align}
 			\hat T = \sum_{i=1}^N \frac{ \mathbf{p}_i^2}{2m_i} \sum_{i=1}^N \left( \frac{\hbar^2}{2m_i} \nabla_i^2 \right) = \sum_{i=1} t(x_i)
 		\end{align}
 		And a general potential operator can be written as
 		\begin{align}
 			\hat V = \sum_{i=1}^N \hat u_{ext}(x_i) + \sum_{ji = 1}^N v(x_i,x_j) + \sum_{ijk=1}^N v(x_i,x_j,x_k) + \cdots 
 		\end{align}
 		Where we have included the possibility of more than two-body interactions. When doing quantum chemistry, it is common to \textit{freeze} the core. This is called the Born-Oppenheimer Approximation, and simplifies the potential a lot. We now need to look at electrons interacting with a positive core through the Coulombic interaction. The Coulombic potential is a two-body potential, and including the interaction between every electron, we can rewrite the Hamiltonian as
 		\begin{align}
 			\hat H = \sum_{i=1}^{N_e} t(x_i) - \sum_{i=1}^{N_e} k \frac{Z}{r_i} + \sum_{i<j}^{N_e} \frac{k}{r_{ij}}
 		\end{align}
 		Where $N_e$ is the number of electrons and $k = 1.44$eVnm. It is useful to group the one- and two-body parts together
 		\begin{align}
 			\hat H = \hat H_0 + \hat H_1
 		\end{align}
 		Where we have the one-electron energy
 		\begin{align}
 			\hat H_0 = \sum_{i=1}^{N_e} t(x_i) - \sum_{i=1}^{N_e} k \frac{Z}{r_i}
 		\end{align}
 		and the interaction term
 		\begin{align}
 			\hat H_1 = \sum_{i<j}^{N_e} \frac{k}{r_{ij}}
 		\end{align}
 		It is very useful to have an ansatz for the wave function that satisfies the relation
 		\begin{align}
 			\hat H_0 \left| \phi_\lambda \right> = \epsilon_\lambda \left| \phi_\lambda \right>
 		\end{align}
 		In this thesis, I have only included a two-body interaction for my potentials, simplifing the calculations on nuclear matter by using easier potentials. 
 	\end{section}

	\begin{section}{Matrix Elements}
		A Slater determinant will have an energy, given by the Hamiltonian operator
		\begin{align}
			\hat H \left| \Phi_{SD} \right> = \epsilon_{SD} \left| \Phi \right>
		\end{align}
		We aim to calculate the energy, and to do that, we need to introduce the concept of expectation values. By taking the Hermitian conjugate of a wave function, one finds the \textit{bra} version of the state. The original state is known as a $ket$ state. 
		\begin{align}
			\left( \left| \Phi_{SD} \right> \right)^\dagger = \left( \Phi_{SD}^* \right)^T = \left< \Phi_{SD} \right| 
		\end{align}
		The expectation value is defined as taking the inner product of two states, where one is worked on by an operator
		\begin{align}
			\int_{-\infty}^\infty \Phi_{SD}^\dagger \hat H \Phi_{SD} d \tau = \epsilon_{SD}
		\end{align}
		Because of the orthonormality of the states, this calculation will result in the energy. In terms of Dirac notation, this is usually referred to as \textit{multiplying from the left by a bra state}
		\begin{align}
			\left< \Phi_{SD} | \hat H | \Phi_{SD} \right> = \epsilon_{SD}
		\end{align}
		By splitting the Hamiltonian into the one-body and two-body part
		\begin{align}
			\hat H = \hat H_0 + \hat H_1 = \sum_i \hat h_0(x_i) + \sum_{i<j} \hat v(i,j)
		\end{align}
		We can rephrase the expectation value as a one-body calculation and a two-body calculation. 
		\begin{align}
			\left< \Phi_{SD} \right| \hat H \left| \Phi_{SD} \right> = \left< \Phi_{SD} \right| \hat H_0 \left| \Phi_{SD} \right> + \left< \Phi_{SD} \right| \hat H_1 \left| \Phi_{SD} \right>
		\end{align}
		Written out, this gives 
		\begin{align}
			\left< \Phi_{SD} \right| \sum_i \hat h_0(x_i) \left| \Phi_{SD} \right> + \left< \Phi_{SD} \right| \sum_{i<j} \hat v \left| \Phi_{SD} \right>
		\end{align}
		We will commonly refer to these elements as \textit{matrix elements}.

		\begin{subsection}{Calculation of matrix elements}
			Looking at the one-body matrix element, we use equations (\ref{equation:SlaterDeterminant},\ref{equation:OperatorA})
			\begin{align}
				\left< \Phi_{SD} \right| \hat h_0(x_i) \left| \Phi_{SD} \right> = N! \left< \Phi_h \right| \hat h_0(x_i) \mathcal{A} \left| \Phi_h \right> 
			\end{align}
			Which written out on the integral form gives
			\begin{align}
				\sum_i N! \int \Phi_h^* \hat h_0(x_i) \mathcal{A} \Phi_h d\tau 
			\end{align}
			Substituting out the Hatree-product and $\mathcal{A}$ for the perturbation operator, we are left with
			\begin{align}
				\sum_i \sum_\lambda (-1)^\lambda \int d\tau \left( \prod_j \phi_j(x_j)^* \right) \hat h_0(x_i) \hat P_\lambda \left( \prod_k \phi_k(x_k) \right)
			\end{align}
			Because of the orthogonality of the single particle states, we can deduce that any perturbation of particles on one Hartree-product, will set up an inner product of different particles and give zero as a result. We can therefore reduce the calculation to a single sum of unperturbed inner products. 
			\begin{align}
				\sum_i \ \int d\tau \left( \prod_j \phi_j(x_j)^* \right) \hat h_0(x_i) \left( \prod_k \phi_k(x_k) \right) 
			\end{align}
			Since the operator $\hat h_0(x_i)$ only works on $\phi_i(x_i)$, we can split the sum into two parts. Looking at the equation for particle i.
			\begin{align}
				\left< \phi_i \right| \hat h_0 \left| \phi_i \right> \cdot  \left( \prod_{j \neq i} \int d\tau \left| \phi_j(x_j) \right|^2 \right)
			\end{align}
			Which, using the orthonormality relations, become
			\begin{align}
				\left< \phi_i \right| \hat h_0 \left| \phi_i \right> \cdot 1
			\end{align}
			And we can write the one-body matrix elements as
			\begin{align}
				E_0 = \sum_i \left< \phi_i \right| \hat h_0 \left| \phi_i \right>
			\end{align}
			By using single particle wave functions that are eigenstates for the one-body Hamiltonian operator, we get the simple result
			\begin{align}
				\left< \right. \hat H_0 \left. \right> = E_0 = \sum_i \epsilon_i 
			\end{align}

			Applying the same logic for the two-body part
			\begin{align}
				\left< \Phi_{SD} \right| \hat H_1 \left| \Phi_{SD} \right>
			\end{align}
			We want to calculate 
			\begin{align}
				N! \left< \Phi_h \right| \sum_{i<j} \hat v_{ij} \mathcal{A} \left| \Phi_h \right> = N! \sum_{i<j} \int \Phi_h^* \hat v(x_i,x_j) \mathcal{A} \Phi_h d\tau
			\end{align}
			Written in terms of the perturbation operator
			\begin{align}
				\sum_{i<j} \sum_\sigma (-1)^\sigma \int \Phi_h^* v(x_1,x_2) \hat P \Phi_h d\tau
			\end{align}
			The two-body interaction will allow for a single perturbation, because it is dependent on the distance between the two particles. Every other particle must be unperturbed. We can rewrite the equation by this single perturbation as
			\begin{align} 
				\sum_{i<j} \int \Phi_h^* v(x_i,x_j) (1 - P_{ij}) \Phi_h d\tau
			\end{align}
			Where $P_{ij}$ means the interchange of the two particles $i$ and $j$. By the same argument as for the one-particle operator, most states vanish due to orthonormality, and we are left with the terms that take part in the interaction, giving
			\begin{align}
				\frac{1}{2} \sum_\mu \sum_\nu & \left[ \int \phi_\mu^*(x_i) \phi_\nu^*(x_j) \hat v(x_i,x_j) \phi_\mu(x_i) \phi_\nu(x_j) d x_i d x_j \right.  \\     -& \left. \int \phi_\mu^*(x_i) \phi_\nu^*(x_j) \hat v(x_i,x_j) \phi_\nu(x_i) \phi_\mu(x_j) d x_i d x_j \right]
			\end{align}
			Where we have introduced the factor $\frac{1}{2}$ because the sum now counts all states twice. The first term is known as the direct term, and the second term is known as the \textit{exchange term} or the \textit{Fock} term and it incorporates the Pauli principle. We need to introduce an easier notation to present this matrix element
			\begin{align}
				\left< \mu \nu | v | \mu \nu \right> = \int \phi_\mu^*(x_i) \phi_\nu^*(x_j) \hat v(x_i,x_j) \phi_\mu(x_i) \phi_\nu(x_j) d x_i d x_j
			\end{align}
			and 
			\begin{align}
				\left< \mu \nu | v | \nu \mu \right> = \int \phi_\mu^*(x_i) \phi_\nu^*(x_j) \hat v(x_i,x_j) \phi_\nu(x_i) \phi_\mu(x_j) d x_i d x_j
			\end{align}
			And finally, we write it on an anti-symmetric form
			\begin{align}
				\left< \mu \nu | v | \mu \nu \right>_{AS} = \left< \mu \nu | v | \mu \nu \right> - \left< \mu \nu | v | \nu \mu \right> 
			\end{align}
			Meaning that we can write the expectation value of the interaction as a sum of alle the anti-symmetric matrix elements
			\begin{align}
				\left< \Phi_{SD} \right| \hat H_1 \left| \Phi_{SD} \right> = E_{\text{interaction}} = \frac{1}{2} \sum_{\mu \nu} \left< \mu \nu | v | \mu \nu \right>_{AS}
 			\end{align}
		\end{subsection}
	\end{section}

	\newpage

	\begin{section}{The Variational Principle}
		The variational principle is a very powerful principle, useful when doing many-body quantum theory. It states that, if you have a system with the true many-body wave function $\left| \Psi \right>$ and the exact energy
		\begin{align}
			\left< \Psi \right| \hat H \left| \Psi \right> = \epsilon_0
		\end{align}
		Then, any approximate wave function will produce a larger energy \cite{Szabo}
		\begin{align}
			\left< \Phi \right| \hat H \left| \Phi \right> \leq \epsilon_0
		\end{align}
		So we can search for the wave function providing the lowest possible energy.
	\end{section}

\end{chapter}



\begin{chapter}{Second Quantization}
 	Second quantization is a new method of representing states and operators. 
	\begin{section}{Annihilation and Creation operators}
		We introduce a new way of writing states using the mathematical technique known as second quantization. The main goal is to treat states without paying attention
		to individual particle coordinates. We represent the empty space with the symbol for vacuum
		\begin{align}
			\ket{0}
		\end{align}
		To represent a state, we use a creation operator to add the state to the vacuum
		\begin{align}
			\hat a_i^{\dagger} \ket{0} = \ket{\phi_i}
		\end{align}
		And the annihilation operator will remove the particle again
		\begin{align}
			\hat a_i \ket{\phi_i} = \ket{0}
		\end{align}
		Trying to add a new particle to an already filled state and removing an unoccupied state results in zero
		\begin{align}
			\hat a_i^{\dagger} \ket{\phi_i} = 0 \;\;\;\;\; \hat a_i \ket{0} = 0
		\end{align}
		Bra states are needed, and by looking at the adjoint of a ket state, we get
		\begin{align}
			\left(\left| \phi_i \right> \right)^\dagger = \left< \phi_i \right| 
		\end{align}
		Which results in
		\begin{align}
			\left( \hat a_i^\dagger \left| 0 \right> \right)^\dagger = \left< 0 \right| \hat a_i = \left< \phi_i \right|
		\end{align}
		We see that the creation and annihilator operator are each other's adjoint operator. We can define the counting operator, $\hat N$, which will count how many states are occupied in a Slater determinant
		\begin{align}
			\hat N = \sum_p \hat a^\dagger_p \hat a_p = \sum_p \hat n_p
		\end{align}
	\end{section}

	\begin{section}{Strings of Operators}
		We can now construct the Slater determinant by working on vacuum with a string of creation operators
		\begin{align}
			\hat a_1^{\dagger} \hat a_2^{\dagger}... \hat a_N^{\dagger} \ket{0} = \left| \phi_1 \phi_2 ... \phi_N \right>
		\end{align}
		Permutations of the operators introduce a sign-change, which is equivalent to interchanging rows in the determinant. We need second quantization to respect the antisymmetrization condition, so a permutation of two states should introduce a change of sign
		\begin{align}
			\hat a_1^{\dagger} \hat a_2^{\dagger} \ket{0} = \ket{\phi_1 \phi_2} = -\ket{\phi_2 \phi_1} = -\hat a_2^{\dagger} \hat a_1^{\dagger} \ket{0}
		\end{align}
		We introduce the permutation operator, $\hat P$, which permutes two states in the Slater determinant 
		\begin{align}
			\hat P \left| \Phi \right> = (-1)^{\sigma(P)} \left| \Phi \right>
		\end{align}
		Where $\sigma(P)$ counts how many times the states are interchanged. Demonstrated with creation operators
		\begin{align}
			\hat a_1^\dagger \hat a_2^\dagger ... \hat a_i^\dagger \hat a_j^\dagger ... \hat a_n^\dagger = - \hat a_1^\dagger \hat a_2^\dagger ... \hat a_j^\dagger \hat a_i^\dagger ... \hat a_n^\dagger
		\end{align}
	\end{section}

	\begin{section}{Anticommutator Relations}
		When working on strings of operators, it is very convenient to introduce anticommutator relations. We define the relation as 
		\begin{align}
			\{ \hat A, \hat B \} = \hat A \hat B + \hat B \hat A	
		\end{align}
		By inserting the annihilation and creation operator, we can compute the relations and look at how they work on the vacuum state 
		\begin{align}
			\{ \hat a_i^\dagger \hat a_j \} \left| 0 \right>  &= \hat a_i^\dagger \hat a_j \left| 0 \right>  + \hat a_j \hat a_i^\dagger \left| 0 \right> = 0 + \delta_{ij} \left|0\right> 
 		\end{align}
 		Where we have introduced the kroenecker-delta function
 		\begin{align}
 			\delta_{ij} = \begin{cases}
 						1, & \text{if } i = j \\
 						0, & \text{ij } i \neq j
 						\end{cases}
 		\end{align}
		The second case
		\begin{align}
			\{ \hat a_i \hat a_j^\dagger \} \left| 0 \right> &= \hat a_i \hat a_j^\dagger + \hat a_j^\dagger \hat a_i \left| 0 \right> = \delta_{ij} \left| 0 \right> + 0
		\end{align}
		And the two last cases
 		\begin{align}
			\{ \hat a_i \hat a_j \} \left| 0 \right> &= \hat a_i \hat a_j \left| 0 \right> + \hat a_j \hat a_i \left| 0 \right> = \hat a_i \hat a_j \left| 0 \right> - \hat a_i \hat a_j \left| 0 \right> = 0\\
			\{ \hat a_i^\dagger \hat a_j^\dagger \} \left| 0 \right> &= \hat a_i^\dagger \hat a_j^\dagger \left| 0 \right> + \hat a_j^\dagger \hat a_i^\dagger \left| 0 \right> = \hat a_i^\dagger \hat a_j^\dagger \left| 0 \right> - \hat a_i^\dagger \hat a_j^\dagger \left| 0 \right> = 0
 		\end{align}
 		Ending up with our relations
 		\begin{align}
 			&\{ \hat a_i \hat a_j \} = 0 \\
 			&\{ \hat a_i^\dagger \hat a_j^\dagger \} = 0 \\
			&\{ \hat a_i^\dagger \hat a_j \} = \{ \hat a_i \hat a_j^\dagger \} = \delta_{ij}
		\end{align}
		The last result is very useful for rewriting strings of operators, since it allows us to rewrite a set of two operators as
		\begin{align}
			\hat a_i^\dagger \hat a_j = \{ \hat a_i^\dagger \hat a_j \} - \hat a_j \hat a_i^\dagger = \delta_{ij} - \hat a_j \hat a_i^\dagger 
			\label{interchange operators}
		\end{align}
		Which will be at the center of Wick's theorem. 
	\end{section}

	\begin{section}{Inner products}
		We assume all states are orthonormal, taking the inner product of two states should give
		\begin{align}
			\left< i | j \right> = \delta_{ij}
		\end{align}
		And for consistency, the vacuum state must also be normalized
		\begin{align}
			\left< 0 | 0 \right> = 1
		\end{align}
		This can be demonstrated by looking at the definition of the inner product of two equal states and using the anticommutator relations
		\begin{align}
			1 = \left< i | i \right> &= \left< 0 \right| \hat a_i \hat a_i^\dagger \left| 0 \right> \\
									 &= \left< 0 \right| (\delta_{ij} - \hat a_i^\dagger \hat a_i) \left| 0 \right> \\
									 &= \left< 0 | 0 \right> - 0 = \left< 0 | 0 \right>
		\end{align}
		It turns out we can use this exact scheme for longer chains of operators as well. Looking at the inner product of two general Slater Determinants
		\begin{align}
			&\left| A \right> = \left| a_1 a_2 ... a_N \right> = \hat a_1^\dagger \hat a_2^\dagger ... \hat a_N^\dagger \left| 0 \right> \\
			&\left| B \right> = \left| b_1 b_2 ... b_N \right> = \hat b_1^\dagger \hat b_2^\dagger ... \hat b_N^\dagger \left| 0 \right>
		\end{align}
		Writing the inner product
		\begin{align}
			\left< A | B \right> = \left< 0 \right| \hat a_N ... \hat a_2 \hat a_1 \hat b_1^\dagger \hat b_2^\dagger ... \hat b_N^\dagger \left| 0 \right>
		\end{align}
		By moving the annihilation operators all the way to the right, we know that the inner product becomes zero because $\hat a_p \left| 0 \right> = 0$. We utilize the anticommutator relations for interchanging creation and annihilation operators shown in (\ref{interchange operators}). By first moving $a_1$ to the right, we get two possible outcomes:
		\begin{enumerate} 
			\item One $b_p$ is equal to $a_1$ and we get
			\begin{align}
				\hat a_1 \hat b_p^\dagger = \delta_{a_1,b_p} - \hat b_p^\dagger \hat a_1 = 1 - \hat b_p^\dagger \hat a_1 
				\label{InnerProduct1}
			\end{align}
			This will now give us a new and shorter inner product
			\begin{align}
				\left< A | B \right> = \left< 0 \right| \hat a_N ... \hat a_2 \hat b_1^\dagger... \hat b_{p-1}^\dagger \hat b_{p+1}^\dagger ... \hat b_N^\dagger \left| 0 \right>(-1)^{p-1} - \left< 0 \right| \hat a_N ... \hat a_2 \hat b_1^\dagger \hat b_2^\dagger ... \hat b_N^\dagger \hat a_1  \left| 0 \right>
			\end{align}
			Where the last term will vanish because of $\hat a_1 \left| 0 \right> = 0$. Notice the sign factor coming from $(-1)^{p-1}$. This is due to interchanging creation operators when moving $\hat b_p^\dagger$ from position $p$ and $(p-1)$ steps to the left before using (\ref{InnerProduct1}).  
			\item No $b_p$ is equal to $a_1$ and all $\delta_{a_1, b_p} = 0$. Applying the same logic as for outcome 1, we get
			\begin{align}
				\left< A | B \right> = 0
			\end{align}
		\end{enumerate}
		We do the same for all states and see that this inner product can only be non-zero if all states $a_1 .. a_N$ has a matching state in $b_1 .. b_N$ and vice versa. If the ordering of states is different, a permutation factor $-1^{\sigma(P)}$ is included. 
	\end{section}

	\begin{section}{Representation of Operators}
		Consider a symmetric one-body operator represented by
		\begin{align}
			\hat F = \sum_{\mu = 1}^N \hat f_\mu 
		\end{align}
		The number $\mu$ tells us on which particle $\hat F$ works on. In this case, we are looking at a symmetric operator because it works identically on all particles. Looking at a matrix element of $\hat F$ put between two Slater determinants
		\begin{align}
			\left< a_1 a_2 ... a_N \right| \hat F \left| b_1 b_2 ... b_N \right> 
		\end{align}
		\begin{align}
			\sum_\mu \left< a_1 a_2 ... a_N \right| \hat f_\mu \left| b_1 b_2 ... b_N \right> 
		\end{align}

		\begin{subsection}{One-Body Operator}
			In second quantization, a one-body operator is given as
			\begin{align}
				\hat F = \sum_{pq} \left< p \right| \hat f \left| q \right> \hat a_p^\dagger \hat a_q 
			\end{align}
			Where the matrix element $\left< p \right| \hat f \left| q \right>$ is determined on the nature of the operator $\hat F$. It is common to denote this matrix element as
			\begin{align}
				\hat F = \sum_{pq} \left< p \right| \hat f \left| q \right> \hat a_p^\dagger \hat a_q = \sum_{pq} f_{pq} \hat a_p^\dagger \hat a_q
			\end{align}
			Doing calculations in many-body quantum mechanics, we are primarily interested in expectation values. It is therefore crucial that we develop a solid scheme for calculating these values. This can be done by for example looking at the following inner product 
			\begin{align}
				\left< P \right| \hat F \left| R \right> 
			\end{align}
			Inserting the definition of $\hat F$
			\begin{align}
				\left< 0 \right| \hat a_M ... \hat a_s \hat a_r \left( \sum_{kl} f_{kl} \hat a_k^\dagger \hat a_l \right) \hat a_p^\dagger \hat a_q^\dagger ... \hat a_N^\dagger \left| 0 \right>
			\end{align}
			Which can be rewritten as
			\begin{align}
				\sum_{pq} f_{pq} \left< 0 \right| \hat a_M ... \hat a_s \hat a_r (\hat a_k^\dagger \hat a_l) \hat a_p^\dagger \hat a_q^\dagger ... \hat a_N^\dagger \left| 0 \right>
			\end{align}
			We apply the same logic as in the previous section, which provides us with three different outcomes for this expectation value
			\begin{enumerate}
				\item The states $p,q,...,N$ are all identical to the states $r,s,...,M$. This results in
				\begin{align}
					\left< P \right| \hat F \left| R \right> = \sum_k^N f_{kk} (-1)^{\sigma(P)}
				\end{align}
				Where we have included a perturbation factor in case the ordering of states is different in the two states. 
				\item If all states except one from each Slater determinant are equal, we get a \textit{noncoincidence} \cite{ShavittAndBartlett}
				\begin{align}
					(p = r), \: (s = q), \: ..., \: (n \neq m), \: ..., \: (N = N)
				\end{align}
				We can rewrite the expectation value as
				\begin{align}
					\sum_{pq} f_{pq} \left< 0 \right| \hat a_M ... \hat a_s \hat a_r (\hat a_k^\dagger \hat a_l) \hat a_p^\dagger \hat a_q^\dagger ... \hat a_N^\dagger \left| 0 \right> = (-1)^{\sigma(P)} f_{mn}
				\end{align}
				Because the operators $\hat a_k^\dagger$ and $\hat a_l$ must be paired with the non-identical states $m$ and $n$ for us to be left with a orthogonal inner product.
				\item If there are more than one noncoincidence, no contributions can survive, and the expectation value is 
				\begin{align}
					\left< P \right| \hat F \left| R \right> = 0
				\end{align}
			\end{enumerate}
		\end{subsection}

		\begin{subsection}{Two-body Operator}
			I have in this thesis only looked at Hamiltonians consisting of a maximum of two-body interactions. Because of this, I will need a formalism for a two-body operator as well. It is defined almost identically as the one-body operator. We write the general two-body operator as
			\begin{align}
				\hat G = \frac{1}{2} \sum_{ijkl} \left< i(1) j(2) \right| g_{12} \left| k(1) l(2) \right> \hat a_i^\dagger \hat a_j^\dagger \hat a_l \hat a_k
			\end{align}
			Where the numbers $(1)$ and $(2)$ show which particle occupy the state. We are, as for the one-body operator, interested in how we can calculate expectation values for this operator. We take the inner product with the two Slater determinants $\left| P \right>$ and $\left| R\right>$
			\begin{align}
				\frac{1}{2} \sum_{ijkl} \left< i(1) j(2) \right| g_{12} \left| k(1) l(2) \right>   \left< 0 \right| \hat a_M ... \hat a_s \hat a_r (\hat a_i^\dagger \hat a_j^\dagger \hat a_l \hat a_k) \hat a_p^\dagger \hat a_q^\dagger ... \hat a_N^\dagger \left| 0 \right>
			\end{align}
			There are three possible outcomes here as well 
			\begin{enumerate}
				\item If there are none noncoincidences, and all states in SD $\left| P \right>$ are equal to all states in SD $\left| R \right>$, we get 
				\begin{align}
				 	\left< P \right| \hat G \left| R \right> = \frac{1}{2}\sum_{p \in P}\sum_{q \in P} (\left< pq\right| \hat g \left| pq \right> - \left< pq\right| \hat g \left| qp \right> ) = \frac{1}{2}\sum_{p \in P}\sum_{q \in P} \left< pq || pq \right>
				\end{align}
				Where it is useful to use the antisymmetric matrix element
				\begin{align}
					\left< pq || pq \right> = \left< pq\right| \hat g \left| pq \right> - \left< pq\right| \hat g \left| qp \right>  
				\end{align}
				\item If we have a single noncoincidence, where all states except one from each SD are perfectly identical, we get \cite{ShavittAndBartlett}
				\begin{align}
					\left< P \right| \hat G \left| R \right> = \sum_{q \in P} \left< p' q || p q \right>
				\end{align}
				where the states $p'$ and $p$ are the unequal states. 
				\item If we have two noncoincidences, we get 
				\begin{align}
					\left< P \right| \hat G \left| R \right> = \left< p' q' || p q \right> 
				\end{align}
				\item If more than two states from each SD are unequal, the expectation value will be $0$.
			\end{enumerate}
		\end{subsection}

		\begin{subsection}{The Hamiltonian}
			We can now write our Hamiltonian using second quantization. The Hamiltonian consists of a one-body and a two-body term
			\begin{align}
				\hat H = \hat H_1 + \hat H_2
			\end{align}
			Which can be written out as
			\begin{align}
				\hat H_1 = \sum_\mu \hat h_\mu, \:\;\;\;\;\; \hat H_2 = \sum_{\mu < \nu} \hat v_{\mu \nu}
			\end{align}
			Using atomic units, we can write this as
			\begin{align}
				\hat h_\mu = -\frac{1}{2}\nabla_\mu^2 - \sum_A \frac{Z_A}{r_{\mu A}}, \:\;\;\;\;\; \hat v_{\mu \nu} = \frac{1}{r_{\mu \nu}}
			\end{align}
			Using the formalism introduced, we can write this as
			\begin{align}
				\hat H = \hat H_1 + \hat H_2 = \sum_{ij} \left<i \right| \hat h \left| j \right> \hat a_i^\dagger \hat a_j 
						+ \frac{1}{4} \sum_{ijkl} \left<ij|| kl \right> \hat a_i^\dagger \hat a_j^\dagger \hat a_l \hat a_k
			\end{align}
			Where we have used the anti-symmetric form of the two-body operator
			\begin{align}
				\left<ij|| kl \right> = \left< i(1) j(2) \right| \hat v_{12} \left| k(1) l(2) \right> - \left< i(1) j(2) \right| \hat v_{12} \left| l(1) k(2) \right>
			\end{align}
		\end{subsection}

	\end{section}

	\begin{section}{Normal Ordering and Wick's Theorem}
		As one can see, calculations of inner products can be a tedious affair when utilizing the anticommutator rules. Luckily, one can develop more powerful tools, namely Wick's theorem. Before introducing Wick's theorem, a definition of normal ordering and contractions are needed.
		\begin{subsection}{Normal Ordering}
			As previously shown, when evaluating a string of operators, the general scheme is to place all annihilation operators to the right of creation operators. This is because, when working on the true vacuum state, annihilation operators give zero. The only non-zero results will then arize from kroenecker delta's when permutating creation-annihilation operators according to equation (\ref{interchange operators}). 

			A string of operators with all annihilation operators to the right will be referred to as a \textit{normal ordered} string of operators. Normal ordering of operators is commonly denoted by a curvy bracket or square bracket
			\begin{align}
				n[ \hat A \hat B ... \hat N ] = \{ \hat A \hat B ... \hat N \}
			\end{align}
			Any expectation value, with respect to the true vacuum, of a set of normal ordered operators will always be zero:
			\begin{align}
				\left< 0 \right| \{ \hat A \hat B ... \hat N \} \left| 0 \right> = 0 
				\label{NormalOrdering1}
			\end{align}
			One can note that the Hamiltonian operator is already written in a \textit{normal ordered} form. 
		\end{subsection}

		\begin{subsection}{Contractions}
			The second tool needed for Wick's theorem is the definition \textit{contractions} of operators. We define the contraction of general creation and annihilation operators as 
			\begin{align}
				\bcontraction{}{\hat A}{}{\hat B} 
				\hat A \hat B
				\equiv \hat A \hat B - \{ \hat A \hat B \}
			\end{align}
			And taking the expectation value of the two operators with respect to the true vacuum, providing the contractions
			\begin{align}
				\bcontraction{}{\hat a_a^\dagger}{}{\hat a_b^\dagger}
				\hat a_a^\dagger \hat a_b^\dagger 
				= 
				\bcontraction{}{\hat a_a}{}{\hat a_b}
				\hat a_a \hat a_b
				= 
				\bcontraction{}{\hat a_a^\dagger}{}{\hat a_b}
				\hat a_a^\dagger \hat a_b
				= 0 
			\end{align}
			The only non-zero results will be for 
			\begin{align}
				\bcontraction{}{\hat a_a}{}{\hat a_b}
				\hat a_a \hat a_b
				^\dagger = \delta_{ab}
			\end{align}
		\end{subsection}
	
		\begin{subsection}{Time-independent Wick's theorem}
			Wick's theorem states: \textit{A product of a string of creation and annihilation operators is equal to their normal product plus the sum of all possible normal ordered contractions} \cite{ShavittAndBartlett}. Symbolically, this is shown by 
			\begin{align}
				\hat A \hat B \hat C \hat D ... = \{\hat A \hat B \hat C \hat D ... \} + \sum \{  \bcontraction[2ex]{}{\hat A}{\hat B \hat C \hat D ...}
				\hat A \bcontraction{}{\hat B}{\hat C \hat D ..}
				\hat B \hat C \hat D .... \}
			\end{align}
			The usefulness of this relation is when calculating expectation values. Because of (\ref{NormalOrdering1}), the only result that will give a non-zero result, is when all operators are fully contracted. As an example to display the usefulness of Wick's theorem 
			\begin{align}
				\left< 0 \right| \hat a_a \hat a_b^\dagger \hat a_c \hat a_d^\dagger \hat a_e \hat a_f^\dagger \left| 0 \right> = \left< 0 \right| \{ 
				\bcontraction{}{\hat a_a}{}{\hat a_b^\dagger}
				\hat a_a \hat a_b^\dagger \bcontraction{}{\hat a_c}{}{\hat a_d^\dagger}
				\hat a_c \hat a_d^\dagger \bcontraction{}{\hat a_e}{}{\hat a_f^\dagger}
				\hat a_e \hat a_f^\dagger 
				\} \left| 0 \right> = \delta_{ab} \delta_{cd} \delta_{ef}
			\end{align}
			Where the contractions displayed are the only set of non-zero contractions possible. 
		\end{subsection}
	\end{section}

	\begin{section}{Particle-Hole Formulation}
		For larger Slater determinants, it is tedious to write all states in terms of the vacuum state $\left| 0 \right>$. We define a reference state that will be used instead of the pure vacuum. Looking at a general Slater determinant
		\begin{align}
			\left| \Phi_0 \right> = \hat a_i^\dagger \hat a_j^\dagger ... \hat a_n^\dagger \left| 0 \right>
		\end{align}
		If this Slater Determinant is the ground state of our system, we can use it as a reference state. We define the highest lying occupied state as the Fermi level, and name all states above the Fermi level \textit{particle states} or \textit{virtual states}. If a state below the Fermi level is vacant, we name it a \textit{hole state}. From here on out, we will use a distinct naming pattern for indices. Indices using the latin alphabet using letters $i, j, k, l, ...$ are reserved for \textit{hole states}. Latin letters $a, b, c, d, ...$ are reserved for \textit{particle states}. Sometimes, we want to name more general states that can take the form of either a \textit{hole state} or a \textit{particle state}. We use the latin letters $p, q, r, s, ...$. For a more convenient way of writing, operators will be written on a shorter and more convenient form
		\begin{align}
			\hat a_a = \hat a \:\:\:\:\: \hat a_b^\dagger = \hat b^\dagger \:\:\:\:\: \hat a_i^\dagger = \hat i^\dagger \:\:\:\: ...
		\end{align}
		And so forth. The reference state will be written as 
		\begin{align}
			\left| \Phi_0 \right> = \hat i^\dagger \hat j^\dagger \hat k^\dagger ... \hat n^\dagger \left| \right> = \left| ijk ... n \right> = \left| \right>
		\end{align}
		And excitations will be written as
		\begin{align}
			\text{Single Excitation: }\:\:\:\:& \left| \Phi_i^a \right> = \left| ajk ... n \right> = \hat i \hat a^\dagger \left| \right> \\
			\text{Double Excitation: }\:\:\:\:& \left| \Phi_{ij}^{ab} \right> = \left| abk ... n \right> = \hat i \hat j \hat a^\dagger \hat b^\dagger \left| \right> 
		\end{align}
		Where the use of annihilation operators for \textit{hole states} no longer produce zero when used on the reference state, but simply remove one particle from the reference state and create a \textit{hole state}:
		\begin{align}
			\hat a_i \left| \right> = \left| \Phi_i \right> = \left| jk ... n \right>
		\end{align}
		This will introduce a small change in Wick's theorem, as the only non-zero contractions are now 
		\begin{align}
			\contraction{}{\hat i^\dagger}{}{\hat j}
			\hat i^\dagger \hat j = \delta_{ij}
		\end{align}
		And 
		\begin{align}
			\contraction{}{\hat a}{}{\hat b^\dagger}
			\hat a \hat b^\dagger = \delta_{ab}
		\end{align}
		Contractions relative to the Fermi vacuum will now be denoted by brackets \textit{above} the operators instead of below. Apart from this, Wick's theorem is unchanged relative to the Fermi vacuum. \par 


		A very important property of the reference state, is the expectation value for the Hamiltonian: 
		\begin{align}
			\left< \right| \hat H \left| \right> = \left< \Phi_0 \right| \hat H \left| \Phi_0 \right> = \left< ijk...n \right| \hat H \left| ijk...n\right> 
		\end{align}
		We name this the reference Energy. The result is given by \cite{ShavittAndBartlett}
		\begin{align}
			E_{\text{ref}} = \left< \Phi_0 \right| \hat H \left| \Phi_0 \right> = \sum_i h_{ii} + \frac{1}{2} \sum_{ij} \left< ij || ij \right>
		\end{align}

	\end{section}

	\begin{section}{Normal ordering of Operators}
		After defining the new vacuum, we will now write the operators on a normal-ordered form, which will now work with respect to the reference state.	
		\begin{subsection}{One-Body Operator}
			 Consider a general one-body operator
			\begin{align}
				\hat F = \sum_{pq} \left< p \right| \hat f \left| q \right> \hat p^\dagger \hat q
			\end{align}
			Using Wick's theorem to rewrite the string of operators
			\begin{align}
				\hat p^\dagger \hat q = \{\hat p^\dagger \hat q \} + \contraction{}{\hat p}{^\dagger}{\hat q}
				\hat p^\dagger \hat q
			\end{align}
			We get 	
			\begin{align}
				\hat F &= \sum_{pq} \left< p \right| \hat f \left| q \right> \{ \hat p^\dagger \hat q \} + \sum_i \left< i \right| \hat f \left| i \right>\\
					&= \hat F_N + \sum_i \left< i \right| \hat f \left| j \right>
			\end{align}
			We notice that since 
			\begin{align}
				\left< \right. | \hat F_N |\left. \right> = 0 \:\:\:\: \rightarrow \:\:\:\: \sum_i \left< i \right| \hat f \left| i \right> = \left< \right. | \hat F | \left. \right>
			\end{align}
			We can rewrite the equation as
			\begin{align}
				\hat F = F_N + \left< \right. | \hat F | \left. \right>
			\end{align}
			Meaning that $F_N$ represent the difference between $\hat F$ and the Fermi expectation value. 
		\end{subsection}
		
		\begin{subsection}{Two-Body operators}
			The general two-body operator is given by
			\begin{align}
				\hat G = \frac{1}{4} \sum_{pqrs} \left< pq | \hat g | rs \right>_A \hat p^\dagger \hat q^\dagger \hat s \hat r
			\end{align}
			Although the method will be identical for a two-body operator as for a one-body operator, we will require a much larger sum over all possible contractions when using Wick's theorem. Calculation of the result can be viewed in \cite{ShavittAndBartlett}. 
			\begin{align}
				\hat G = \frac{1}{4} \sum_{pqrs} \left<pq | \hat g | rs\right>_A \{ \hat p^\dagger \hat q^\dagger \hat s \hat r \}+ \sum_{ipq} \left<pi |\hat g | qi\right>_A \{ \hat p^\dagger \hat q\} + \frac{1}{2} \sum_{ij} \left< ij | \hat g | ij \right>_A 
				\label{Two-Body Normal Ordering}
			\end{align}
			As for the one-body operator
			\begin{align}
				\left< \right. | \hat G | \left.  \right> = \frac{1}{2} \sum_{ij} \left< ij | \hat g | ij \right>_A 
			\end{align}
			We can now name the terms 
			\begin{align}
				\hat G = \hat G_N + \hat G_N' + \left< \right. | \hat G | \left.  \right>
			\end{align}
			Where $\hat G_N'$ is a normal-ordered two-body operator. 

		\end{subsection}
	\end{section}

	\begin{section}{Partitioning the Hamiltonian Operator}
		The Hamiltonian has been shown to consist of a one-body and a two-body term
		\begin{align}
			\hat H = \hat H_1 + \hat H_2
		\end{align}
		One can, however, write it in terms of a zero-order term and a perturbation
		\begin{align}
			\hat H = \hat H_0 + \hat V
		\end{align}
		It is convenient to choose a zero-order Hamiltonian that is diagonal
		\begin{align}
			\hat H_0 = \sum_p \epsilon_p \hat p^\dagger \hat p
		\end{align}
		This means we can write the perturbation as
		\begin{align}
			\hat V &= (\hat H_1 - \hat H_0) + \hat H_2 \\
			&= \sum_{pq}(h_{pq} - \epsilon_p \delta_{pq} ) \hat p^\dagger \hat q + \frac{1}{4}\left<pq||rs\right>\hat p^\dagger \hat q^\dagger \hat s \hat r 
		\end{align}
		First, we define a Fock operator, $\hat F$, and a common practice is to choose the orbital energies as the diagonal elements of this Fock operator. 
		\begin{align}
			\hat F = \sum_{pq} f_{pq} \hat p^\dagger \hat q
		\end{align}
		With the matrix element defined as
		\begin{align}
			f_{pq} = h_{pq} + u_{pq}
		\end{align}
		Here $u_{pq}$ is the matrix element of a one-body operator $\hat U$. It is commonly implemented to simplify the zeroth-order term $\hat H_0$ and the normal ordering of the Hamiltonian. See (\ref{Total Perturbation}). We define the operator $\hat U$ as
		\begin{align}
			\hat U &= \sum_{pq} u_{pq} \hat p^\dagger \hat q \\
			u_{pq} &= \sum_i \left<pi||qi\right>
		\end{align}
		This means we can write $\hat F = \hat H_1 + \hat U$. Inserting the Fock operator into the perturbation
		\begin{align}
			\hat V &= \hat F - \hat H_0 - \hat U + \hat H_2 \\
				   &= \sum_{pq}(f_{pq} - \epsilon_p \delta_{pq} - u_{pq}) \hat p^\dagger \hat q + \frac{1}{4} \sum_{pqrs} \left<pq||rs\right> \hat p^\dagger \hat q^\dagger \hat s \hat r
			\label{3.93}	
		\end{align}
		For a non-canonical Hartree-Fock case, the Fock matrix is diagonal, namely
		\begin{align}
			f_{pq} = \epsilon_p \delta_{pq}
		\end{align}
		This means the perturbation can be rewritten as
		\begin{align}
			\hat V = -\sum_{pq} u_{pq} \hat p^\dagger \hat q + \frac{1}{4} \sum_{pqrs} \left<pq||rs\right> \hat p^\dagger \hat q^\dagger \hat s \hat r	
			\label{3.95}
		\end{align}
		With the zeroth-order energies given by 
		\begin{align}
			\hat H_0 = \sum_p \epsilon_p \hat p^\dagger \hat p \;\;\;\;\;\; \epsilon_p = h_{pp} + \sum_i \left<pi||pi\right>
		\end{align}
		The noncanonical case, the Fock operator, $\hat F$, is block diagonal, with $f_{ia} = 0$. To, again, cancel out the single orbital energies from the perturbation, we split the Fock operator into a diagonal and off-diagonal term
		\begin{align}
			\hat F = \hat F^d + \hat F^o
		\end{align}
		The diagonal term will now be canceled out, and we are left with the perturbation
		\begin{align}
			\hat V = -\sum_{pq} (f_{pq}^o - u_{pq}) \hat p^\dagger \hat q + \frac{1}{4} \sum_{pqrs} \left<pq||rs\right> \hat p^\dagger \hat q^\dagger \hat s \hat r
		\end{align}
		For convience, we can organize the perturbation into a one-body part and a two-body part, $\hat V_1$ and $\hat V_2$
		\begin{align}
			\hat V_1 &= \hat F^o - \hat U = \sum_{pq} (f_{pq}^o - u_{pq}) \hat p^\dagger \hat q \\
			\hat V_2 &= \hat H_2 = \frac{1}{4} \sum_{pqrs} \left< pq||rs\right> \hat p^\dagger \hat q^\dagger \hat s \hat r
			\label{Partitioned Hamiltonian}
		\end{align}
		Resulting in the Hamiltonian
		\begin{align}
			\hat H = \hat H_0 + \hat V_1 + \hat V_2
		\end{align}

	\end{section}

	\begin{section}{Normal Ordering of Hamiltonian}
		To sum it all up, I will now present a normal ordering of the partitioned Hamiltonian operator. Starting by applying Wick's theorem to the zeroth order term
		\begin{align}
			(\hat H_0)_N = \hat H_0 - E^{(0)} = \sum_p \epsilon_p \hat p^\dagger \hat p - \sum_i e_i = \sum_p \epsilon_p \{\hat p^\dagger \hat p\}
		\end{align}
		Then applying Wick's theorem to the one- and two-body perturbations given in equation \ref{Partitioned Hamiltonian}, we get 
		\begin{align}
			\hat V_1 = (\hat V_1)_N + \left< \right. | \hat V_1 | \left. \right>
		\end{align}
		Where we have 
		\begin{align}
			(\hat V_1)_N = \hat F_N^o - \hat U_N = \sum_{pq}(f_{pq}^o - u_{pq})\{ \hat p^\dagger \hat q \}
		\end{align}
		and
		\begin{align}
			\left< \right. | \hat V_1 | \left. \right> = -\sum_{ij} \left< ij || ij \right> = - \left< \right. | \hat U | \left. \right> 
		\end{align}
		Turning to the two-body perturbation and using the equation \ref{Two-Body Normal Ordering}, we can write the two-body part as
		\begin{align}
			\hat V_2 = (\hat V_2)_N + \hat V_N' + \left< \right. | \hat V_2 | \left. \right>
		\end{align}
		Where we have the following 
		\begin{align}
			(\hat V_2)_N &= \frac{1}{4} \sum_{pqrs} \left<pq||rs\right> \{ \hat p^\dagger \hat q^\dagger \hat s \hat r \} \\
			V_N' &= \sum_{pq} \left<pi||pi\right> \{ \hat p^\dagger \hat q \} \\
			\left< \right. | \hat V_2 | \left. \right> &= \frac{1}{2} \sum_{ij} \left<ij||ij\right>
		\end{align}
		We notice now, that after normal ordering the operators, we are left with many terms that can be reorganized into zero-, one- and two-body parts. We can rewrite the total perturbation as
		\begin{align}
			\hat V = \hat F_N^o - \hat U_N + \left< \right. | \hat V_1 | \left. \right> + (\hat V_2)_N + \hat V_N' + \left< \right. | \hat V_2 | \left. \right>
			\label{Total Perturbation}
		\end{align}
		Now, by construction of $\hat U$, we see that $\hat U$ and $\hat V_N'$ cancel each other out. Renaming $(\hat V_2)_N = \hat W_N$, we see that the terms left can be written as 
		\begin{align}
			\hat V = \hat F_N^o + \hat W_N + \left< \right. | \hat V | \left. \right>
		\end{align}
		By applying the same logic as earlier, we write
		\begin{align}
			\hat V_N = \hat V - \left< \right. | \hat V | \left. \right>
		\end{align}
		So that we finally can write the normal ordered perturbation as
		\begin{align}
			\hat V_N = \hat F_N^o + \hat W_N
		\end{align}
		We notice here the use of the diagonal Fock matrix. This matrix is just zero in the canonical Hartree Fock case. 
	\end{section}

	\begin{section}{Correlation Energy}
		All the many-body quantum mechanics methods described in this thesis will aim to compute the correlation energy. We derive it by substracting 
		\begin{align}
			\left< \right. | \hat H | \left. \right> = \left< \right. | \hat H_0 | \left. \right> + \left< \right. | \hat V | \left. \right>
		\end{align}
		from the partitioned hamiltonian $\hat H = \hat H_0 + \hat V$. Resulting in
		\begin{align}
			\hat H - \left< \right. | \hat H | \left. \right> &= \hat H_0 - \left< \right. | \hat H_0 | \left. \right> + \hat V - \left< \right. |\hat V| \left. \right>
		\end{align}
		This can be rewritten in terms of normal ordered operators as 
		\begin{align}
			\hat H_N = (\hat H_0)_N + \hat V_N
		\end{align}
		The Schr\"{o}dinger equation for this operator is given as
		\begin{align}
			\hat H_N \Psi = \Delta E \Psi 
		\end{align}
		Where we have defined the computed energy as
		\begin{align}
			\Delta E = E - E_{\text{ref}}
		\end{align}
		or 
		\begin{align}
			E = E_{\text{ref}} + \Delta E
		\end{align}
		This energy is named the correlation energy, and the goal of my thesis is to implement and compare different methods to compute this energy for different systems. The reference energy, given as
		\begin{align}
			E_{\text{ref}} = \left< \right. | \hat H_0 | \left. \right> + \left< \right. | \hat V | \left. \right>
		\end{align}
		Is easily computed when the basis is set up. Finally, we can set up the fully partitioned normal ordered Hamiltonian as
		\begin{align}
			\hat H_N = \hat F_N^d + \hat F_N^o + \hat W_N
		\end{align}

	\end{section}
 
\end{chapter}



\begin{chapter}{Diagramatic Representation}
	It can be quite cumbersome and error-prone to treat the manipulation of states and operators with second quantization \cite{ShavittAndBartlett}. The soon to be introduced many-body methods will include various sums over states. One can introduce a new formalism originated in quantum field theory in the form of Feynman diagrams to depict and list these sums. It is quite common to refer to these sums simply as \textit{diagrams}. The main benefits of the diagramatic notation include an easy way of listing non-vanishing terms and elucidating various cancelations in the sums. 

	\begin{section}{The Slater Determinant}
		We begin, as in second quantization, by setting up the Slater determinant. There is a time dependent direction on the diagrams going up. The actual times are irrelevant, but the sequence is important. The reference state, $| \left. \right> = \left| \Phi \right>$, is depicted simply as a horizontal line
		\begin{figure}[H]
			\includegraphics[width=\textwidth]{Figures/SlaterDeterminant1.pdf}
			\label{SlaterDeterminant1}
			\caption{Diagram for the reference state $| \left. \right>$}
		\end{figure}
		While the hole states are represented by vertical lines either going up or down, particle and hole states are depicted by a vertical line. An arrow pointing up relates a particle state, while an arrow pointing down means a hole state. Depicting the two states $\left| \Phi^a \right> $ and $\left| \Phi_i \right>$
		\begin{figure}[H]
			\includegraphics[width=\textwidth]{Figures/SlaterDeterminant2.pdf}
			\label{SlaterDeterminant2}
			\caption{Diagrams for the addition of a particle and a hole state, $\left| \Phi^a \right> $ and $\left| \Phi_i \right> $ respectively}
		\end{figure}
		The ket-variant of the singly excited Slater determinant $\left< \Phi_i^a \right| $ can be drawn as
		\begin{figure}[H]
			\includegraphics[width=\textwidth]{Figures/SlaterDeterminant3.pdf}
			\label{SlaterDeterminant3}
			\caption{Diagram for the singly excited ket state $\left< \Phi_i^a \right|$}
		\end{figure}
		And the doubly excited states $\left| \Phi_{ij}^{ab} \right>$ can be drawn as
		\begin{figure}[H]
			\includegraphics[width=\textwidth]{Figures/SlaterDeterminant4.pdf}
			\label{SlaterDeterminant4}
			\caption{Diagram for the doubly excited bra state $\left| \Phi_{ij}^{ab} \right>$}
		\end{figure}
	\end{section}

	\begin{section}{Operators}
		We need a convention for one-body operators as well. A general one-body operator is given by 
		\begin{align}
			\hat F_N = \sum_{pq} \left< p \right| \hat f \left| q \right> \left\{ \hat p^\dagger \hat q \right\}
		\end{align}
		We will represent the matrix element $\left< p \right| \hat f \left| q \right>$ by a dashed line, while there will be one line entering and one line leaving the operator due to the annihilation and creation operator. Because the operator behaves different depending on whether the general operators $p$ and $q$ are virtual or occupied states, it can be drawn as four different forms. Presenting the various forms in the figure below \cite{ShavittAndBartlett}
		\begin{figure}[H]
			\includegraphics[width=\textwidth]{Figures/OneBodyOperator.pdf}
			\label{OneBodyOperator}
			\caption{Diagrams for four different variants of the one-body operator. From left to right, the operators shown are $\sum_{ij} h_{ij} i^\dagger j $, $\sum_{ab} h_{ab} a^\dagger b$, $\sum_{ai}h_{ai} a^\dagger i$ and $\sum_{ai} h_{ia} i^\dagger a$}
		\end{figure}
		The same logic can be applied to the general two-body operator, given by 
		\begin{align}
			\hat V_N = \frac{1}{4} \sum_{pqrs} \left<pq||rs\right> \left\{ \hat p^\dagger \hat q^\dagger \hat s \hat r \right\}
		\end{align}
		When we draw this diagram, one will need two outgoing lines representing the creation operators and two incoming lines, representing the annihilation operators. The matrix element will, as for the one-body operator, be drawn as a horizontal \textit{interaction line}
		\begin{figure}[H]
			\includegraphics[width=\textwidth]{Figures/TwoBodyOperator0.pdf}
			\caption{two-body operator, showing the horizontal line and four creation or annihilation operators}
			\label{Figure:TwoBodyOperator0}
		\end{figure}
		The left half side of the interaction will represent particle 1, while the right half will represent particle two. We can therefore set up the general relations for the term $\left\{ \hat p^\dagger \hat q^\dagger \hat s \hat r \right\}$
		\begin{align}
			\nonumber \hat p^\dagger &\rightarrow \text{left outgoing line}, \:\:\:\: \hat q^\dagger \rightarrow \text{right outgoing line} \\
			\nonumber \hat r &\rightarrow \text{left incoming line}, \:\:\:\: \hat s \rightarrow \text{right incoming line} 
		\end{align}
		And for the matrix element, we use the rules 
		\begin{align}
			\left< \text{left-out } \text{ right-out } | | \text{ left-in } \text{ right-in } \right>
		\end{align}
		There should be 16 combinations of particle- and hole-states distributed out between the operators $\hat p^\dagger$, $\hat q^\dagger$, $\hat s$ and $\hat r$, but since some diagrams will be equivalent, we are left with 9 distuingishable diagrams. The equivalent diagrams will be included by a weight factor $2$. 

		\begin{figure}[H]
			\includegraphics[width=\textwidth]{Figures/TwoBodyOperator.pdf}
			\caption{A figure showing 6 different Goldstone diagrams for the two-body operator. The matrix elements shown, from left to right, are:
			$\left<ab||cd\right>$, $\left<ij||kl\right>$, $\left<ai||bj\right>$, $\left<ab||ci\right>$, $\left<ia||jk\right>$, $\left<ai||bc\right>$.}
			\label{Figure:TwoBodyOperator1}
		\end{figure}

		\begin{figure}[H]
			\includegraphics[width=\textwidth]{Figures/TwoBodyOperator2.pdf}
			\caption{A figure showing 3 different Goldstone diagrams for the two-body operator. The matrix elements shown, from left to right, are:
			$\left<ij||ka\right>$, $\left<ab||ij\right>$, $\left<ij||ab\right>$.}
			\label{Figure:TwoBodyOperator2}
		\end{figure}

	\end{section}

	\begin{section}{Contractions and Inner products}
		As seen, contractions are an important part of many-body methods. Representing contractions is easy with using a diagrammatic approach. It is done by connecting the lines between operators and Slater determinants. Take, for instance, the Slater determinant \cite{Audun,ShavittAndBartlett}
		\begin{align}
			\left| \Phi_i^a \right> = \hat a^\dagger \hat i | \left. \right> 
		\end{align}
		and the general one-body operator 
		\begin{align}
			\hat U = \sum_{bc} \left< b | \hat u | c \right> \{ \hat b^\dagger \hat c \}
		\end{align}
		When the operator $\hat U$ acts on the Slater determinant, the resulting Slater determinant will change 
		\begin{align}
			\hat U \left| \Phi_i^a \right> = \sum_{bc} \left< b | \hat u | c \right> \{ \hat b^\dagger \hat c \} \{ \hat a^\dagger \hat i \} | \left. \right>
		\end{align}
		We can write this out using the generalized Wick's theorem, noticing that there is only one possible contraction that is non-zero. 
		\begin{align}
			= \left< b | \hat u | c \right> \{ \hat b^\dagger \hat c \hat a^\dagger \hat i \} + \left< b | \hat u | c \right> \{ \hat b^\dagger \contraction{}{\hat c}{}{\hat a^\dagger}
			\hat c \hat a^\dagger \hat i \} = 0 + \left< b | \hat u | c \right> \delta_{ac} \left| \Phi_i^b \right>
		\end{align}
		Which gives
		\begin{align}
			\left< b | \hat u | a \right> \{ \hat b^\dagger \hat i \} | \left. \right> = \left< b | \hat u | a \right> \left| \Phi_i^b \right>
		\end{align}
		The diagrammatic representation will be shown as 
		\newpage
		\begin{figure}[H]
			\includegraphics[width=\textwidth]{Figures/Contraction.pdf}
			\caption{The diagrammatic representation of a contraction between the a one-body operator and a singly excited Slater determinant.}
			\label{Contraction}
		\end{figure}
		Representing an inner product of two Slater Determinants is done by putting together the diagram for a ket state and the diagram for a bra state. Looking at the previous example, taking the expectation value of the general operator $\hat U$, we get 
		\begin{align}
			\left< \Phi_k^d \right| \hat U \left| \Phi_i^a \right>
		\end{align}
		Which can be written out as
		\begin{align}
			\sum_{bj} \left< b | \hat u | c \right> \left< \right. | \{ \hat k^\dagger \hat d \} \{ \hat b^\dagger \hat c \} \{ \hat a^\dagger \hat i \} | \left. \right>
		\end{align}
		Calculating with generalized Wick's theorem
		\begin{align}
			= \left< d | \hat u | a \right> \delta_{db} \delta_{ac} \delta_{ki}
		\end{align}
		\begin{figure}[H]
			\includegraphics[width=\textwidth]{Figures/InnerProduct.pdf}
			\label{InnerProduct}
			\caption{Diagrammatic representation of the inner product for a one-body operator between two singly excited Slater determinants.}
		\end{figure}
	\end{section}
	\newpage
	\begin{section}{Interpreting Diagrams}	
		The many-body methods presented in the thesis rely heavily upon operator expressions and contractions. A common use of diagrams, is to perform  contractions using the rules presented in this chapter, to set up diagrams representing the energy and wave functions. This is by many considered to be more efficient than to perform calculations using Wick's theorem by hand. 

		An important part of using diagrams, is to have a consistant toolset to translate diagrams into mathematical expressions. These tools exist, see for example \cite{ShavittAndBartlett}, and the implementation of perturbation theory for Pairing model presented in this thesis.  
	\end{section}

\end{chapter}



\begin{chapter}{Many-Body Methods}
	We define an ansatz for the ground state, $\left| \Phi_0 \right>$ as a Slater determinant consisting of the single-particle states, $\left| \phi_i \right>$
	\begin{align}
		\ket{\Psi} \approx \ket{\Phi_0} = 	\frac{1}{ \sqrt{N!} } \left|\begin{matrix}
			\phi_1(\mathbf{x}_1) & \phi_2(\mathbf{x}_1) & ... & \phi_N(\mathbf{x}_1) \\
			\phi_1(\mathbf{x}_2) & \phi_2(\mathbf{x}_2) & ... & \phi_N(\mathbf{x}_2) \\
			... & & & \\
			\phi_1(\mathbf{x}_N) & \phi_2(\mathbf{x}_N) & ... & \phi_N(\mathbf{x}_N) 
		\end{matrix} \right|
	\end{align}
	Written in terms of second quantization
	\begin{align}
		\left| \Phi_0 \right> = \left( \prod_{i \leq F} \hat i^\dagger \right) \left| 0 \right> = |\left.  \right> 
	\end{align}
	Typically one chooses well-known and mathematically simple single-particle states that are easy to implement. In this thesis, I have used a free particle wave function as single-particle states for infinite matter. Using this basis, I obviously fail to incorporate the interaction between electrons since $\phi_1$ remains unchanged if I also add $\phi_2$. This can be solved by using a smarter basis, which is the goal of Hartree-Fock. Hartree-Fock will, through an iterative method, change the single-particle states to get a better result. This can be viewed as incorporating the interaction as a \textit{mean field} approximation. 

	I will in this thesis present, and use, three \textit{post Hartree-Fock} methods. These are \textit{Full Configuration Interaction Theory}, \textit{Many-Body Perturbation Theory} and \textit{Coupled Cluster Theory}, where the latter is the main focus of my thesis. These methods aim to compute the \textit{Correlation Energy} as presented in the chapter on Second Quantization. It is common to first implement the Hartree-Fock method, providing the most precise reference energy. 

	\begin{section}{Full Configuration Interaction Theory}
		The first \textit{Post Hartree-Fock} method to be presented is the \textit{Full Configuration Interaction theory}. We expand the true wave function as a linear combination of the ground state ansatz and all possible excitations
		\begin{align}
			\left| \Psi \right> = C_0 \left| \Phi_0 \right> + \sum_{ai} C_i^a \left| \Phi_i^a \right> + \sum_{abij} C_{ij}^{ab} \left| \Phi_{ij}^{ab} \right> + ... 
		\end{align}
		Which can be rewritten in terms of a \textit{correlation operator}
		\begin{align}
			\left| \Psi \right> = ( C_0 + \hat C) \left| \Phi_0 \right> 
		\end{align}
		With
		\begin{align}
			\hat C = \sum_{ai} C_i^a \hat a^\dagger \hat i + \sum_{abij} C_{ij}^{ab} \hat a^\dagger \hat b^\dagger \hat j \hat i + ...
		\end{align}
		We can name the terms such that
		\begin{align}
			\hat C = \hat C_1 + \hat C_2 + ...
		\end{align}
		We use intermediate normalization, which set $C_0 = 1$, such that we get the relation
		\begin{align}
			\left< \Psi | \Phi_0 \right> = C_0 \left< \Phi_0 | \Phi_0 \right> = 1 
		\end{align}
		We can now rewrite $\left| \Psi \right>$
		\begin{align}
			\left| \Psi \right> = (1 + \hat C) \left| \Phi_0 \right> 
		\end{align}
		To simplify the notation, we can write the equation in terms of $P$ and $H$, which symbolizes all possible chains of creation and annihilation operators
		\begin{align}
			\left| \Psi \right> = \sum_{PH} C_H^P \left| \Phi_H^P \right> = \left( \sum_{PH} C_H^P \hat A_H^P \right) \left| \Phi_0 \right>  
		\end{align}
		We are working with orthonormal states, meaning that 
		\begin{align}
			\left< \Psi | \Psi \right> = \sum_{PH} \left| C_H^P \right|^2 = 1
		\end{align}
		The only thing left now, is defining how to compute the correlation energy. We write the expression for the energy as
		\begin{align}
			E = \left< \right. \Psi | \hat H | \Psi \left. \right> = \sum_{PHP'H'} (C^P_H)^* \left< \right. \Phi_H^P | \hat H | \Phi_{H'}^{P'} \left. \right> C_{H'}^{P'} 	
		\end{align} 
		
		\begin{subsection}{The Hamiltonian Matrix}
			We can build a Hamiltonian matrix consisting of all possible combinations of Slater determinants, i.e. all possible combinations of $P,H$ and $P',H'$. The matrix elements will be the expectation value for the Hamiltonian with respect to the given Slater determinants. 
			\begin{align}
				\hat{ \mathcal{H} } = \left(  \begin{matrix}
							& 0p - 0h & 1p - 1h & 2p - 2h & 3p - 3h & 4p-4h & ... & Np - Nh \\ 
					0p - 0h & x 	  & x 		& x 	  & 0 		& 0 	& 0	   & 0 		\\		
					1p - 1h & x 	  & x 		& x 	  & x  		& 0 	& 0    & 0 		\\
					2p - 2h & x 	  & x 		& x 	  & x  		& x		&\cdots& 0		\\
					3p - 3h & 0 	  & x 		& x 	  & x  		& x 	&\cdots& 0 		\\
					4p - 4h & 0		  & 0 		& x 	  & x 		& x 	&\cdots& 0		\\
					\vdots 	& 0  	  & 0 	    & \vdots  & \vdots  & \vdots&\ddots& \vdots \\
					Np - Nh & 0 	  & 0		& 0 	  & 0 		& 0		&\hdots& x
				\end{matrix} \right)
			\end{align}
			Above is an example of a general Hamiltonian matrix, $\mathcal{H}$, set up for a N-particles, N-holes, basis. One can notice that many matrix elements are zero. This is because the Hamiltonian only have a two-particle interaction term. If we have performed Hartree-Fock calculations, or start out with a Hartree-Fock basis, we have shifted the basis so that all matrix elements of the type
			\begin{align}
				\left< 0p-0h \right| \hat H \left| 1p-1h \right> = \left< 1p-1h \right| \hat H \left| 0p-0h \right> = 0
			\end{align}
			Giving us a shifted Hamiltonian matrix 
			\begin{align}
				\hat{ \mathcal{H} } = \left(  \begin{matrix}
							& 0p - 0h & 1p - 1h & 2p - 2h & 3p - 3h & 4p - 4h & ... & Np - Nh \\ 
					0p - 0h & \tilde x& 0       & \tilde x& 0 		& 0 	  & 0	 & 0 		\\		
					1p - 1h & 0 	  & \tilde x& \tilde x& \tilde x& 0 	  & 0    & 0 		\\
					2p - 2h & \tilde x& \tilde x& \tilde x& \tilde x& \tilde x&\cdots& 0		\\
					3p - 3h & 0 	  & \tilde x& \tilde x& \tilde x& \tilde x&\cdots& 0 		\\
					4p - 4h & 0		  & 0 		& \tilde x& \tilde x& \tilde x&\cdots& 0		\\
					... 	& 0  	  & 0 	    & \vdots  & \vdots  & \vdots  &\ddots& \vdots\\
					Np - Nh & 0 	  & 0		& 0 	  & 0 		& 0		  &\cdots& \tilde x
				\end{matrix} \right)
			\end{align}
			To find the ground state correlation energy, the normal procedure is to diagonalize the Hamiltonian matrix through computational algorithms. If we have a finite size Hilbert space, we can set up a finite Hamiltonian matrix which, when diagonalized, will provide us with the exact ground state correlation energy. 

			Unfortunatly, the Full Configuration Interaction Theory is very computationally costly. The Hamiltonian matrix will grow exponentially fast for large Hilbert spaces, which both increases the memory usage dramatically and increases the prosessing power associated with diagonalizing the matrix. For infinite and very large Hilbert spaces, one can truncate the number of excitations at some level to reduce the size of Hamiltonian matrix. I will later refer to this as just \textit{Configuration Interaction theory}. 
		\end{subsection}

		\begin{subsection}{Computational cost}
			As a brief example on how costly the full configuration interaction theory can be, we look at the nucleus of an oxygen atom. For a system consisting of $N$ states and $n$ particles, the total number of unique Slater determinants is given by \cite{MHJFCI}
			\begin{align}
				\binom{N}{n} = \frac{n!}{(n-N)!N!}
				\label{FCI1}
			\end{align}
			Looking at the Oxygen nucleus, we have $8$ protons and $8$ neutrons. If we only include the first major shells, 0s, 0p, 1s0d and 1p0f, we have a total of $40$ states that the neutrons and protons can occupy. Using (\ref{FCI1})
			\begin{align}
				\binom{40}{8} = \frac{40!}{32!8!} \approx 10^9
			\end{align}
			for both the protons and the neutrons. Multiplying them together, we get 
			\begin{align}
				10^9 10^9 = 10^{18}
			\end{align}
			Slater determinants for the whole system. This shows how fast the dimensionality explodes! 

		\end{subsection}

	\end{section}	

	\begin{section}{Many-body Perturbation Theory}
		The Perturbation theory presents a non-iterative approach to approximating the ground state energy. The approach is similar to previous methods. We start by splitting the Hamiltonian into a solvable part and a perturbation 
	 	\begin{align}
	 		\hat H = \hat H_0 + \hat V
	 	\end{align}
	 	Where we have chosen our basis such that
	 	\begin{align}
	 		\hat H_0 \left| \Psi_0 \right>  = W_0 \left| \Psi_0 \right>
	 	\end{align}
	 	We also split the basis
	 	\begin{align}
	 		\left| \Psi_0 \right> = \left| \Phi_0 \right> + \sum_i^{\infty} c_i \left| \phi_i \right>
	 	\end{align}
	 	Assuming intermediate normalization
	 	\begin{align}
	 		\left< \Phi_0 | \Psi_0 \right> = 1
	 	\end{align}
		We can calculate the total exact energy
	 	\begin{align}
	 		E = \left< \Phi_0 \right| \hat H_0 \left| \Psi_0 \right> + \left< \Phi_0 \right| \hat V \left| \Psi_0 \right>
	 	\end{align}
	 	Where we know that
	 	\begin{align}
	 		 \left< \Phi_0 \right| \hat H_0 \left| \Psi_0 \right>  = W_0
	 	\end{align}
	 	And we get the correlation energy
	 	\begin{align}
	 		E - W_0 = \Delta E = \left< \Phi_0 \right| \hat V \left| \Psi_0 \right>
	 	\end{align}
	 	We will usually aim to compute this energy when doing MBPT. 

	 	\begin{subsection}{General derivation of Many-Body Particle Theory equations}
	 		Looking at the equation
	 		\begin{align}
	 			\hat V \left| \Psi_0 \right> = \hat H \left| \Psi_0 \right> + \hat H_0 \left| \Psi_0 \right> 
	 		\end{align}
	 		We reorganize and add the term $\omega \left| \Psi_0 \right>$ on both sides
	 		\begin{align}
	 			\hat V \left| \Psi_0 \right> + \omega \left| \Psi_0 \right> - \hat H \left| \Psi_0 \right> = \omega \left| \Psi_0 \right> - \hat H_0 \left| \Psi_0 \right> 
	 		\end{align}
	 		Remembering that $\hat H \left| \Psi_0 \right> = E\left| \Psi_0 \right> $, we get 
	 		\begin{align}
	 			\left| \Psi_0 \right> = \frac{ \hat V + \omega - E }{\omega - \hat H_0} \left| \Psi_0 \right>
	 			\label{pert_1}
	 		\end{align}
	 		Before continuing, we introduce the operators $\hat P$ and $\hat Q$, such that
	 		\begin{align}
	 			\left| \Psi_0 \right> = \hat P \left| \Psi_0 \right> + \hat Q \left| \Psi_0 \right> 
	 			&= \left| \Phi_0 \right> \left< \Phi_0 \middle| \Psi_0 \right> + \sum_i \left| \Phi_i \right> \left< \Phi_i \middle| \Psi_0 \right> 
	 			\label{pert_2} \\
	 			&= \left| \Phi_0 \right> + \chi
	 		\end{align}
	 		Giving
	 		\begin{align}
	 			\left| \Phi_0 \right> = \hat P \left| \Psi_0 \right> \;\;\;\; \chi = \hat Q \left| \Psi_0 \right> 
	 			\label{pert_3}
	 		\end{align}
	 		Using $\hat R(\omega) = \frac{\hat{Q}}{\left( \omega - \hat H_0 \right)}$ and multiplying both sides with $\hat Q$ from the left in equation (\ref{pert_1}) we attain
	 		\begin{align}
	 			\hat Q \left| \Psi_0 \right> = \hat R(\omega) \left( \hat V + \omega - E \right) \left| \Psi_0 \right>
	 		\end{align}
	 		Using equations (\ref{pert_2}) and (\ref{pert_3}), we get
	 		\begin{align}
	 			\left| \Psi_0 \right> = \left| \Phi_0 \right> + \hat R(\omega) \left( \hat V + \omega - E \right) \left| \Psi_0 \right>
	 		\end{align}
	 		This is an iterative scheme. We can substitute $\left| \Psi_0 \right>$ on the right hand side with the entire right hand side. This results in an infinite sum provided the series converges
	 		\begin{align}
	 			\left| \Psi_0 \right> = \sum_0^\infty \left\{ \hat R(\omega) (\hat V + \omega - E) \right\}^m \left| \Phi_0 \right>
	 		\end{align}
	 		The right hand side does include the energy, $E$, which must be computed using $ E = W_0 + \Delta E$, and
	 		\begin{align}
	 			\Delta E = \left< \Phi_0 \right| \hat V \left| \Psi_0 \right> 
	 			= \sum_0^\infty \left< \Phi_0 \right| \hat V \left[ \hat R(\omega) (\hat V - E + \omega) \right]^m \left| \Phi_0 \right>  
	 		\end{align}
	 	\end{subsection}

	 	\begin{subsection}{Equations for Reileigh-Schr\"{o}dinger Perturbation Theory}
	 		We can interpret $\omega$ in different ways. I here present the Reileigh-Schr\"{o}dinger Perturbation Theory which postulates that
	 		\begin{align}
	 			\omega = E_0^{(0)}
	 		\end{align}
	 		Such that we get the expression for the resolvent
	 		\begin{align}
	 			\hat R_0 = \frac{\hat Q}{E_0^{0} - \hat H_0}
	 		\end{align}
	 		Giving
	 		\begin{align}
	 			\left| \Psi_0 \right> = \frac{ \hat V - \Delta E }{\omega - \hat H_0} \left| \Psi_0 \right>
	 		\end{align}
	 		and we get the final equation for the wave function 
	 		\begin{align}
	 			\left| \Psi_0 \right> = \sum_0^\infty \left\{ \hat R(\omega) (\hat V + - \Delta E) \right\}^m \left| \Phi_0 \right>
	 		\end{align}
	 		and for the correlation energy
	 		\begin{align}
	 			\Delta E = \sum_0^\infty \left< \Phi_0 \right| \hat V \left[ \hat R(\omega) (\hat V - \Delta E) \right]^m \left| \Phi_0 \right>  
	 		\end{align}
	 		Taking a closer look at the energy-equations, we find that we can write the first orders as
	 		\begin{align*}
	 			E^{(1)} &= \left< \Phi_0 \right| \hat V \left| \Phi_0 \right>  = V_{00}\\
	 			E^{(2)} &= \left< \Phi_0 \right| \hat V \hat R_0 \hat V \left| \Phi_0 \right> \\
	 			E^{(3)} &= \left< \Phi_0 \right| \hat V \hat R_0 (\hat V - E^{(1)})  \hat R_0 \hat V \left| \Phi_0 \right> \\
	 			E^{(4)} &= \left< \Phi_0 \right| \hat V \hat R_0 (\hat V - E^{(1)})  \hat R_0 (\hat V - E^{(1)}) \hat R_0 \hat V \left| \Phi_0 \right> 
	 					- E^{(2)} \left< \Phi_0 \right| \hat V \hat R_0^2 \hat V \left| \Phi_0 \right>
	  		\end{align*}
	  		Because of the frequent appearance, we can rewrite $\hat V - E^{(1)}$ as
	  		\begin{align}
	  			\hat \Omega = \hat V - E^{(1)} = \hat V - \left< \Phi_0 \right| \hat V \left| \Phi_0 \right>
	  		\end{align}
	  		We name this new variable the wave operator, and rewrite the equations in a simpler form. 
	  		\begin{align*}
	 			E^{(1)} &= \left< \Phi_0 \right| \hat V \left| \Phi_0 \right>  = V_{00}\\
	 			E^{(2)} &= \left< \Phi_0 \right| \hat V \hat R_0 \hat V \left| \Phi_0 \right> \\
	 			E^{(3)} &= \left< \Phi_0 \right| \hat V \hat R_0 \hat \Omega \hat R_0 \hat V \left| \Phi_0 \right> \\
	 			E^{(4)} &= \left< \Phi_0 \right| \hat V \hat R_0 \hat \Omega  \hat R_0 \hat \Omega \hat R_0 \hat V \left| \Phi_0 \right> 
	 					- E^{(2)} \left< \Phi_0 \right| \hat V \hat R_0^2 \hat V \left| \Phi_0 \right>
	 			\label{MBPT equations}
	  		\end{align*}
	  		I am, in this thesis, concerned with calculating the correlation energy, and these four equations will be implemented for the Pairing model. 
	 	\end{subsection}
	\end{section}

	\begin{section}{Linked Diagram theorem}
		The linked diagram theorem is an important theorem, presented by Goldstone in 1957 \cite{ShavittAndBartlett,Goldstone} which leads to the cancellation of all unlinked diagrams in Reileigh-Schr\"{o}dinger perturbation theory.

		The theorem states that the wave function and the energy can be expressed as a sum of linked diagrams \textit{only}. Reducing the equations to 
		\begin{align}
			E^{(n)} = \left< \right. | \hat W (\hat R_0 \hat W)^{n-1} \left. | \right>_L \\
			\left| \Psi^{(n)} \right> = \left[ (\hat R_0 \hat W)^n |\left.\right>  \right]_L
		\end{align}
		More specifically, we see that the second order term for $E^{(4)}$ in \ref{MBPT equations}, will vanish. 

	\end{section}

	\begin{section}{Hartree-Fock calculations}
 		When doing Hartree-Fock calculation, we conduct a change of the basis, and instead of expanding our Hamiltonian, we vary the wave function to minimize the energy. We name the original basis by greek letters and the new basis by latin letters. The original basis should be chosen such that we can calculate it's expectation value. 
 		\begin{align}
 			\left< \Phi_0 \right| \hat H \left| \Phi_0 \right> = E^{\text{HF}}
 		\end{align}
 		Variational principle ensures that 
 		\begin{align}
 			E^{\text{HF}} > 0 
 		\end{align}
 		We now introduce a change of basis 
 		\begin{align}
 			\left| \psi_a \right> = \sum_{\lambda} C_{a\lambda} \left| \psi_{\lambda} \right>
 		\end{align}
 		Varying $C_{p\lambda}$, we can look for the basis providing the lowest energy. We start by rewriting $E^{HF}$ as a functional
 		\begin{align}
 			E\left[ \psi \right] = \sum_{a=1}^N \left< a \right| h \left| a \right> + \frac{1}{2} \sum_{ab}^N \left< ab \right| v \left| ab \right>
  		\end{align}
  		In terms of the original greek basis
  		\begin{align}
  			E\left[ \psi \right] = \sum_{a=1}^N \sum_{\alpha \beta} C_{a \alpha}^* C_{a \beta} \left< \alpha \right| h \left| \beta \right> + \frac{1}{2} \sum_{ab}^N \sum_{\alpha \beta \gamma \delta} C_{a \alpha}^* C_{b \beta}^* C_{a \gamma} C_{b \delta} \left< \alpha \beta \right| v \left| \gamma \delta \right>
  		\end{align}
  		To find the minima, we introduce a Lagrange multiplier before differentiating with respect to $C_{a  \alpha}^*$. This will give N equations, one for each state, $a$. The equations are given by
  		\begin{align}
  			\sum_{\beta} C_{a \beta} \left< \alpha \right| h \left| \beta \right> + \sum_b^N \sum_{\beta \gamma \delta} C_{b \beta}^* C_{b \delta} C_{a \gamma} \left< \alpha \beta \right| v \left| \gamma \delta \right> = \epsilon_a C_{a \alpha}
  		\end{align}
  		Defining
  		\begin{align}
  			h_{\alpha \gamma}^{\text{HF}} = \left< \alpha \right| h \left| \gamma \right> + \sum_{b=1}^N \sum_{\beta \delta} C_{b \beta}^* C_{b \delta} \left< \alpha \beta \right| v \left| \gamma \delta \right> 
  		\end{align}
  		We get the short hand iterative equations to be solved 
  		\begin{align}
  			\sum_{\gamma} h_{\alpha \gamma}^{\text{HF}} C_{a \gamma} = \epsilon_{a} C_{a \alpha}
  		\end{align}
 	\end{section}

\end{chapter}



\begin{chapter}{Coupled-Cluster Theory} 
	Coupled-cluster theory is similar to full configuration interaction theory. Coupled-cluster theory is a post-Hartree-Fock method, so we set up an ansatz for the ground state wave function, $\left| \Phi_0 \right>$. One can, for the best results, optimize this basis by the use of Hartree-Fock method. The goal of Coupled-cluster theory is to improve the ansatz by including a set of excitations. Coester and Kummel initially developed the ideas that led to the coupled-cluster theory in the late 1950's \cite{MHJonline}. 
 	
 	\begin{section}{The Exponential Ansatz}
 		The basic idea of Coupled-cluster theory is to express the true wave function as an exponential operator working on the Slater determinant \cite{ShavittAndBartlett,MHJonline,Crawford}
 		\begin{align}
	 		\ket{\Psi} \approx e^{\hat T} \ket{\Phi_0}
	  	\end{align}
	  	The operator $\hat T$, is a sum of the excitation operators, also known as cluster operators
	  	\begin{align}
	  		\hat T = \hat T_1 + \hat T_2 + \hat T_3 + ... + \hat T_N
	  	\end{align}
	  	Where the operators are defined as
	  	\begin{align}
	  		T_1 &= \sum_{ia} t_i^a \hat a_a^{\dagger} \hat a_i \\
	  		T_2 &= \frac{1}{2} \sum_{ijab} t_{ij}^{ab} \hat a_a^{\dagger}\hat a_b^{\dagger} \hat a_j \hat a_i \\
	  		T_N &= \left(\frac{1}{n!}\right)^2 \sum_{ij..ab..}^n t_{ij..n}^{ab..n} \hat a_a^{\dagger}\hat a_b^{\dagger} ...\hat a_n^{\dagger} \hat a_n ... \hat a_j \hat a_i \\
	  	\end{align}
	  	Which is very similar to configuration interaction theory.
	\end{section}

	\begin{section}{Comparison with Configuration Interaction}
	  	By doing an expansion of the exponential operator, we can rewrite it as
	  	\begin{align}
	  		e^{\hat T} = 1 + \hat T + \frac{\hat T^2}{2!} + \frac{\hat T^3}{3!} + \cdots
	  	\end{align}
	  	Calculating the terms and organizing them in terms of total excitations, we can write the exponential operator as 
	  	\begin{align}
	  		e^{\hat T} = \left( 1 \right)  + \left( \hat T_1 \right) + \left( \hat T_2 + \frac{\hat T_1^2}{2} \right) + \left( \hat T_3 + \hat T_1 \hat T_2 + \frac{\hat T_1^3}{6} \right) + \cdots 
	  	\end{align}	
	  	
	  	Remembering the equations for configuration interaction
	  	\begin{align}
	  		\ket{\Psi_{CI}} = (1 + \hat C) \ket{\Phi_0} 
	   	\end{align}
	   	Where
	  	\begin{align}
	  		\hat C = \hat C_1 + \hat C_2 + ... =  \sum_{ia} c_i^a a_a^{\dagger} a_i + \frac{1}{4} \sum_{ijab} c_{ij}^{ab} a_a^{\dagger} a_b^{\dagger} a_j a_i + ...
	   	\end{align}
	   	By comparing configuration interaction with coupled-cluster theory, we see that we can write
	   	\begin{align}
	   		\hat C_0 = 1 \:\:\:\:\:\:\: \hat C_1 = \hat T_1 
	   	\end{align}
	   	\begin{align}
	   		\hat C_2 = \hat T_2 + \frac{1}{2} T_1^2
	   	\end{align}
	   	and 
	   	\begin{align}
	   		\hat C_3 = \hat T_3 + \hat T_1 \hat T_2 + \frac{\hat T_1^3}{6}
	   	\end{align}
	   	The difference we notice, is that coupled-cluster introduces a mixing of excitation operators for every level of total excitations. 
 	\end{section}

	\begin{section}{Truncating the Exponential Ansatz}
	  	By including infinite terms, this expansion will represent the true wave function, but the equations cannot be computed unless they are truncated at some point. 
	  	\begin{enumerate}
	  		\item By including only $\hat T = \hat T_1$, we are doing coupled-cluster singles, or CCS
	  		\item By truncating the equations at double excitations, $\hat T = \hat T_1 + \hat T_2$, we are doing coupled-cluster singles and doubles, or CCSD
	  		\item By truncating the equations at triple excitations, $\hat T = \hat T_1 + \hat T_2 + \hat T_3$, we are doing coupled-cluster singles, doubles and 		triples, or CCSDT 
	  		\item four excitations are called quadruples, and so on
	  	\end{enumerate}

	  	We introduce a new operator, given as 
	  	\begin{align}
	  		\overline H = e^{-\hat T} \hat H e^{\hat T} 
	  	\end{align}
	  	When calculating the energy, we look at the expectation value for the Hamiltonian 
	  	\begin{align}
	  		\left< \Phi_0 \right| e^{-\hat T} \hat H e^{\hat T} \left| \Phi_0 \right> = \left< \Phi_0 \right| \overline H \left| \Phi_0 \right> = E
	  	\end{align}
	  	By subsequent left-projection of various excited states, we get amplitude equations
	  	\begin{align}
	  		\left< \Phi_{ij\cdots}^{ab\cdots} \right| \overline H \left| \Phi_0 \right> = E
	  	\end{align}
	  	We have now decoupled the amplitude equations from the energy equations, reducing the complexity of a coupled-cluster solver. The energy-equation is a function of the amplitudes $t_i, t_j, \cdots$ and $t_a, t_b, \cdots$, which can now be found through a different set of iterative equations. We have introduced the similarity transformed Hamiltonian, which can be significantly simplified using the Baker-Campbell-Hausdorff formula \cite{Crawford}
	  	\begin{align}
	  		\overline H = e^{-\hat T} \hat H e^{\hat T} =& \hat H + [ \hat H, \hat T] + \frac{1}{2!} [[\hat H, \hat T], \hat T] \\ + &\frac{1}{3!} [[[ \hat H, \hat T ], \hat T ], \hat T ] + \frac{1}{4!} [[[[\hat H, \hat T], \hat T], \hat T], \hat T] + \cdots \nonumber
	  	\end{align}
	  	At first glance, this equation does not look like a simplification, but based on properties on the system, we can truncate this expansion. The cluster operators, $\hat T_1, \hat T_2, \hat T_3, \cdots$ commute with each other, but they do not generally commute with the Hamiltonian operator. Consider the general commutation of the one-body Hamiltonian and the $T_1$ cluster operator
	  	\begin{align}
	  		[\hat H_0, \hat T_1] = [\hat p^\dagger \hat q, \hat a^\dagger \hat i] = \hat p^\dagger \hat q \hat a^\dagger \hat i - \hat a^\dagger \hat i \hat p^\dagger \hat q
	  	\end{align}
	  	We can use the anti-commutator relations to rewrite two terms on the right-hand side
	  	\begin{align}
	  		\hat p^\dagger \delta_{qa} \hat i - \hat a^\dagger \delta_{ip} \hat q
	  	\end{align}
	  	Because $p$ and $q$ is the sum of all possible states, not limited to virtual or occupied states, we cannot explicitly state that the Kronecker delta functions $\delta_{qa}$ or $\delta_{ip}$ are either $0$ or $1$. 

	  	Because the cluster operators commute, to get a non-zero result, the Hamiltonian must create one Kronecker-delta function for each of the participating cluster operators. For every system in this thesis, we are only working with a two-body Hamiltonian, so a commutation with more than four cluster operators must provide zero. We will get a natural truncation, that holds for both the energy and amplitude equations. This is true for all systems that have a two-body Hamiltonian. We now write the similarity transformed Hamiltonian as
	  	\begin{align}
	  		\overline H = e^{-\hat T} \hat H e^{\hat T} = \hat H &+ [ \hat H, \hat T] + \frac{1}{2!} [[\hat H, \hat T], \hat T] + \frac{1}{3!} [[[ \hat H, \hat T ], \hat T ], \hat T ] \\  &+ \frac{1}{4!} [[[[\hat H, \hat T], \hat T], \hat T], \hat T] \nonumber
	  	\end{align}

	\end{section}  	

	\begin{section}{The Variational Principle}
		Using a variational method comes with great advantages. One can be sure to have calculated an upper boundary to the energy, but the coupled-cluster energy equation do not conform to any variational conditions \cite{Crawford}. However, the exponential ansatz does allow for another way of setting up the energy equation
		\begin{align}
			E_{\text{exact}} \leq E = \frac{\left< \Phi_0 \right| (e^{\hat T})^\dagger \hat H e^{\hat T} \left| \Phi_0 \right>}{\left< \Phi_0 \right| (e^{\hat T})^\dagger \hat H e^{\hat T} \left| \Phi_0 \right>} = \frac{\left< \Psi \right| \hat H \left| \Psi \right>}{\left< \Psi \right| \hat H \left| \Psi \right>}
		\end{align}
		Which is variational. Unfortunatly, this equation do not have a natural truncation, and will be much more difficult to solve. 
	\end{section}

  	\begin{section}{Size-Extensivity}
  		It can be important to have a wave function that scales with size. Imagine two particles, $X$ and $Y$, with infinite separation, meaning that they do not interact. This means we should be able to write the total energy as
  		\begin{align}
  			E = E_X + E_Y
  		\end{align}
  		Rewriting the cluster operators in terms of the two particles
  		\begin{align}
  			\hat T = \hat T_X + \hat T_Y 
  		\end{align}
  		The wave function can be rewritten as 
  		\begin{align}
  			\ket{\Psi}_{CC} = e^{\hat T_X + \hat T_Y} \ket{\Phi_0} = e^{\hat T_X} e^{\hat T_Y} \ket{\Psi_0}
  		\end{align}
  		Since we can write the reference state as a product of the two seperated parts, we are able to write
  		\begin{align}
  			E_{CC} = E_{CC}^X + E_{CC}^Y
  		\end{align}
  		For Configuration Interaction, multiplicative separability is not possible
  		\begin{align}
  			\Psi_{CI} = \left(1 + \hat C\right) \Phi_0 = \left( 1 + \hat C_x + \hat C_y \right) \Phi_0
  		\end{align}
  		Which cannot be rewritten as two separable parts. This means the coupled-cluster theory produces a \textit{size-extensive} energy, contrary to full configuration interaction. A size-extensive system will scale perfectly with the size of the system, regardless of the interaction between the particles.

  	\end{section}

  	\begin{section}{The Coupled-Cluster Doubles Equations}
  		We need to truncate the cluster operator, $\hat T$, and the approximation used in this thesis, is to only allow 2p-2h excitations. This is normally referred to as the coupled-cluster doubles equations, or CCD. We can rewrite the operator as \cite{MHJonline}
  		\begin{align}
  			\hat T \approx \hat T_2
  		\end{align}
  		The wave function will be approximated by 
  		\begin{align}
  			\left| \Psi_0 \right> \approx \left| \Psi_{\text{CCD}} \right> = e^{\hat T_2} \left| \Phi_0 \right>
  		\end{align}
  		Inserting this ansatz into the Hamiltonian expectation value, we get
  		\begin{align}
  			\left< \Phi_0 \right| e^{-\hat T_2} \hat H e^{\hat T_2} \left| \Phi_0 \right> 
  		\end{align}
  		Which will have the natural truncation at 
  		\begin{align}
  			\left< \Phi_0 \right|  \hat H (1 + \hat T_2) \left| \Phi_0 \right> = E_{\text{CCD}}
  		\end{align}
  		Leading up to the energy equation
  		\begin{align}
  			E_{\text{CCD}} = E_{\text{ref}} + \frac{1}{4} \sum_{abij} \left<ij|\hat v|ab\right> t_{ij}^{ab}
  		\end{align}
  		With the reference energy defined as 
  		\begin{align}
  			E_{ref} = \sum_i \left< i \right| \hat h_0 \left| j\right> + \sum_{ij} \left<ij\middle|\hat v\middle|ij\right> + \frac{1}{2}Av_0
  		\end{align}
  		$v_0$ is a constant, nonzero for the finite electron gas. The second part of the energy, is known as the correlation energy. It is given by
  		\begin{align}
  			\Delta E_{CCD} = \frac{1}{4} \sum_{ijab}\left<ij\middle|\hat v\middle|ab\right> t_{ij}^{ab}
  		\end{align}
  		The computation of this correlation energy is the goal of the coupled-cluster theory. This is dependent on the amplitudes $t_{ij}^{ab}$, so we need the amplitude equations, found by
  		\begin{align}
  			\left< \Phi_{ij}^{ab} \right| x^{-\hat T_2} \hat H_N e^{\hat T_2} \left| \Phi_0 \right> = 0
  		\end{align}
  		After several applications of Wick's theorem, the amplitude equations can be reduced to 
  		\begin{align}
  			(\epsilon_i + \epsilon_j - \epsilon_a - \epsilon_b) t_{ij}^{ab} = \left<ab\middle|\hat v\middle|ij\right> + \frac{1}{2} \sum_{cd}\left<ab\middle|\hat v\middle|cd\right>t_{ij}^{cd} \\
  			+ \frac{1}{2} \sum_{kl} \left<kl\middle|\hat v\middle|ij\right>t_{kl}^{ab} + \hat P\left(ij\middle|ab\right) \sum_{kc}\left<kb\middle|\hat v\middle|cj\right>t_{ik}^{ac} \\
  			+ \frac{1}{4} \sum_{klcd}\left<kl\middle|\hat v\middle|cd\right>t_{ij}^{cd} t_{kl}^{ab} + \frac{1}{2} \hat P\left(ij\middle|ab\right) \sum_{klcd}\left<kl\middle|\hat v\middle|cd\right>t_{ik}^{ac} t_{lj}^{db}\\
  			- \frac{1}{2}\hat P(ij) \sum_{klcd}\left<kl\middle|\hat v\middle|cd\right>t_{ik}^{ab} t_{jl}^{cd} - \frac{1}{2}\hat P(ab) \sum_{klcd}\left<kl\middle|\hat v\middle|cd\right>t_{kl}^{bd} t_{ij}^{ac}
  			\label{CCD_equations1}
  		\end{align}
  		Where we have defined
  		\begin{align}
  			\hat P(ij) = 1 - \hat P_{ij}
  		\end{align}
  		Where $\hat P_{ij}$ interchanges the two particles occupying the quantum states $i$ and $j$. Furthermore, we define the operator 
  		\begin{align}
  			\hat P\left( ij \middle| ab \right) = (1 - \hat P_{ij}) (1 - \hat P_{ab})
  		\end{align}
  		We notice that some parts are linear in the amplitude, while some are quadratic. Sorting them into the linear and quadratic parts, $L$ and $Q$ respectably, I get
  		\begin{align}
  			L(t_{ij}^{ab}) = \frac{1}{2} \sum_{cd}\left<ab\middle|\hat v\middle|cd\right>t_{ij}^{cd} + \frac{1}{2} \sum_{kl} \left<kl\middle|\hat v\middle|ij\right>t_{kl}^{ab} + \hat P\left(ij\middle|ab\right) \sum_{kc}\left<kb\middle|\hat v\middle|cj\right>t_{ik}^{ac}
  		\end{align}
  		and 
  		\begin{align}
  			Q(t_{ij}^{ab}t_{ij}^{ab}) = \frac{1}{4} \sum_{klcd}\left<kl\middle|\hat v\middle|cd\right>t_{ij}^{cd} t_{kl}^{ab} + \frac{1}{2} \hat P\left(ij\middle|ab\right) \sum_{klcd}\left<kl\middle|\hat v\middle|cd\right>t_{ik}^{ac} t_{lj}^{db} \\
  			- \frac{1}{2}\hat P(ij) \sum_{klcd}\left<kl\middle|\hat v\middle|cd\right>t_{ik}^{ab} t_{jl}^{cd} - \frac{1}{2}\hat P(ab) \sum_{klcd}\left<kl\middle|\hat v\middle|cd\right>t_{kl}^{bd} t_{ij}^{ac}
  		\end{align}
  		Labeling each term for practical reasons	
  		\begin{align}
  			L_a &= \frac{1}{2} \sum_{cd}\left<ab\middle|\hat v\middle|cd\right>t_{ij}^{cd} \\
  			L_b &= \frac{1}{2} \sum_{kl} \left<kl\middle|\hat v\middle|ij\right>t_{kl}^{ab} \\
  			L_c &= \hat P\left(ij\middle|ab\right) \sum_{kc}\left<kb\middle|\hat v\middle|cj\right>t_{ik}^{ac} \\
  			Q_a &= \frac{1}{4} \sum_{klcd}\left<kl\middle|\hat v\middle|cd\right>t_{ij}^{cd} t_{kl}^{ab} \\
  			Q_b &= \frac{1}{2} \hat P\left(ij\middle|ab\right) \sum_{klcd}\left<kl\middle|\hat v\middle|cd\right>t_{ik}^{ac} t_{lj}^{db} \\
  			Q_c &= - \frac{1}{2}\hat P(ij) \sum_{klcd}\left<kl\middle|\hat v\middle|cd\right>t_{ik}^{ab} t_{jl}^{cd} \\
  			Q_d &= - \frac{1}{2}\hat P(ab) \sum_{klcd}\left<kl\middle|\hat v\middle|cd\right>t_{kl}^{bd} t_{ij}^{ac}
  		\end{align}
   	\end{section}
   	\newpage
  	\begin{section}{Intermediates}
  		As coupled-cluster computations consume large amounts of computational power, researchers are spending much effort trying to reduce computational cost. One way of reducing the cost is by refactoring the amplitude equations such that we can perform an intermediate computation first and use the result to compute various diagrams later. 

  		Rewriting the equation, (\ref{CCD_equations1}) for CCD amplitudes \cite{Baardsen,Audun}:
  		\begin{align}
  			(\epsilon_i + \epsilon_j - \epsilon_a - \epsilon_b) t_{ij}^{ab} = \left<ab\middle|\hat v\middle|ij\right> + \frac{1}{2} \sum_{cd}\left<ab\middle|\hat v\middle|cd\right>t_{ij}^{cd} \\
  			+ \frac{1}{2} \sum_{kl} t_{kl}^{ab} \left[ \left<kl\middle|\hat v\middle|ij\right> + \frac{1}{2} \sum_{cd} \left<kl\middle|\hat v\middle|cd\right> t_{ij}^{cd} \right] \\
  			+ \hat P\left(ij\middle|ab\right) \sum_{kc} t_{ik}^{ac} \left[ \left<kb\middle|\hat v\middle|cj\right> + \frac{1}{2}\sum_{ld}\left<kl\middle|\hat v\middle|cd\right>t_{lj}^{db} \right] \\
  			- \frac{1}{2} \hat P(ij) \sum_{k} t_{ik}^{ab} \left[ \sum_{lcd} \left<kl\middle|\hat v\middle|cd\right> t_{jl}^{cd} \right] \\
  			- \frac{1}{2} \hat P(ab) \sum_{c} t_{ij}^{ac} \left[ \sum_{kld} \left<kl\middle|\hat v\middle|cd\right> t_{kl}^{bd} \right]
  		\end{align}
  		We can now define, and precompute the following values
  		\begin{align}
  			I_1 = \left<kl\middle|\hat v\middle|ij\right> + \frac{1}{2} \sum_{cd} \left<kl\middle|\hat v\middle|cd\right> t_{ij}^{cd} \\
  			I_2 = \left<kb\middle|\hat v\middle|cj\right> + \frac{1}{2}\sum_{ld}\left<kl\middle|\hat v\middle|cd\right>t_{lj}^{db} \\
  			I_3 = \sum_{lcd} \left<kl\middle|\hat v\middle|cd\right> t_{jl}^{cd} \\
  			I_4 = \sum_{kld} \left<kl\middle|\hat v\middle|cd\right> t_{kl}^{bd}
  		\end{align}
  		We can now redefine the CCD equation 
  		\begin{align}
  			(\epsilon_i + \epsilon_j - \epsilon_a - \epsilon_b) t_{ij}^{ab} = \left<ab\middle|\hat v\middle|ij\right> + \frac{1}{2} \sum_{cd}\left<ab\middle|\hat v\middle|cd\right>t_{ij}^{cd} + \frac{1}{2} \sum_{kl} t_{kl}^{ab} I_1 \\
  			+ \hat P\left(ij\middle|ab\right) \sum_{kc} t_{ik}^{ac} I_2 - \frac{1}{2} \hat P(ij) \sum_{k} t_{ik}^{ab} I_3  - \frac{1}{2} \hat P(ab) \sum_{c} t_{ij}^{ac} I_4
  			\label{Intermediates}
  		\end{align}
  		By doing the intermediate calculations, we can achieve a reduction of computational cost from $\mathcal{O}(h^4 p^4)$ to $\mathcal{O}(h^4 p^2)$, which is significant for large systems approaching the thermodynamic limit. However, storing the intermediate values will require a greater use of memory. 

  	\end{section}

\end{chapter}



\begin{chapter}{The Pairing Model}
	The first system I looked at is the pairing model. I have implemented a Pairing model consisting of four energy levels with degeneracy two, one for positive and negative spin. The system consisted of four electrons, filling up the four lower-most states up to the Fermi level. 
	\begin{figure}[h]
		\includegraphics[width=\textwidth]{Figures/Pairing_model.pdf}
		\label{PairingModel_1}
		\caption{A figure depicting a 4 particles-4 holes state. The system consists of occupied particle states below the Fermi level and unoccupied hole states above Fermi level.}
	\end{figure}
	
	\begin{section}{The Hamiltonian}
		We limit ourselves to a two-body interaction, writing the Hamiltonian as
		\begin{align}
			\hat H = \sum_{\alpha \beta} \left< \alpha \right| \hat h_0 \left| \beta \right> \hat a_{\alpha}^{\dagger} \hat a_{\beta} 
			        + \frac{1}{4} \sum_{\alpha \beta \gamma \delta} \left< \alpha \beta \middle| \hat v_0 \middle| \gamma \delta \right> \hat a_{\alpha}^{\dagger} \hat a_{\beta}^{\dagger} \hat a_{\delta} \hat a_{\gamma}
		\end{align}
		We use the complete basis $\left| \alpha \right>$ and define the set as eigenvalues of the one-body operator, $\hat h_0$. 
		
		The system does require that the total spin is equal to $0$. In addition we will not allow spin pairs to be broken, i.e.\  singly excitated states are not allowed. 
		\begin{align}
			\left| \Psi_i^a \right> = 0 
		\end{align}	
		We introduce the double creation and annihilation operator. 
		\begin{align}
			\hat P_{pq}^{\dagger} = \hat a_{p \sigma}^{\dagger} \hat a_{p -\sigma}^{\dagger}
		\end{align}
		\begin{align}
			\hat P_{pq} =  a_{q \sigma} a_{q -\sigma}
		\end{align}

		We can rewrite the Hamiltonian as an unperterturbed part and a perturbation
		\begin{align}
			\hat H = \hat H_0 + \hat V
		\end{align}
		\begin{align}
			\hat H_0 = \xi \sum_{p \sigma} (p-1) \hat a_{p \sigma}^{\dagger} \hat a_{p \sigma}
		\end{align}
		\begin{align}
			\hat V = - \frac{1}{2}g \sum_{pq} \hat a_{p +}^{\dagger} \hat a_{p-}^{\dagger} \hat a_{q-} \hat a_{q+}
		\end{align}
		The value of $\xi$ determines the spacing between the energy levels, which I have set to $1$. This will not impact the insight attained solving this system. $p$ and $q$ determines the energy level. $\sigma$ is the spin, with value either $+\frac{1}{2}$ or $-\frac{1}{2}$. Both the unperturbed and perturbed Hamiltonian keeps total spin at $0$.

		We can normal order the Hamiltonian by Wick's general theorem. 
		\begin{align}
			a_p^{\dagger} a_q = \left\{ a_p^{\dagger}a_q \right\} + \delta_{pq \in i}
		\end{align}
		\begin{align}
			a_p^{\dagger} a_q^{\dagger} a_s a_r = \left\{ a_p^{\dagger}a_q^{\dagger} a_s a_r \right\} +\left\{a_p^{\dagger}a_r\right\} \delta_{qs\in i} - \left\{a_p^{\dagger}a_s\right\} \delta_{qr\in i} \\
			+\left\{a_q^{\dagger}a_s\right\} \delta_{pr\in i} \
			- \left\{a_q^{\dagger}a_r\right\} \delta_{ps\in i} + \delta_{pr \in i} \delta_{qs \in i} - \delta_{ps \in i}\delta_{qr \in i}
		\end{align}
		Which gives the Normal-ordered Hamiltonian
		\begin{align}
			\hat H = \hat H_N + E_{ref}
		\end{align}
		\begin{align}
			\hat H_N = \hat F_N + \hat W 
		\end{align}
		\begin{align}
			\hat F_N =  \sum_{pq} h_{pq} \left\{ \hat a_{p \sigma}^{\dagger} \hat a_{p \sigma} \right\}
			- \sum_{pqi} \left< pi || qi \right> \left\{ \hat a_{p +}^{\dagger} \hat a_{q -} \right\}
		\end{align}
		\begin{align}
			\hat W = - \frac{1}{2} \sum_{pqrs} \left< pq || rs \right> \left\{ \hat a_{p +}^{\dagger} \hat a_{p-}^{\dagger} \hat a_{q-} \hat a_{q+} \right\}
		\end{align}
		\begin{align}
 			E_{ref} = \sum_{i} h_{ii} + \frac{1}{2} \sum_{ij} \left< ij \middle| \middle| ij \right>
		\end{align}

	\end{section}

	\newpage

	\begin{section}{Configuration Interaction theory}
		This system is a good way to benchmark various methods as we can compute the exact solution using Full Configuration Interaction. 

		\begin{figure}[H]
			\includegraphics[width=1.1\linewidth]{Figures/Pairing_model2.pdf}
			\label{PairingModel_2}
			\caption{Configuration space for given pairing model showing all possible distributions of electrons}
		\end{figure}

	 	We need to diagonalize the Hamiltonian matrix looking at the linear combination of all different combinations of 
		\begin{align}
			\hat{ \mathcal{H} } = \left(  \begin{matrix}
				& \left| \Phi_0 \right> & \left| \Phi_{12}^{56} \right> & \left| \Phi_{12}^{78} \right> & \left| \Phi_{34}^{56} \right> & \left| \Phi_{34}^{78} \right> & \left| \Phi_{1234}^{5678} \right> \\ 
				\left< \Phi_0 \right| &   &   &   &   &   & \\
				\left< \Phi_{12}^{56} \right| &   &   &   &   &   & \\
				\left< \Phi_{12}^{78} \right| &   &   &   &   &   & \\
				\left< \Phi_{34}^{56} \right| &   &   &   &   &   & \\
				\left< \Phi_{34}^{78} \right| &   &   &   &   &   & \\
				\left< \Phi_{1234}^{5678} \right| &   &   &   &   &   & 
			\end{matrix} \right)
		\end{align}

		Excluding the 4p-4h excitations one does not diagonalize the exact matrix, but rather the approximated matrix known from Configuration Interaction. 

		The diagonal elements are calculated using Wick's theorem. Looking first at the ground state calculation with the unperturbed Hamiltonian part
		\begin{align}
			\left< \Phi_0 \middle| \hat{\mathbf{H_0}} \middle| \Phi_0 \right> 
		\end{align}
		\begin{align}
			\left< \right|  a_{2 \downarrow}  a_{2 \uparrow} a_{1 \downarrow} a_{1 \uparrow} \sum_{p \sigma} \delta (p-1) a_{p \sigma}^{\dagger} a_{p \sigma} 
			a_{1 \uparrow}^{\dagger} a_{1 \downarrow}^{\dagger} a_{2 \uparrow}^{\dagger} a_{2 \downarrow}^{\dagger} \left| \right> 
		\end{align}
		Which we see can contract in four different ways, resulting in 
		\begin{align}
			2 \delta (1-1) + 2 \delta (2-1) = 2 \delta
		\end{align}

		And the perturbation part
		\begin{align}
			\left< \Phi_0 \middle| \hat{\mathbf{V}} \middle| \Phi_0 \right>
		\end{align}
		\begin{align}
			\left< \right| a_{2 \downarrow}  a_{2 \uparrow} a_{1 \downarrow} a_{1 \uparrow} \left( -g / 2 \sum_{pq} a_{p \uparrow}^{\dagger} a_{q \downarrow}^{\dagger} a_{q \downarrow} a_{p \uparrow} \right) 
			a_{1 \uparrow}^{\dagger} a_{1 \downarrow}^{\dagger} a_{2 \uparrow}^{\dagger} a_{2 \downarrow}^{\dagger} \left| \right> 
		\end{align}
		As we can see, there are two ways this can contract, each contributing with the constant factor, $-g / 2$
		Resulting in the final Hamiltonian matrix 
		\begin{align}
			\hat{\mathcal{H}} = \left( \begin{matrix}
				2 \delta - g & -g / 2 & -g / 2 & -g / 2 & -g / 2 & 0  \\
				-g / 2 & 4 \delta - g & -g / 2 & -g / 2 & 0 & -g / 2  \\
				-g / 2 & -g / 2 & 6 \delta - g & 0 & -g / 2 & -g / 2 \\
				-g / 2 & -g / 2 & 0 & 6 \delta - g & -g / 2 & -g / 2 \\
				-g / 2 & 0 & -g / 2 & -g / 2 & 8 \delta - g & -g / 2 \\
				0 & -g / 2 & -g / 2 & -g / 2 & -g / 2 & 10 \delta - g 
			\end{matrix} \right)
		\end{align}

	\end{section}

	\begin{section}{Hartree-Fock calculations}
		When doing Hartree-Fock calculations on the pairing model, the goal is to minimize the Hamiltonian expectation value through a change in basis. The ground state energy is given by 
		\begin{align}
			\left< \Phi_0 \right| \hat H \left| \Phi_0 \right> = E^{\text{HF}}
		\end{align}
		This leads to the iterative equation 
		\begin{align}
  			\sum_{\gamma} h_{\alpha \gamma}^{\text{HF}} C_{a \gamma} = \epsilon_{a} C_{a \alpha}
  		\end{align}
  		where 
  		\begin{align}
  			h_{\alpha \gamma}^{\text{HF}} = \left< \alpha \right| h \left| \gamma \right> + \sum_{b=1}^N \sum_{\beta \delta} C_{b \beta}^* C_{b \delta} \left< \alpha \beta \right| v \left| \gamma \delta \right> 
  		\end{align}
  		For the first iteration, we must make a guess on the factors, $C_{b \beta}^*$ and $C_{b \delta}$. A natural starting point is to set
  		\begin{align}
  			C_{b \beta} = \delta_{b \beta} \:\:\:\:\:\: C_{b \delta} = \delta_{b \delta}
  		\end{align}
  		This is the same as using the original basis in the first iteration, as there is no overlap between the states
  		\begin{align}
  			\left| \psi_a \right> = \sum_ \lambda \delta_{a \lambda} \left| \psi_ \lambda \right> 
  		\end{align}
  		To evaluate the Hartree-Fock matrix elements, we look at the states below Fermi level 
  		\begin{align}
  			\{p, \sigma\} \in \{ 1 \uparrow, 1 \downarrow, 2 \uparrow, 2 \downarrow \}
  		\end{align}
  		The greek basis will therefore loop over these four states. The one-electron operator $\hat H_0$ is diagonal, so the matrix element
  		\begin{align}
  			\left< \alpha | h | \gamma \right> 
  		\end{align}
 		Will also be diagonal. Because of the starting point for the basis coefficients, we see that the two-electron operator can be written as
 		\begin{align}
 			V = \sum_{ b = 1 }^4 \left< \alpha b | v | \gamma b \right>  
 		\end{align}
 		Because the pairing model does not allow broken pairs, this matrix element will only be non-zero when $\alpha = \gamma$ and when $p_{\alpha} = p_{b}$, $\sigma_ \alpha = \sigma_b$. The Hartree-Fock matrix will therefore be diagonal, meaning the original basis is a canonical Hartree-Fock basis. Hartree-Fock calculations on this basis will not provide any new results. The Hartree-Fock energy can be calculated
 		\begin{align}
 			E^{\text{HF}} = \left< \Phi_0 \right| \hat H \left| \Phi_0 \right> &= \left< \Phi_0 \right| \hat H_0 \left| \Phi_0 \right> + \left< \Phi_0 \right| \hat V \left| \Phi_0 \right> \\
 			&= 2 - g 
 		\end{align}
 		This energy will be referred to as the reference energy. 
 	\end{section}

	\begin{section}{Many-Body Perturbation Theory}
 		When setting up the perturbation theory equations, it is useful to present them as diagrams. All the diagrams for the first, second and third order perturbation theory are presented and translated to equations in this section. 
 		
		Because of special properties of the Pairing model, many of these diagrams can be removed by a visual examination. First, we have no broken pairs, meaning that a general two-body matrix element 
		\begin{align}
			\left< pq | v | rs \right> 
		\end{align}
		is only non-zero if \textit{both} $p$ and $q$ are hole states or \textit{both} are particle states. The same restriction applies to $r$ and $s$. The second thing to notice, is that we have a canonical Hartree-Fock. That means only diagonal one-body matrix elements are non-zero. We will compute the correlation energy $\Delta E$, using the Hamiltonian
		\begin{align}
			\hat H_N = \hat F_N^d + \hat F_N^o + \hat W = \hat F_N^d + \hat W
		\end{align}
		where
		\begin{align}
			f_{pq} = \epsilon_p \delta_{pq}
		\end{align}
 		\begin{figure}[H]
			\includegraphics[width=\textwidth]{Figures/FirstSecondThirdOrder.pdf}
			\caption{Diagrams for Many-Body Perturbation theory to second and third order. }
			\label{figure:mbpt23}
		\end{figure}

		\begin{subsection}{Interpreting diagrams}
			When reading the diagrams, and connecting them to the equations presented in the equations (\ref{MBPT equations}), there are a simple set of rules. We have the expression for the resolvent, $\hat R_0$ given as 
			\begin{align}
				\hat R_0 = \frac{\hat Q}{E_0^{(0)} - \hat H_0} = \sum_I \frac{\left| \Phi_I \right> \left< \Phi_I \right| }{E_0^{(0)} - E_I^{(0)}}
			\end{align}
			Where we sum over all states apart from $\left| \Phi_0 \right>$. When this operator operates on any state $\left| J \right>$ other than $\left| \Phi_0 \right> $, it will only produce \cite{ShavittAndBartlett}
			\begin{align}
				\hat R_0 \left| J \right> = \left| J \right> \frac{1}{E_0^{(0)} - E_J^{(0)}}
			\end{align}
			Meaning that the resolvent will only introduce a denominator expressed in terms of zeroth-order energies. We will introduce a more practical notation for this denominator
			\begin{align}
				\epsilon_{ij..}^{ab..} = E_0^{(0)} - E_{\left| \Phi_{ij..}^{ab..} \right> } = \epsilon_i + \epsilon_j + ... - \epsilon_a - \epsilon_b - ...
			\end{align}
			The operator $\hat V$, as shown in equations (\ref{MBPT equations}), will give rise to matrix elements. If we have a canonical Hartree-Fock basis, we can rewrite 
			\begin{align}
				\hat V = \hat W + \hat F^o = \hat W 
			\end{align}
			And there will only be two-body matrix elements present, which implies that all diagrams with one-body interactions can be removed. In the noncanonical Hartree-Fock case, $\hat F^o$ will give non-zero results and must be present. The procedure for interpreting the diagram and write out the corresponding equations can be summed up in the following sequence of operations
		\end{subsection}

		\begin{subsection}{Label all lines}
			First one should identify which lines represent hole states and which represent particle states, and label the lines with the corresponding letter, using $i,j,k,l,...$ for hole states and $a,b,c,d,...$ for particle states. 
		\end{subsection}

		\begin{subsection}{Identify the operators}
			A one-body vertex should be identified as the one-body operator used for the system, where one sets up the matrix element $f_p^q$ by the labels as
			\begin{align}
				f_p^q = \left< \text{line out} \right| \hat f \left| \text{line in} \right>
			\end{align}
			The two-body vertices are identified as the two-body operators, and when identified, one should set up the corresponding matrix elements following the interpretation rule
			\begin{align}
				\left< pq || rs \right> = \left< \text{left in, right in} || \text{left out, right out} \right> 
			\end{align}
		\end{subsection}

		\begin{subsection}{Identify the denominator}
			To identify the denominator produced by the resolvent, $\hat R_0$, one draws imaginary lines between the interactions and set up the $\epsilon$ for every state-line that was crossed.
		\end{subsection}

		\begin{subsection}{Including phase factor}
			The resulting diagram will get a phase factor depending on how many hole states and how many closed loops there are. The factor is given by 
			\begin{align}
				(-1)^{\text{Closed loops} + \text{Number of holes}}
			\end{align}
		\end{subsection}

		\begin{subsection}{Identify equivalent lines}
			Equivalent lines are pairs of lines that connect at the same vertices. They must also be of the same kind, either both particle states or both hole states. They will introduce a factor given as 
			\begin{align}
				\left( \frac{1}{2} \right)^{\text{number of equivalent lines}}
			\end{align}
		\end{subsection}

		\begin{subsection}{Second Order Perturbation Theory}
			Starting with diagram 1, we see that this diagram is non-zero, because there is no one-body operator and no pairs are broken. We can set up the equation as
			\begin{align}
				E_\text{Diagram 1} = (-1)^{2+2} \frac{1}{2^2} \sum_{\substack{ab \\ ij}} \frac{\left< ij || ab \right> \left< ab || ij \right>}{\epsilon_{ij}^{ab}}
			\end{align}
			Diagram 2 can be written out as
			\begin{align}
				E_\text{Diagram 2} = \sum_{ia} \frac{\left<i\right|f\left|a\right> \left<a\right| \hat f \left| i \right>}{\epsilon_i^a} = 0
			\end{align}
			This, however, will be zero. This is because we are operating with a canonical Hartree-Fock basis. By the definition of a non canonical Hartree Fock basis, $f_i^a = 0$, that basis would provide the same result. That means, only diagram 1 will provide a non-zero result for second order perturbation theory. 

		\end{subsection}

		\begin{subsection}{Third Order Perturbation Theory}
			The third order diagrams, shown in figure \ref{figure:mbpt23}, are numbered from 3 to 15. Third order diagrams have three interaction parts: One at the top and one at the bottom of the diagram along with an intermediate interaction part in the middle. Applying the same logic that we applied for diagram 2, we can exclude all diagrams with a one-body interaction term, leaving only diagrams 3, 4 and 5. 
			\begin{align}
				E_{\text{diagram 3}} = \sum_{\substack{abc \\ ijk}} \frac{\left<ij||ab\right>\left<bk||jc\right>\left<ac||ij\right>}{\epsilon_{ij}^{ac} \epsilon_{ij}^{ab}} = 0
			\end{align}
			However, here we see a problem. We have an interaction term $\left<bk||jc\right>$, which is a broken pair. The Pairing model does not allow such states, and this must be zero. This is not a problem for the diagrams 4 and 5. 
			\begin{align}
				E_{\text{diagram 4}} = \frac{1}{2^3} \sum_{\substack{abcd \\ ij}} \frac{\left<cd||ij\right>\left<ab||cd\right>\left<ij||ab\right>}{\epsilon_{ij}^{cd} \epsilon_{ij}^{ab}}
			\end{align}
			\begin{align}
				E_{\text{diagram 4}} = \frac{1}{2^3} \sum_{\substack{ab \\ ijkl}} \frac{\left<ab||kl\right>\left<kl||ij\right>\left<ij||ab\right>}{\epsilon_{kl}^{ab} \epsilon_{ij}^{ab}}
			\end{align}
			So when doing perturbation theory to third degree with a canonical Hartree-Fock basis as for the Pairing model, one only needs to calculate the diagrams 1, 4 and 5. 

		\end{subsection}

		\begin{subsection}{Fourth Order Perturbation Theory}
			When calculating the correlation energy with the fourth order energy, the second and third order are included as well. The amount of diagrams increase dramatically when adding the fourth order, but as we only work with a canonical Hartree-Fock basis, the amount is somewhat limited \cite{ShavittAndBartlett}. We group the diagrams by the excitations they produce, i.e. how many pairs of external lines. 
			\begin{figure}[H]
				\includegraphics[width=\textwidth]{Figures/fourthorder1p1h.png}
				\caption{Goldstone diagrams for fourth order Reileigh-Schr\"{o}dinger perturbation theory with 1p1h excitations}
				\label{figure:mbpt1p1h}
			\end{figure}
			The first set of diagrams in figure (\ref{figure:mbpt1p1h}) show diagrams giving rise to a 1particle-1hole excitation. All these diagrams have an intermediate step with a 1p-1h part. The Pairing model does not allow broken pairs, meaning that intermediate steps with 1p-1h or 3p-3h interaction parts must be zero. Therefore none of these diagrams are included in the calculations.
			\begin{figure}[H]
				\includegraphics[width=\textwidth]{Figures/fourthorder2p2h.png}
				\caption{Goldstone diagrams for fourth order Reileigh-Schr\"{o}dinger perturbation theory with 2p2h excitations}
				\label{figure:mbpt2p2h}
			\end{figure}
			The set of diagrams shown in figure (\ref{figure:mbpt2p2h}), give rise to a 2 particle and 2 hole excitation. For all these diagrams, there are only 2p-2h interaction parts for all intermediate steps. However, many of these diagrams give rise to a broken pair interaction of the form 
			\begin{align}
			 	\left< ai || pq \right> 
			\end{align}
			Only the diagrams 5,6,14 and 15 have no broken pair interactions. They are calculated as
			\begin{align}
				E_{\text{diagram 5}} = \frac{1}{2^4} \sum_{\substack{abcd\\ijkl}} \frac{ \left<cd||kl\right>\left<kl||ij\right>\left<ab||cd\right>\left<ij||ab\right> }{ \epsilon_{kl}^{cd} \epsilon_{ij}^{cd} \epsilon_{ij}^{ab} }
			\end{align} 
			And diagram 6
			\begin{align}
				E_{\text{diagram 6}} = \frac{1}{2^4} \sum_{\substack{abcd\\ijkl}} \frac{ \left<cd||kl\right>\left<kl||ij\right>\left<ab||cd\right>\left<ij||ab\right> }{ \epsilon_{kl}^{ab} \epsilon_{kl}^{cd} \epsilon_{ij}^{ab} }
			\end{align} 
			For diagram 14, we get 
			\begin{align}
				E_{\text{diagram 14}} = \frac{1}{2^4} \sum_{\substack{abcdef\\ij}} \frac{ \left<ij||ab\right>\left<ab||cd\right>\left<cd||ef\right>\left<ef||ij\right> }{ \epsilon_{ij}^{ab} \epsilon_{ij}^{cd} \epsilon_{ij}^{ef} }
			\end{align} 
			And for diagram 15
			\begin{align}
				E_{\text{diagram 15}} = \frac{1}{2^4} \sum_{\substack{ab\\ijklmn}} \frac{ \left<ij||ab\right>\left<kl||ij\right>\left<mn||kl\right>\left<ab||mn\right> }{ \epsilon_{ij}^{ab} \epsilon_{kl}^{ab} \epsilon_{mn}^{ab} }
			\end{align} 

			\begin{figure}[H]
				\includegraphics[width=\textwidth]{Figures/fourthorder3p3h.png}
				\caption{Goldstone diagrams for fourth order Reileigh-Schr\"{o}dinger perturbation theory with 3p3h excitations}
				\label{figure:mbpt3p3h}
			\end{figure}
			The diagrams depicted in figure (\ref{figure:mbpt3p3h}), show the fourth order diagrams giving rise to 3 particles and 3 holes excitations. We notice that all these diagrams include one intermediate step with a 3p-3h excitation. Therefore we can exclude all these diagrams from the calculations.  

			\begin{figure}[H]
				\includegraphics[width=\textwidth]{Figures/fourthorder4p4h.png}
				\caption{Goldstone diagrams for fourth order Reileigh-Schr\"{o}dinger perturbation theory with 4p4h excitations}
				\label{figure:mbpt4p4h}
			\end{figure}
			The last set of diagrams, depicted in figure (\ref{figure:mbpt4p4h}), show the fourth order diagrams that include a 4 particle and 4 hole part. Invoking the Linked diagram theorem, we can immediatly exclude diagram 33 and diagram 41. Diagram 34 to 40 do will be non-zero, and must be calculated. For diagram 34, we get
			\begin{align}
				E_{\text{diagram 34}} = \left(-1\right)^{(3+4)} \frac{1}{2^2} \sum_{\substack{abcd\\ijkl}} \frac{ \left<ij||ab\right>\left<kl||cd\right>\left<ab||ik\right>\left<cd||jl\right> }{ \epsilon_{ij}^{ab} \epsilon_{ijkl}^{abcd} \epsilon_{jl}^{cd} }
			\end{align}
			We notice that there are 3 closed loops and 4 hole states, giving rise to the negative phase factor. We also notice that we have two pairs of equivalent lines, arising from the particle states, introducing a factor $\frac{1}{4}$. One can also notice the fourth order denominator term $\epsilon_{ijkl}^{abcd}$, arising from the 4p-4h intermediate excitation part. The last diagrams are calculated following the same principles, giving 
			\begin{align}
				E_{\text{diagram 35}} = \left(-1\right)^{(3+4)} \frac{1}{2^2} \sum_{\substack{abcd\\ijkl}} \frac{ \left<ij||ab\right>\left<kl||cd\right>\left<ac||ij\right>\left<bd||kl\right> }{ \epsilon_{ij}^{ab} \epsilon_{ijkl}^{abcd} \epsilon_{kl}^{bd} }
			\end{align}
			And diagram 36. Please notice that there is a mistake in the drawing of the diagram 36. The right-most particle state is supposed to be a hole state, giving the correct equation 
			\begin{align}
				E_{\text{diagram 36}} = \frac{1}{2^4} \sum_{\substack{abcd\\ijkl}} \frac{ \left<ij||ab\right>\left<kl||cd\right>\left<ab||kl\right>\left<cd||ij\right> }{ \epsilon_{ij}^{ab} \epsilon_{ijkl}^{abcd} \epsilon_{ij}^{cd} }
			\end{align}
			Diagram 37 is also depicted with the right-most state wrong. It is supposed to be a particle state, giving
			\begin{align}
				E_{\text{diagram 37}} = \frac{1}{2^4} \sum_{\substack{abcd\\ijkl}} \frac{ \left<ij||ab\right>\left<kl||cd\right>\left<cd||ij\right>\left<ab||kl\right> }{ \epsilon_{ij}^{ab} \epsilon_{ijkl}^{abcd} \epsilon_{kl}^{ab} }
			\end{align}
			and for diagram 38, we notice that there are no equal state pairs
			\begin{align}
				E_{\text{diagram 38}} = \sum_{\substack{abcd\\ijkl}} \frac{ \left<ij||ab\right>\left<kl||cd\right>\left<db||lj\right>\left<ac||ik\right> }{ \epsilon_{ij}^{ab} \epsilon_{ijkl}^{abcd} \epsilon_{ik}^{ac} }
			\end{align}
			Diagram 39 gives
			\begin{align}
				E_{\text{diagram 39}} = \left(-1\right)^{(3+4)} \frac{1}{2^2} \sum_{\substack{abcd\\ijkl}} \frac{ \left<ij||ab\right>\left<kl||cd\right>\left<bd||kl\right>\left<ac||ij\right> }{ \epsilon_{ij}^{ab} \epsilon_{ijkl}^{abcd} \epsilon_{ij}^{ac} }
			\end{align}
			And finally, diagram 40 gives the equation
			\begin{align}
				E_{\text{diagram 40}} = \left(-1\right)^{(3+4)} \frac{1}{2^2} \sum_{\substack{abcd\\ijkl}} \frac{ \left<ij||ab\right>\left<kl||cd\right>\left<cd||jl\right>\left<ab||ik\right> }{ \epsilon_{ij}^{ab} \epsilon_{ijkl}^{abcd} \epsilon_{ik}^{ab} }
			\end{align}
			
		\end{subsection}
 		
 	\end{section}

 	\begin{section}{Spin Summations}
 		Up to this point, we have not taken into account the effect of spin in the matrix elements. Because of spin orthogonality, terms may vanish from certain two-electron matrix elements. Listed here, are all the different ways spins can be organized, along with the resulting integration. Representing the spin up orbital with a bar, we get \cite{ShavittAndBartlett}
 		\begin{align}
 			\left< pq || rs \right> &= \left< pq | \hat v | rs \right> - \left< pq | \hat v | sr \right> \\
 			\left< p\bar q || r\bar s \right> &= \left<pq | \hat v | rs \right> \\
 			\left< p \bar q|| \bar r s \right> &= - \left<pq | \hat v | sr \right> \\
 			\left< \bar p q|| \bar r s\right> &= \left< pq | \hat v | rs \right> \\
 			\left< \bar p q|| r \bar s \right> &= - \left< pq | \hat v | sr \right> \\
 			\left< \bar p \bar q || \bar r \bar s \right> &= \left< pq | \hat v | rs \right> - \left< pq | \hat v | sr \right> 
 		\end{align}
 		Because of the restrictions on the pairing model, the first and last equation will also be zero, because the states are not allowed to exist. Matrix elements, where there is an unequal amount of equal spin orbitals will all give zero as result as well
 		\begin{align}
 			\left< \bar p q || rs \right> &= \left< p \bar q || rs \right> = \left< pq || \bar r s \right> = \left< pq || r \bar s \right> = 0 \\
 			\left< \bar p \bar q || rs \right> &= \left< pq || \bar r \bar s \right>  = 0 \\
 			\left< \bar p \bar q || \bar r s \right> &= \left< \bar p \bar q || r \bar s \right> = \left< \bar p q || \bar r \bar s \right> = \left< p \bar q || \bar r \bar s \right> = 0
 		\end{align} 


 	\end{section}

\end{chapter}



\begin{chapter}{Infinite Matter}
	A study of infinite matter is the most comprehensible way of studying nuclear material. This thesis will study the infinite electron gas before the final study of nuclear material. This is done for pedagogical reasons and because the electron gas has closed form solutions that provide important benchmarking for the code. 
	\begin{section}{The Infinate Electron Gas}
		The infinite electron gas gives a good approximation to valence electrons in metal. The gas consists only of interacting electrons with a uniform background of charged ions. The whole system is charge neutral. We assume a finite cubic box as done in \cite{Shepherd2012} and \cite{Shepherd2013}. The box has a length $L$ and volume $\Omega = L^3$, with $N_e$ as the number of electrons with a charge density $\rho = N_e / \Omega$.

		\begin{subsection}{The Hamiltonian}
			The electrons interact with the central symmetric Colomb potential, $\hat V(\vec r_1, \vec r_2)$ depending only on the distance $\left| \vec r_1 - \vec r_2 \right|$. The Hamiltonian for infinite electron gas is \cite{Baardsen}
			\begin{align}
				\hat H = \hat H_1 + \hat H_2 = \hat H_{\text{kin}} + \hat H_{\text{interaction}}
			\end{align}
			The interaction term will be dependent on both the electron-electron interaction, the electron-background interaction and the background-background interaction
			\begin{align}
				\hat H = \hat H_{\text{kin}} + \hat H_{\text{ee}} + \hat H_{\text{eb}} + \hat H_{\text{bb}}
			\end{align}
			And the kinetic energy, $\hat H_{\text{kin}}$ is given as
			\begin{align}
				\hat H_{\text{kin}} = \sum_p \frac{\hbar ^2 k^2}{2m} a_{k \sigma}^{\dagger} a_{k \sigma}
			\end{align}
			The background-interaction terms will vanish as explained by Fraser et al \cite{Fraser et al} both for three- and two-dimensional electron gas. When we sum over all particles, we can write the electron-electron interaction term as an Ewald summation term, because it is not possible to use a $1/r$ term for infinite systems \cite{Drummond2008} \cite{MHJonline}. We can write this term as
			\begin{align}
				\hat H_{ee} = \sum_{i<j}^N v_E(\mathbf{r}_i - \mathbf{r}_j) + \frac{1}{2}Ne^2v_0
			\end{align}
			Where $v_E(\mathbf{r})$ is an effective two-body interaction. $v_0$ is the self-interaction term, defined as 
			\begin{align}
				v_0 = \lim_{\mathbf{r}\rightarrow \infty} \left\{ v_E(\mathbf{r}) - \frac{1}{r} \right\}
			\end{align}
			The Ewald summation will account for interactions between all electrons in the finite size system as well as all the image electrons that will arize from self-interaction because of periodic boundaries. We define it as 
			\begin{align}
				v_E(\mathbf{r}) &= \sum_{k \neq 0} \frac{4\pi}{L^3k^2} e^{i \mathbf{k}\cdot \mathbf{r} } e^{-\eta^2 k^2 / 4} \\
								&+ \sum_{\mathbf{R}} \frac{1}{|	\mathbf{r} - \mathbf{R}|} \text{erfc} \left( \frac{| \mathbf{r} - \mathbf{R}|}{\eta} \right) - \frac{\pi \eta^2}{L^3}
			\end{align}
			$L$ is the size of the box, $\mathbf{k}$ is the momentum vector, while $\mathbf{r}$ represent the position vectors for all electrons. The translational vector $\mathbf{R}$, is used to obtain all image cells in the entire real space \cite{MHJonline}
			\begin{align}
				\mathbf{R} = L(n_x \mathbf{u}_x + n_y \mathbf{u}_y + n_z \mathbf{u}_z)
			\end{align}
			We have used the error functions
			\begin{align}
				\text{erf}(x) = \frac{2}{\sqrt{\pi}} \int_0^x e^{-t^2} \text{dt}
			\end{align}
			\begin{align}
				\text{erfc}(x) = 1 - \text{erf}(x) = \frac{2}{\sqrt{\pi}} \int_x^\infty e^{-t^2} \text{dt}
			\end{align}
			We use this relation because an interaction on the form $1/|r|$ is not convergent for an infinite number of particles \cite{Audun}. Ewald found that one can rewrite the interaction in terms of these error functions \cite{Ewald}
			\begin{align}
				\frac{1}{r} = \frac{\text{erf}(\frac{1}{2}\sqrt{\eta}r)}{r} + \frac{\text{erfc}(\frac{1}{2}\sqrt{\eta}r)}{r}
			\end{align}
			One can calculate the two-dimensional Ewald term as well \cite{Baardsen}, resulting in 
			\begin{align}
				v_E^{\eta=0, z=0} = \sum_{\mathbf{k} \neq 0} \frac{2 \pi}{L^2 k} e^{i \mathbf{k} \cdot \mathbf{r}_{xy}}
			\end{align}
		\end{subsection}
		
		\begin{subsection}{The Reference Energy}
			The reference energy for electron gas can be written as \cite{Baardsen}
			\begin{align}
				E_{\text{ref}} = \sum_i \left<i | h_0 | i\right> + \frac{1}{2} \sum_{ij} \left<ij||ij\right> + \frac{1}{2} Av_0
			\end{align}
			$A$ is the number of electrons, and the term $A v_0$ is the so-called Madelung constant. It is how we incorporate the self-interaction term into the system. This factor will be larger for smaller system and vanish as we approach the thermodynamic limit. 
		\end{subsection}
		
		\begin{subsection}{The Fock Matrix Elements}
			The Fock Matrix Elements will be given as
			\begin{align}
				\left< p | f | q \right> = \frac{k_p^2}{2m} \delta_{\mathbf{k}_p \mathbf{k}_q} \delta_{m_{s_p} m_{s_q}} + \sum_i \left<pi||qi\right>
			\end{align}
			We notice that the Fock Matrix elements can be written as a diagonal part plus the $\hat U$ operator. As we can see from (\ref{3.93}) and (\ref{3.95}), this means the perturbation can be written solely by the two-body interaction
			\begin{align}
				\hat V = \frac{1}{4} \sum_{pqrs} \left<pq||rs\right> \hat p^\dagger \hat q^\dagger \hat s \hat r
			\end{align}
		\end{subsection}

		\begin{subsection}{Anti-Symmetric Matrix Elements}
			We now need to define the matrix elements for the two- and three-dimensional electron gas to calculate the perturbation 
			\begin{align}
				&\left< \mathbf{k}_p m_{s_p} \mathbf{k}_q m_{s_q} || \mathbf{k}_r m_{s_r} \mathbf{k}_s m_{s_s} \right> \\
				&= \frac{4 \pi e^2}{L^3} \delta_{\mathbf{k}_p + \mathbf{k}_q, \mathbf{k}_r + \mathbf{k}_s} \left\{ \delta_{ m_{s_p},m_{s_r} } \delta_{ m_{s_q},m_{s_s} } (1 - \delta_{\mathbf{k}_p, \mathbf{k}_r}) \frac{1}{| \mathbf{k}_r - \mathbf{k}_p|^2} \right. \\
				& - \delta_{ m_{s_p},m_{s_s} } \delta_{ m_{s_q},m_{s_r} } (1 - \delta_{\mathbf{k}_p, \mathbf{k}_s}) \left. \frac{1}{| \mathbf{k}_s - \mathbf{k}_p|^2}  \right\}
			\end{align}
			The two-dimensial case is almost identical
			\begin{align}
				&\left< \mathbf{k}_p m_{s_p} \mathbf{k}_q m_{s_q} || \mathbf{k}_r m_{s_r} \mathbf{k}_s m_{s_s} \right> \\
				&= \frac{2 \pi e^2}{L^2} \delta_{\mathbf{k}_p + \mathbf{k}_q, \mathbf{k}_r + \mathbf{k}_s} \left\{ \delta_{ m_{s_p},m_{s_r} } \delta_{ m_{s_q},m_{s_s} } (1 - \delta_{\mathbf{k}_p, \mathbf{k}_r}) \frac{1}{| \mathbf{k}_r - \mathbf{k}_p|} \right. \\
				& - \delta_{ m_{s_p},m_{s_s} } \delta_{ m_{s_q},m_{s_r} } (1 - \delta_{\mathbf{k}_p, \mathbf{k}_s}) \left. \frac{1}{| \mathbf{k}_s - \mathbf{k}_p|}  \right\}
			\end{align}		
		\end{subsection}

		\begin{subsection}{The Plane Wave Basis}
			When set up with periodic boundary conditions, the Homogenous electron gas can be set up with free particle normalized wave functions
			\begin{align}
				\psi_{\vec k \sigma} (\vec r) = \frac{1}{\sqrt{\Omega}} e^{i \vec k \vec r} \xi_{\sigma}
			\end{align}
			Where $\vec k$ is the wave number and $\xi_{\sigma}$ is a spin function. 
			\begin{align}
				\xi_{+\frac{1}{2}} = \left( \begin{matrix} 1 \\ 0 \end{matrix} \right) \:\;\:\; \xi_{-\frac{1}{2}} = \left( \begin{matrix} 0 \\ 1 \end{matrix} \right)
			\end{align}
			Because of periodic boundary conditions, we acquire the following wave numbers
			\begin{align}
				k_i = \frac{2\pi n_i}{L} \:\:\:\;\; i = x,y,z \;\;\:\:\: n_i = 0, \pm 1, \pm 2, ...
			\end{align}
			and the associated single-particle energies for two dimensions
			\begin{align}
				\epsilon_{n_x,n_y} = \frac{\hbar^2}{2m} \left( \frac{2\pi}{L} \right)^2 (n_x^2 + n_y^2)
			\end{align}
			And for three dimensions
			\begin{align}
				\epsilon_{n_x,n_y,n_z} = \frac{\hbar^2}{2m} \left( \frac{2\pi}{L} \right)^2 (n_x^2 + n_y^2 + n_z^2 )
			\end{align}
			By the nature of the single particle energies, the energy levels will be determined by the value of $n_x^2 + n_y^2 + n_z^2$. There are different combinations of $n_x, n_y$ and $n_z$ that set up each energy level. The cumulative number of particles needed to completely fill these energy states will be named \textit{magic numbers} and are listed in table (\ref{Magic Numbers 3d}). 
			\begin{table}[H]
				\begin{center}
					\begin{tabular}[center]{l | c c c | c | c | r }
						$n_x^2 + n_y^2 + n_z^2$ & $n_x$ & $n_y$ & $n_z$ & $N_{\uparrow \uparrow}$ & $N_{\uparrow \downarrow}$ & $N_{\uparrow \downarrow} \hat \tau$ \\
						\hline
						0 & 0 & 0 & 0 & 1 & 2 & 4 \\
						\hline
						1 & 1 & 0 & 0 &   &   &   \\
						  & -1& 0 & 0 &   &   &   \\
						  & 0 & 1 & 0 &   &   &   \\
						  & 0 & -1& 0 &   &   &   \\
						  & 0 & 0 & 1 &   &   &   \\
						  & 0 & 0 & -1& 7 & 14& 28\\
						\hline
						2 & 1 & 1 & 0 &   &   &   \\
						  & 1 & -1& 0 &   &   &   \\
						  & 1 & 0 & 1 &   &   &   \\
						  & 1 & 0 & -1&   &   &   \\
						  & -1& 1 & 0 &   &   &   \\
						  & -1& -1& 0 &   &   &   \\
						  & -1& 0 & 1 &   &   &   \\
						  & -1& 0 & -1&   &   &   \\
						  & 0 & 1 & 1 &   &   &   \\
						  & 0 & 1 & -1&   &   &   \\
						  & 0 & -1& 1 &   &   &   \\
						  & 0 & -1& -1&19 &38 & 76\\
						\hline
						3 & 1 & 1 & 1 &   &   &   \\
						  & 1 & 1 & -1&   &   &   \\
						  & 1 & -1& 1 &   &   &   \\
						  & 1 & -1& -1&   &   &   \\
						  & -1& 1 & 1 &   &   &   \\
						  & -1& 1 & -1&   &   &   \\
						  & -1& -1& 1 &   &   &   \\
						  & -1& -1& -1&27 & 54&108\\
						\hline
						4 & 2 & 0 & 0 &   &   &   \\
						  & -2& 0 & 0 &   &   &   \\
						  & 0 & 2 & 0 &   &   &   \\
						  & 0 & -2& 0 &   &   &   \\
						  & 0 & 0 & 2 &   &   &   \\
						  & 0 & 0 & -2& 33& 66&132\\
						\hline
						5 &   &   &   & 57&114&228\\
						\hline
						6 &   &   &   & 81&162&324\\
						\hline
						7 &   &   &   & 81&162&324\\
						\hline
						8 &   &   &   & 93&186&372
					\end{tabular}
				\end{center}
				\caption{All magic numbers for three dimensional infinite matter. The table demonstrates how states will fill up energy levels. $n_x$, $n_y$ and $n_z$ represent momentum quantum numbers, $n_x^2 + n_y^2 + n_z^2$ represent energy level. $N_{\uparrow \uparrow}$ shows magic number without spin degeneracy, $N_{\uparrow \downarrow}$ adds two possible spins, and $N_{\uparrow \downarrow} \hat \tau $ also adds isospin degeneracy.} 
				\label{Magic Numbers 3d}
			\end{table}

		\end{subsection}

	\end{section}

	\begin{section}{Infinite Nuclear Matter}
		Central to my thesis, is the study of infinite nuclear matter. I look at baryonic matter similar to the dense baryonic matter found in neutron stars. I limit the study to temperatures far below Fermi level. The matter is mostly made up of an equilibrium of baryons and leptons. In neutron star matter, we assume the equilibrium consists of protons, neutrons, electrons and muons with densities larger than $0.1 \text{fm}^-3$. The equilibrium conditions are specified by weak interactions
		\begin{align}
		 	b_1 \rightarrow b_2 + l + \bar \nu_l \:\:\:\:\:\: b_2 + l \rightarrow b_1 + \nu_l
		\end{align} 
		Where $b$ represent either neutron or proton and $l$ is either an electron or muon. $\nu_l$ is the corresponding neutrino. 

		Nuclear matter is a hypothetical system filling all of space at a uniform density. Symmetric nuclear matter (SNM) consist of equal numbers of protons of neutrons, while pure nuclear matter (PNM) consist only of neutrons. For finite-nucleus systems, the most difficult part is calculating the single particle wave function. For nuclear matter we can use the same plane wave basis that we used for the electron gas. The difficult part is calculating the energy and the effective interaction between particles \cite{Day1967}. In my calculations, I have looked at pure nuclear matter. 
	\end{section}

	\begin{section}{Nuclear Interaction}
		Nuclear matter is composed of baryons, which interacts through the strong force. 
		
		\begin{subsection}{The Minnesota Potential}
			The Minnesota Potential is given as
			\begin{align}
				v(r) = &\left(v_R + (1 + P_{12}^\sigma) v_T/2 + (1 - P_{12}^\sigma) v_S/2 \right) \\
					   \cdot &\left( \alpha + (2- \alpha)P_{12}^r \right)/2 + (1+m_{t,1})(1+m_{t,2})\frac{e^2}{4r}
			\end{align}
			where $r$ is given as $\left| \mathbf{r_1} - \mathbf{r_2} \right|$ and $m_t$ is the isospin projection of particle 1 or 2. $m_t = \pm 1$. 
			$P_{12}^\sigma $ and $P_{12}^r$ are exchange operators for spin and position, respectively \cite{Baardsen}. Furthermore, we have used
			\begin{align} 
				v_R = v_{0R}e^{-k_R r^2}, \:\:\: v_T = -v_{0T} e^{-k_Tr^2}, \:\:\: v_S = -v_{0S}e^{-k_sr^2}
			\end{align}
			Where the constants $v_{0R}$, $v_{0T}$, $v_{0S}$, $k_R$, $k_T$ and $k_S$ are given by \cite{Thompson1977}
			\begin{enumerate}
				\item $v_{0R} = 200$MeV,  $k_R = 0.1487 \text{fm}^{-2}$
				\item $v_{0T} = 178$MeV,  $k_T = 0.649 \text{fm}^{-2}$
				\item $v_{0S} = 91.85$MeV, $k_S = 0.465 \text{fm}^{-2}$
			\end{enumerate}
			Written by second quantisation, we want to calculate the two-body interaction
			\begin{align}
			 	\left<k_p k_q \middle| v \middle| k_r k_s \right> = \frac{V_0}{L^3} \left(\frac{\pi}{\alpha}\right)^{3/2} e^{-q^2 / 4 \alpha} \delta_{\vec k_p + \vec k_q, \vec k_r + \vec k_s}
			\end{align}
			Where $q$ is the relative momentum transfer
			\begin{align}
				\mathbf{q} = \mathbf{p} - \mathbf{p'} 
			\end{align}
			\begin{align}
				\mathbf{p} = \frac{1}{2} (\mathbf{k}_p - \mathbf{k}_q) \:\:\:\:\: \mathbf{p'} = \frac{1}{2}(\mathbf{k}_r- \mathbf{k}_s) 
			\end{align}
			We can now set up the two-body Matrix-elements for the Minnesota Potential
			\begin{align}
				\left<\mathbf{k}_p \mathbf{k}_q \middle| v \middle| \mathbf{k}_r \mathbf{k}_s \right> = 
				&\left<\mathbf{k}_p \mathbf{k}_q \right| \frac{1}{2} \left( V_R + \frac{1}{2} V_T + \frac{1}{2} V_S \right) \left| \mathbf{k}_r \mathbf{k}_s \right>  \\
				+&\left<\mathbf{k}_p \mathbf{k}_q \right| \frac{1}{4} (V_T - V_S) P_{12}^\sigma \left| \mathbf{k}_r \mathbf{k}_s \right> \\
				-&\left<\mathbf{k}_p \mathbf{k}_q \right| \frac{1}{2} \left( V_R + \frac{1}{2} V_T + \frac{1}{2} V_S \right) P_{12}^\sigma P_{12}^\tau \left| \mathbf{k}_r \mathbf{k}_s \right> \\
				-&\left<\mathbf{k}_p \mathbf{k}_q \right| \frac{1}{4}(V_T - V_S) P_{12}^\tau  \left| \mathbf{k}_r \mathbf{k}_s \right>&
			\end{align}
			Matrix elements for the spin and isospin exchange operators are 
			\begin{align}
				\left< \sigma_p \sigma_q \right| P_{12}^\sigma \left| \sigma_r \sigma_s \right> = \delta_{\sigma_p,\sigma_s} \delta_{\sigma_q,\sigma_r}
			\end{align}
			One can see that these matrix elements come at a far greater computational cost than for electron-electron interaction in the electron gas. Therefore it is necessary to compute and store all elements instead of computing them "on the fly". Source: Lecture 1-2 infinite matter. 
		\end{subsection}
		
	\end{section}

\end{chapter}



\begin{chapter}{Implementation of CCD}
	In this thesis I have created three different solvers for coupled-cluster doubles equations. 
	\begin{enumerate}
		\item A naive brute force implementation of the equations summing over all variables. 
		\item A naive brute force implementation of intermediate equations summing over all variables.
		\item Rewriting summations as matrix-matrix multiplications and exploiting various symmetry arguments that one can set up as a block implementation.
	\end{enumerate}	
	There is a significant performance leap between each method, but I have included the first two solvers for both educational and benchmarking purposes. The Pairing model with 4 particles and 4 holes is a small system that one can easily solve using the naive approach. After producing expected results with the naive solver, I have compared the more complicated solvers to the naive solver for all systems. 

	\begin{section}{Implementing the CCD equations}
		The basic steps of all implemented CCD algorithms can be explained through the following four steps:
		\begin{enumerate}
			\item Initialize amplitudes $t^{(0)} = 0$ and $\Delta E_{CCD}^{(0)} = 0$
			\item Update the amplitudes and calculate $\Delta E_{CCD}^{(1)}$
			\item If $ |\Delta E_{CCD}^{(1)} - \Delta E_{CCD}^{(0)}| \geq \epsilon $, update amplitudes and compute $\Delta E_{CCD}^{2}$
			\item Repeat until $ |\Delta E_{CCD}^{(n+1)} - \Delta E_{CCD}^{(n)}| \leq \epsilon $
		\end{enumerate}
		The difference between the three solvers I have implemented is the way I update amplitudes. The naive brute force solver loops over all indices when computing. An example of diagram $L_a$ is shown below

		\begin{lstlisting}
		for i in 0, ..., Nholes:
			for j in 0, ..., Nholes:
				for a in Nholes, ..., Nparticles:
					for b in Nholes, ..., Nparticles:
						for c in Nholes, ..., Nparticles:
							for d in Nholes, ..., Nparticles:
								tnew(a,b,i,j) = 0.5  v(a,b,c,d)  told(c,d,i,j)
		\end{lstlisting}

		A significant cost reduction can be obtained by factorizing the diagrams as shown in equation (\ref{Intermediates}). By calculating the four intermediate diagrams, $I_1$, $I_2$, $I_3$ and $I_4$ beforehand and storing the results reduce the cost of calculation from $\mathcal{O}(h^4 p^4)$ to $\mathcal{O}(h^4 p^2)$. The second solver applies this method. 

	\end{section}

	\begin{section}{Matrix Representation of Contractions}
		Diagrams can be viewed as contractions of tensors of varying degree. An example is the matrix-matrix multiplication product
		\begin{align}
		 	\left( M N \right)_{\gamma}^{\alpha} = \sum_{\beta} M_{\beta}^\alpha N_\gamma^\beta 
		 	\label{matrix matrix multiplication}
		\end{align} 

		As our goal is to rewrite the Coupled Cluster equations as matrix-matrix products, we will need to map tensors of rank $\geq 2$ onto matrices. One mapping that provides systematic and unique matrix elements can be 
		\begin{align}
			\left<pq\middle| \hat v\middle|rs\right> = V_{\alpha(p,q),\beta(r,s)}
		\end{align}
		Where 
		\begin{align}
			\alpha(p,q) = p + q N_p \;\,\:\; \beta(r,s) = r + s N_r
			\label{mapping of matrix elements}
		\end{align}
		We need to be careful when mapping tensors this way. Consider first the calculation of the perfectly aligned $L_a$ term
		\begin{align}
			L_a = \sum_{cd} \left< ab \middle| \hat v\middle|cd\right> t_{ij}^{cd}
		\end{align}
		Mapping this equation using equation (\ref{mapping of matrix elements})
		\begin{align}
			\left< ab \middle| \hat v\middle|cd\right> = v_{ab}^{cd} \rightarrow V_{\beta(c,d)}^{\alpha(a,b)}
		\end{align}
		and
		\begin{align}
			t_{ij}^{cd} \rightarrow T_{\delta(i,j)}^{\beta(c,d)}
		\end{align}
		As we are mapping to unique elements 
		\begin{align}
			\beta(c,d) = \beta(c,d)
		\end{align}
		We can now rewrite the equation 
		\begin{align}
			(L_a)_ \delta^\alpha = \sum_ \beta V_ \beta^\alpha T_ \delta^\beta
		\end{align}
		Implying by regarding equation (\ref{matrix matrix multiplication}) that we can rewrite the product as matrix-matrix multiplication 
		\begin{align}
			L_a = VT
		\end{align}

		\begin{subsection}{Aligning elements}	
			Unfortunately, not all products are perfectly aligned like $L_a$. Consider, for example, the term, $L_c$
			\begin{align}
				L_c = -P\left(ij\middle|ab\right) \sum_{kc} \left<kb\middle|\hat v\middle|cj\right>t_{ik}^{ac}
			\end{align}
			Using the same mapping scheme
			\begin{align}
				\left<kb\middle|\hat v\middle|cj\right> = v_{cj}^{kb} \rightarrow V_{\beta(cj)}^{\alpha(kb)}
			\end{align}
			and
			\begin{align}
				t_{ik}^{ac} \rightarrow T_{\delta(ik)}^{\gamma(ac)}
			\end{align}
			This matrix multiplication is misaligned, and if the number of particles is unequal to the number of holes, the matrices' size will be incompatible. 
			\begin{align}
				(L_c)_ \delta^\alpha \neq -P\left(ij\middle|ab\right) \sum_ \beta V_{\beta(cj)}^{\alpha(kb)} T_{\delta(ik)}^{\gamma(ac)}
			\end{align}
			We need to find another mapping, such as
			\begin{align}
				v_{cj}^{kb} \rightarrow \tilde V_{\beta(ck)}^{\alpha(bj)}
			\end{align}
			and 
			\begin{align}
				t_{ik}^{ac} \rightarrow \tilde T_{\delta(ia)}^{\gamma(ck)}
			\end{align}
			Now, the matrix multiplication is aligned
			\begin{align}
				(\tilde L_c)_ \delta^\alpha = -P\left(ij\middle|ab\right) \sum_ \beta \tilde V_{\beta(ck)}^{\alpha(bj)} \tilde T_{\delta(ia)}^{\gamma(ck)}
			\end{align}
			Note, however, that 
			\begin{align}
				L_c \neq \tilde L_c
			\end{align}
			We must "realign" $\tilde L_c$ to match the correct diagram
			\begin{align}
				(\tilde L_c)_{\delta(i,a)}^{\alpha(b,j)} \rightarrow (L_c)_{\delta(i,k)}^{\alpha(k,b)}
			\end{align}

			Another example is the $Qc$ term
			\begin{align}
				Q_c = -\frac{1}{2} \hat P(ij) \sum_{klcd} \left< kl \middle| v \middle| cd \right> t_{ik}^{ab} t_{jl}^{cd} 
			\end{align}
			We can rewrite this as a matrix-matrix multiplication with the matrix elements given by
			\begin{align}
				\left< kl \middle| v \middle| cd \right> = v_{cd}^{kl} & \rightarrow V^{\alpha(cd)}_{\beta(kl)} \\
				t_{ik}^{ab} & \rightarrow (T_1)_{\gamma(ik)}^{\delta(ab)} \\
				t_{jl}^{cd} & \rightarrow (T_2)_{\omega(jl)}^{\eta(cd)}
			\end{align}
			Because we sum over the coefficients $klcd$, we must make sure that they belong to the "inner" indexes. This can only be done by creating a hole, particle-particle-hole configuration. We must also change the order of multiplication
			\begin{align}
				V^{\alpha(cd)}_{\beta(kl)} &  \rightarrow \tilde V^{\delta(k)}_{\gamma(cdl)} \\
				(T_1)_{\gamma(ik)}^{\delta(ab)} & \rightarrow \tilde (T_1)^{\alpha(abi)}_{\delta(k)} \\
				(T_2)_{\omega(jl)}^{\eta(cd)} & \rightarrow \tilde (T_2)^{\gamma(cdl)}_{\beta(j)}
			\end{align}
			This gives us
			\begin{align}
				( \tilde Q_c )_{\beta(j)}^{\alpha(abi)} = -\frac{1}{2} \hat P(ij) \sum_{klcd} (\tilde T_1)^{\alpha(abi)}_{\delta(k)} \tilde V^{\delta(k)}_{\gamma(cdl)} (\tilde T_2)^{\gamma(cdl)}_{\beta(j)}
			\end{align}
			Which must be realigned back to the properly aligned $Q_c$ before it can be added to the amplitude equations.
			\begin{align}
				( \tilde Q_c )_{\beta(j)}^{\alpha(abi)} \rightarrow (Q_c)_{\beta(ij)}^{\alpha(ab)}
			\end{align}
			We will need a general mapping function that can be used regardless of the amount of states used. It turns out that we can use the same mapping as before, just generalized to $N$ states.
			\begin{align}
				\alpha(p_1,p_2,p_3,...,p_N) = p_1 + p_2N_1 + p_3N_1N_2 + ... + p_N N_1 N_2 ... N_{N-1} 
			\end{align}
			Where $N_n$ determines the maximum number of states for $p_n$. If for example $p_n \in i$, i.e. $p_n$ is a hole-state, $N_n = N_{holes}$.

			Writing the diagrams as matrix-matrix multiplications serves as a significant reduction of computational time, due to the efficient algortithms in the BLAS-packages for matrix-matrix multiplications. However, since one has to save all the matrices, memory usage will be a problem for large basises. 
		\end{subsection}

	\end{section}

	\begin{section}{Block Implementation}
		One can both greatly reduce memory usage and improve computational speed by exploiting symmetries for infinite matter. Due to kroenecker delta's in the interaction, one such symmetry is the conservation of momentum
		\begin{align}
			\delta_{\vec k_p + \vec k_q, \vec k_r + \vec k_s} \rightarrow \vec k_p + \vec k_q = \vec k_r + \vec k_s
		\end{align}
		We also conserve spin 
		\begin{align}
			m_{s_p} + m_{s_q} = m_{s_r} + m_{s_s}
		\end{align}
		and for nuclear matter, we will conserve isospin as well
		\begin{align}
			m_{t_p} + m_{t_q} = m_{t_r} + m_{t_s}
		\end{align}
		The amplitudes will be subject to the same restrictions, vizualised by the first order amplitude generated by perturbation theory
		\begin{align}
			(t_{ij}^{ab})^{t=0} = \frac{\left<ab\middle|\hat v\middle|ij\right>}{\epsilon_i + \epsilon_j - \epsilon_a - \epsilon_b}
		\end{align}
		Looking at the $L_a$ term
		\begin{align}
			L_a = \sum_{cd} \left<ab\middle|\hat v\middle|cd\right> t_{ij}^{ab}
		\end{align}
		We see that 
		\begin{align}
			\vec k_a + \vec k_b = \vec k_c + \vec k_d = \vec k_i + \vec k_j
		\end{align}
		And the same for spin
		\begin{align}
			m_{s_a} + m_{s_b} = m_{s_c} + m_{s_d} = m_{s_i} + m_{s_j} 
		\end{align}
		When summing over all variations of contractions, only the quantum numbers preserving the symmetry requirements are non-zero. When storing the interactions in a matrix, most of it will have zero-elements. The blocking method will store the non-zero parts in blocks inside the matrix. By keeping track of the blocks, we can reduce the full matrix-matrix multiplication to a series of multiplications of the blocks. We will hereby refer to the series of blocks as \textit{channels}.

		\begin{subsection}{Two-state configurations}
			As we can see from the $L_a$ diagram, the conservation laws apply for a combination of two states. The next step is then to set up all two-state configurations that will be needed. We start by setting up the direct two-state channels, $T$, which consist of all two-hole and two-particle configurations. A unique identifier must be set up for the combination of quantum numbers. The identifier is used to aligning the non-zero combinations of two-body states to the same channel. Without this identifier, we will have to loop over all channels for each two-body state. I have used the following function 
			\begin{align}
				\text{Index}(N_x,N_y,N_z,S_z,T_z) = &2(N_x + m)M^3 + 2(N_y+m)M^2 + \\ & 2(N_z+m)M + 2(S_z+1) + (T_z+1)
			\end{align}
			Using the same logic as in equation (\ref{mapping of matrix elements}) to get a unique identifier for every combination of $N_x,N_y,N_z,S_z$ and $T_z$. This implies that the two-body states have the same momentum, spin and isospin projection, which satisfies our conservation laws. We need $m$ and $M$ to be sufficiently large. I have used
			\begin{align}
				m = 2|\sqrt{N_{\text{max}}}| \:\:\:\:\:\: M = 2m +1
			\end{align}
			Because of the Pauli-exclusion, two particles cannot occupy the same state, so we can further reduce the amount of two-body states by excluding equal one-body states from the channels. An algorithm for setting up the direct channels can be portraied as
			\begin{align*}
				&\mathbf{for } \text{ one-body state 1} \in \text{STATES}: \\
				&\:\:\:\: \mathbf{for } \text{ one-body state 2} \in \text{STATES}: \\
				&\:\:\:\:\:\:\:\: \mathbf{if} \text{ one-body state 1} \neq \text{ one-body state 2}: \\
				&\:\:\:\:\:\:\:\:\:\: N_x = n_{x,1} + n_{x,2} \\
				&\:\:\:\:\:\:\:\:\:\: N_y = n_{y,1} + n_{y,2} \\
				&\:\:\:\:\:\:\:\:\:\: N_z = n_{z,1} + n_{z,2} \\
 				&\:\:\:\:\:\:\:\:\:\: S_z = m_{s,1} + m_{s,2} \\
				&\:\:\:\:\:\:\:\:\:\: T_z = m_{t,1} + m_{t,2} \\
				&\:\:\:\:\:\:\:\:\:\: \text{Id} = \text{Index}(N_x,N_y,N_z,S_z,T_z) \\
				&\:\:\:\:\:\:\:\:\:\: T \leftarrow (\text{ one-body state 1}, \text{ one-body state 2}, \text{ Id})
			\end{align*}

		\end{subsection}
		
		\begin{subsection}{Unaligned channels}
			Diagram $L_a$, $L_b$ and $Q_a$ have conservation requirements as shown previously for $L_a$
			\begin{align}
			 	\mathbf{k}_a + \mathbf{k}_b = \mathbf{k}_c + \mathbf{k}_d = \mathbf{k}_i + \mathbf{k}_j 
			\end{align}
			Which are implemented using the direct channels. We will however run into some trouble when computing the unaligned diagrams $L_c$, $Q_b$, $Q_c$ and $Q_d$. Looking at the diagram $L_c$, given by 
			\begin{align}
				L_c = - \hat P(ij|ab) \sum_{kc} \left<kb\middle|\hat v\middle| cj \right> t_{ik}^{ac}
			\end{align}
			With the corresponding conservation requirements given by
			\begin{align}
				\mathbf{k}_k + \mathbf{k}_b = \mathbf{k}_c + \mathbf{k}_j = \mathbf{k}_a + \mathbf{k}_c = \mathbf{k}_i + \mathbf{k}_k
			\end{align}
			and 
			\begin{align}
				m_{s,k} + m_{s,b} = m_{s,c} + m_{s,j}  \:\:\:\:\:\:\: m_{t,k} + m_{t,b} = m_{t,c} + m_{t,j} 
			\end{align}
			When realigning the equation, we want it to be on the form
			\begin{align}
				\tilde Lc = -\hat P(ij|ab) \sum_{kc} \left<bj | \tilde v | ck \right> \left< ck \right| \tilde t \left| ai \right>
			\end{align}
			We reorganize the conservation requirements as well to make sure we only calculate the non-zero terms
			\begin{align}
				\mathbf{k}_b - \mathbf{k}_j = \mathbf{k}_c - \mathbf{k}_k = \mathbf{k}_c - \mathbf{k}_k = \mathbf{k}_i - \mathbf{k}_a
			\end{align}
			Spin and isospin will be subject to the same reorganizing. We see that the direct channels do not represent the right conservation requirement and we must set up the cross channels, $X$, that consist of particle-hole or hole-particle two-body configurations. An algorithm can be set up as
			\begin{align*}
				&\mathbf{for } \text{ one-body state 1} \in \text{STATES}:\\
				&\:\: \mathbf{for } \text{ one-body state 2} \in \text{STATES}:\\
				&\:\:\:\: \mathbf{if} \text{ one-body state 1} \neq \text{ one-body state 2}:\\
				&\:\:\:\:\:\: N_x = n_{x,1} - n_{x,2} \\
				&\:\:\:\:\:\: N_y = n_{y,1} - n_{y,2} \\
				&\:\:\:\:\:\: N_z = n_{z,1} - n_{z,2} \\
 				&\:\:\:\:\:\: S_z = m_{s,1} - m_{s,2} \\
				&\:\:\:\:\:\: T_z = m_{t,1} - m_{t,2} \\
				&\:\:\:\:\:\: \text{Id} = \text{Index}(N_x,N_y,N_z,S_z,T_z) \\
				&\:\:\:\:\:\: X \leftarrow (\text{ one-body state 1}, \text{ one-body state 2}, \text{ Id}) \\
				&\:\:\:\:\:\: \text{Id}' = \text{Index}(-N_x,-N_y,-N_z,-S_z,-T_z) \\
				&\:\:\:\:\:\: X' \leftarrow (\text{ one-body state 2}, \text{ one-body state 1}, \text{ Id'})
			\end{align*}
			Where $X'$ is the cross channel compliment, $X(pq) = X'(qp)$. The cross-channels are used for calculating $Q_b$ and $L_c$. 

			Looking at the diagram $Q_c$
			\begin{align}
				Q_c = -\frac{1}{2} \hat P(ij) \sum_{klcd} \left<kl|\hat v|cd\right> t_{ik}^{ab} t_{jl}^{cd}
			\end{align}
			With the momentum conservation requirement
			\begin{align}
				\mathbf{k}_k + \mathbf{k}_l = \mathbf{k}_c \mathbf{k}_d = \mathbf{k}_i + \mathbf{k}_k = \mathbf{k}_a + \mathbf{k}_b = \mathbf{k}_j + \mathbf{k}_l = \mathbf{k}_c + \mathbf{k}_d
			\end{align}
			We see that we must realign the diagram as
			\begin{align}
				\tilde Q_c = -\frac{1}{2} \hat P(ij) \sum_{klcd} \left<abi\right|\tilde t\left|k\right> \left<k\right|\tilde v\left|cdl\right> \left<cdl\right|\tilde t\left|j\right>
			\end{align}
			Which sets the conservation requirement as 
			\begin{align}
				\mathbf{k}_a + \mathbf{k}_b	- \mathbf{k}_i = \mathbf{k}_k = \mathbf{k}_k = \mathbf{k}_c + \mathbf{k}_d - \mathbf{k}_l = \mathbf{k}_c + \mathbf{k}_d - \mathbf{k}_l = \mathbf{k}_j
			\end{align}
			We set up three-body and corresponding one-body channels to calculate $Q_c$ and $Q_d$. An example algorithm for the $K_h$ and $K_{p,p,h}$ channels can be outlined as
			\begin{align*}
				&\mathbf{for } \text{ one-body state 1 } \in \text{HOLES}:\\
				&\:\: N_x = n_{x,1}\\
				&\:\: N_y = n_{y,1}\\
				&\:\: N_z = n_{z,1}\\
 				&\:\: S_z = m_{s,1}\\
				&\:\: T_z = m_{t,1}\\
				&\:\: \text{Id} = \text{Index}(N_x,N_y,N_z,S_z,T_z) \\
				&\:\: K_h \leftarrow (\text{ one-body state 1}, \text{ Id}) \\ \\ \\ 
				&\mathbf{for } \text{ one-body state 1} \in \text{PARTICLES}: \\
				&\:\: \mathbf{for } \text{ one-body state 2} \in \text{PARTICLES}: \\
				&\:\:\:\: \mathbf{for } \text{ one-body state 3} \in \text{HOLES}: \\
				&\:\:\:\:\:\: \mathbf{if} \text{ one-body state 1} \neq \text{ one-body state 2}: \\
				&\:\:\:\:\:\:\:\: N_x = n_{x,1} + n_{x,2} - n_{x,3}\\
				&\:\:\:\:\:\:\:\: N_y = n_{y,1} + n_{y,2} - n_{y,3}\\
				&\:\:\:\:\:\:\:\: N_z = n_{z,1} + n_{z,2} - n_{z,3}\\
 				&\:\:\:\:\:\:\:\: S_z = m_{s,1} + m_{s,2} - n_{s,3}\\
				&\:\:\:\:\:\:\:\: T_z = m_{t,1} + m_{t,2} - n_{t,3}\\
				&\:\:\:\:\:\:\:\: \text{Id} = \text{Index}(N_x,N_y,N_z,S_z,T_z) \\
				&\:\:\:\:\:\:\:\: K_{p,p,h} \leftarrow (\text{ one-body state 1}, \text{ one-body state 2}, \text{ one-body state 3},  \text{ Id}) \\
			\end{align*}
		\end{subsection}

		\begin{subsection}{Permutations}
			Some diagrams come with permutations. These are easy to handle by simply interchanging indexes when adding the diagram to $t^{(n+1)}$. 
			\begin{align*}
				&\mathbf{for } \text{ i} \in \text{Holes}: \\
				&\:\:\mathbf{for } \text{ j} \in \text{Holes}: \\
				&\:\:\:\:\mathbf{for } \text{ a} \in \text{Particles}: \\
				&\:\:\:\:\:\:\mathbf{for } \text{ b} \in \text{Particles}: \\
				&\:\:\:\:\:\:\:\: t^{(n+1)}(a,b,i,j) = t^{(n+1)} - \frac{1}{2}\left(Q_c(a,b,i,j) - Q_c(a,b,j,i)\right)
			\end{align*}
		\end{subsection}

	\end{section}

	\begin{section}{Setting Up Basis}
		Before doing coupled-cluster calculations, the basis must be set up. An important property of this basis, is the occupied and virtual states. For infinite nuclear matter, the following algorithm can be used to set up the states. This algorithm should reproduce the magic numbers presented. 
		\begin{align*}
			&\mathbf{for } \text{ shell } \in \text{ All Shells}: \\
			&\:\:\:\mathbf{for } \: n_x, n_y, n_z \in [-\text{shell, shell} ]: \\
			&\:\:\:\:\:\:n = n_x^2 + n_y^2 + n_z^2 \\
			&\:\:\:\:\:\:\mathbf{if }\: n = \text{shell}: \\
			&\:\:\:\:\:\:\:\:\:\mathbf{for } \: m_s \in \{-1,1\} \\
			&\:\:\:\:\:\:\:\:\:\:\:\: \mathbf{for } \: m_t \in \{-1,1\} \\
			&\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\text{States} \leftarrow (e, n_x, n_y, n_z, m_s, m_t) \\
			&\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:N_s = N_s + 1 \\
			&\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\mathbf{if } \text{ shell} < \text{ Fermi level}: \\
			&\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\: N_h = N_h + 1
		\end{align*}
	\end{section}

	\begin{section}{Parallellization}
		To fully utilize the computational power in modern processors, one must use a parallellized code. Modern processors usually come with more than one core to save power output at the same effiency \cite{IntelOpenMP}. A standard written C++ program will be processed using only 1 \textit{thread}, meaning that a single core only will be used. The super computer, \textit{Smaug}, located at the Institute of Physics at the University of Oslo is built of processors with many but low performing cores given todays standards. If one can split the program into multiple threads, each executed at the same time in different cores, one can hope to reduce computational time substansially. 
		
		OpenMP is a library. 
	\end{section}

\end{chapter}



\begin{chapter}{Results}
	
	\begin{section}{The Pairing Model}
		The Pairing Model serves as a valuable benchmark for implemented solvers. As I have looked at a 4p4h configuration, a full configuration interaction solver can be implemented giving the exact solution. One can also calculate the exact solution for second order perturbation theory by hand \cite{Hjorth-Jensen2016}. 
		\begin{align}
			\Delta E_{MBPT2} = \frac{1}{4} \sum_{abij} \frac{\left<ij\middle|\middle|ab\right>\left<ab\middle|\middle|ij\right>}{\epsilon_{ij}^{ab}} = 
			\sum_{a<b,i<j} \frac{\left<ij\middle|\middle|ab\right>\left<ab\middle|\middle|ij\right>}{\epsilon_{ij}^{ab}}
		\end{align}
		Where 
		\begin{align}
			\epsilon_{ij}^{ab} = \epsilon_i + \epsilon_j - \epsilon_a - \epsilon_b
		\end{align}
		and
		\begin{align}
			\epsilon_p = h_{pp} + \sum_i \left<pi\middle|\middle|pi\right>
		\end{align}
		This results in
		\begin{align}
			\Delta E_{MBPT2} = \frac{\left<01\middle|\middle|45\right>^2}{\epsilon_{01}^{45} } + \frac{\left<01\middle|\middle|67\right>^2}{\epsilon_{01}^{67} }
							  +\frac{\left<23\middle|\middle|45\right>^2}{\epsilon_{23}^{45} } \ \frac{\left<23\middle|\middle|67\right>^2}{\epsilon_{23}^{67} }
		\end{align}
		\begin{align}
			\Delta E_{MBPT2} = -\frac{g^2}{4} \left( \frac{1}{4+g} + \frac{1}{6+g} + \frac{1}{2+g} + \frac{1}{4+g} \right)
		\end{align}
		Where g represents the interaction strength. The table below shows my results for various g's both using the exact mbpt2 calculations and my numerically computed results. All results can be accessed on github \cite{WholmenGithub}

		\begin{table}[H]
			\begin{center}
				\begin{tabular}[center]{l | c | c | r}
					g & $E_0$ & exact $ \Delta E_{MBPT2}$  & $\Delta E_{MBPT2}$ \\
					\hline
					-1 & 3 & -0.466667 & -0.466667 \\
					-0.5 & 2.5 & -0.0887446 & -0.0887446 \\
					0 & 2 & 0 & 0 \\
					0.5 & 1.5 & -0.0623932 & -0.0623932 \\
					1 & 1 & -0.219048 & -0.219048
				\end{tabular}
			\end{center}
			\caption{A table showing correlation energies for Pairing model with 4 particle-states and 4 hole-states.  }
			\label{Results1}
		\end{table}
		As one can see, the correlation energies computed perfectly matches which both tells us that the basis set is set up correctly and that the MBPT2 solver is set up correctly. The results presented also match the results found in \cite{Hjorth-Jensen2016}

		The second order perturbation theory is valuble for benchmarking my implementation of Coupled Cluster Doubles. By initializing the first set of amplitudes, $t$, as zero, I get
		\begin{align}
			t_{ij}^{ab(0)} = 0  
		\end{align}
		\begin{align}
			t_{ij}^{ab(1)} = \frac{1}{4} \sum_{ijab} \frac{\left<ab\middle|\middle|ij\right>}{\epsilon_{ij}^{ab}} 
 		\end{align}
 		Which is equal to second order pertubation theory. 
 		\begin{table}[H]
			\begin{center}
				\begin{tabular}[center]{l | c | r}
					g & $ \Delta E_{MBPT2}$  & $\Delta E_{CCD}^{(1)}$ \\
					\hline
					-1 & -0.466667 & -0.466667 \\
					-0.5 & -0.0887446 & -0.0887446 \\
					0 & 0 & 0 \\
					0.5 & -0.0623932 & -0.0623932 \\
					1 & -0.219048 & -0.219048
				\end{tabular}
			\end{center}
			\caption{A table comparing correlation energies for Pairing model with 4 particle-states and 4 hole-states. This table show that CCD solver used with only a single iteration produces results exactly equal to mbpt2. This was done with the naive implementation of CCD equations}
			\label{Results2}
		\end{table}

		\begin{subsection}{Comparison of CCD solvers}
			In this thesis I have created three different solvers for Coupled Cluster Doubles equations. 
			\begin{enumerate}
				\item A naive brute force implementation of the equations summing over all variables. 
				\item A naive brute force implementation of intermediate equations summing over all variables.
				\item Rewriting summations as matrix-matrix multiplications and exploiting various symmetry arguments one can set up a block implementation.
			\end{enumerate}		
			As shown in table (\ref{Results2}), the naive implementation reproduces the mbpt2 energies as expected. I have used both the naive and intermediate CCD solver to compute correlation energies for the Pairing model, and again, \cite{Hjorth-Jensen2016} provides us with a good benchmark for the CCD equations.

			\begin{table}[H]
				\begin{center}
					\begin{tabular}[center]{l | c | r}
						g & $ \Delta E_{CCD}$ Naive  & $\Delta E_{CCD}$ Intermediates \\
						\hline
						0 & x & x \\
						-0.5 & -0.0630564 & -0.0630562 \\
						0 & 0 & 0 \\
						0.5 & -0.0833621 & -0.0833623 \\
						1 & -0.369557 & -0.369557
					\end{tabular}
				\end{center}
				\caption{A table comparing correlation energies for Pairing model with 4 particle-states and 4 hole-states. This table compare results from Naive and Intermediate implementation of CCD equations. A relaxing factor of $w = 0.3$ has been used because of divergence around $g=-1$}
				\label{Results3}
			\end{table}
			As one can see, my solvers reproduce results presented in \cite{Hjorth-Jensen2016}. For values of $g$ close to $-1$, one will see a divergence for CCD equations. By introducing a relaxing factor of $w = 0.3$, this problem was solved. 
  
		\end{subsection}
		\begin{subsection}{Comparison of various solvers}
			The full configuration interaction provides us with the exact solution for the 4p4h Pairing model. It can therefore be useful to compare the performance of Perturbation theory to second, third and fourth order with coupled-cluster doubles and configuration interaction without the four-particle excitation. 
			\begin{figure}[H]
				\includegraphics[width=\linewidth]{../Pairing_Model/Results/Figures/Pairing4p4h_CompareDE_AllMethods.png}
				\caption{Comparing the correlation energy for a 4 particle, 4 hole Pairing model. This has been calculated for various interaction terms, $g \in [-1,1]$ and for the single particle energy factor $\xi = 1$. The figure show relative performance for various solvers.}
				\label{figure:CompareCorrelationPairing}
			\end{figure}

			\begin{figure}[H]
				\includegraphics[width=\linewidth]{../Pairing_Model/Results/Figures/Pairing4p4h_CompareE_AllMethods.png}
				\caption{Comparing the ground state energy for a 4 particle, 4 hole Pairing model, given by $E_{\text{ref}} + \Delta E$ This has been calculated for various interaction terms, $g \in [-1,1]$ and for the single particle energy factor $\xi = 1$. The figure show relative performance for various solvers.}
				\label{figure:CompareEnergyPairing}
			\end{figure}
			One can see from figures (\ref{figure:CompareCorrelationPairing},\ref{figure:CompareEnergyPairing}) that the performance is good across the board close to $g = 0$, where the interaction is weak or non-existent. Once the interaction grows stronger, one notice that perturbation theory starts deviating a lot from the exact solution given by Full Configuration Interaction. That is particularly obvious for a negative interaction term. The cupled-cluster doubles equations perform very well, barely distinguishable from FCI even at very strong interactions. The same can be said for Configuration Interaction without the 4p-4h excitation term.  
		\end{subsection}

	\end{section}

	\newpage

	\begin{section}{The Homogeneous Electron Gas}
		Results for the Homogeneous Electron gas has various 

		\begin{subsection}{The Reference Energy}
			A benchmark on the reference energy is useful to test the implementation of the states and the interaction. It does not require any coupled-cluster solver, because it is not dependent on the amplitudes. It serves as a good first hand benchmark for the system, and Audun Skau Hansen and Gustav Baardsen \cite{Baardsen,Audun} present results that have been reproduced 
			\begin{table}[H]
				\begin{center}
					\begin{tabular}[center]{l | c  c  c  r}
						$r_s$ & $E_{\text{ref}} / N_p$ & $E_{\text{ref}} / N_p$ \cite{Baardsen} & $E_{\text{ref}} / N_p$ \cite{Audun} \\
						\hline
						1.0 & 0.971682666829 & 0.971682666826 & 0.9717 \\
						0.5 & 4.185191069164 &  &  \\
						2.0 & 0.205613116474 &  &  
					\end{tabular}
				\end{center}
				\caption{Reference energy, computed for three different $r_s$ for the homogenous electron gas with $14$ particles, compared with results from \cite{Baardsen,Audun}. My results are from \cite{WholmenGithub}}
				\label{table:ReferenceEnergyHEG}
			\end{table}

		\end{subsection}

		\begin{subsection}{Comparison of solvers}
			As shown, both the naive and intermediate solver reproduces satisfying results for the Pairing model, and can be further used for benchmarking of the implementation of the more advanced solver. 
			\begin{table}[H]
				\begin{center}
					\begin{tabular}[center]{l | c  c  c  r}
						$N_{\text{particles}}$ & $N_{\text{states}}$ & $ \Delta E_{CCD}$ naive  & $\Delta E_{CCD}$ interm. & $\Delta E_{CCD}$ block \\
						\hline
						2 & 14 & -0.0148295981858 & -0.0148295981858 & -0.0148295981858 \\
						14 & 38 & x & -0.276499387418 & -0.276499387418 \\
						14 & 52 & x & x & x 
					\end{tabular}
				\end{center}
				\caption{Calculations on the Homogeneous electron gas, using three different implementations of CCD equations. Showing results to benchmark the block solver, which was not benchmarked on the Pairing model. The System has been calculated with $2$ or $14$ particles and the total states either $38$ or $54$. The calculations has been made with a relaxing factor of $0.3$ and $r_s = 1.0$. Results can be found in file \textit{CompareTimeNaiveBlock.txt} \cite{WholmenGithub}}
				\label{table:CompareSolversHEG}
			\end{table}
			As we can see, the three solvers produce the exact same results, serving as a succesful benchmark for the block solver. These are relatively small calculations, at least compared to the thermodynamic limit. To fully grasp the point of using the block solver for larger computations, I have compared the time spent on performing the calculations for all three solvers
			\begin{table}[H]
				\begin{center}
					\begin{tabular}[center]{l | c  c  c  r}
						$N_{\text{particles}}$ & $N_{\text{states}}$ & $ \Delta E_{CCD}$ naive  & $\Delta E_{CCD}$ intermediates & $\Delta E_{CCD}$ block \\
						\hline
						2 & 14 & 17.54 s & 1.28 s & 0.01 s \\
						14 & 38 & 7.5 \text{days} & 28.4 \text{mins} & 0.49 s \\
						14 & 52 & \text{N/A} & 2.9 \text{hours} & 0.73 s  
					\end{tabular}
				\end{center}
				\caption{Calculations on the Homogeneous electron gas, using three different implementations of CCD equations. Showing time needed for every solver to calculate results in figure (\ref{table:CompareSolversHEG}. The System has been calculated with $2$ or $14$ particles and the total states either $38$ or $54$. The calculations has been made with a relaxing factor of $0.3$ and $r_s = 1.0$. Results found in file \textit{CompareTimeNaiveBlock.txt} \cite{WholmenGithub}}
				\label{table:CompareSolversTimeHEG}
			\end{table}
			One see the enormous leap of computational time, where the intermediate solver needs almost 10 000 times the computational time and the naive solver even more for the small system with $38$ states. 
		\end{subsection}
 		
		For a more thurough benchmark of the block solver, I have compared results for different states, $r_s$ and weights, to compare with results from Audun Skau Hansen's results \cite{Audun}. I present only the results achieved by the use of a weight factor $\alpha = 0.3$. The results are equal for other weights, and the number of iterations needed are around $1/3$ for $\alpha = 1.0$, but for $r_s = 2.0$, the results are unstable without using the relaxing factor. The results are found in various files on github \cite{WholmenGithub}.
		\begin{table}[H]
			\begin{center}
				\begin{tabular}[center]{l  c  c  c r}
					$r_s$ & $N_{\text{s}}$ & $\Delta E_{CCD}$ block & $\Delta E_{CCD}$ interm. & $\Delta E_{CCD}$ \cite{Audun} \\
					\hline
					1.0 &  54 & -0.3178228436888622 & -0.3178228436888617 & -0.317822843688933 \\
						&  66 & -0.3931116842237731 & -0.392696589806104 & -0.3926965898061966 \\
						& 114 & -0.4483703396794002 & & -0.4479105961757175 \\
						& 162 & -0.4805985770458347 & & -0.4805572589306416 \\
						& 186 & -0.4857493112620241 & & -0.4855229317521318 \\
						& 246 & -0.4931044808539733 & & -0.4929245740023975 \\
						& 294 & -0.4988882478066777 & & -0.4984909094066818 \\
						& 342 & -0.5023838015693459 & & -0.5019526761547779 \\
						& 358 & -0.5029455986670885 & & -0.502519673607641\\
					\hline
					0.5 &  54 & -0.3589655739945123 & -0.3589655739945096 &   \\
						&  66 & -0.4500927397323694 & -0.4498148680442103 & \\
						& 114 & -0.5123238220612253 &  & -0.5120153541478306 \\
						& 162 & -0.5476173361611851 &  & \\
						& 186 & -0.5534833405611211 &  & \\
						& 246 & -0.5623283277338971 &  & \\
						& 294 & -0.5690151565315092 &  & \\
						& 342 & -0.5732601634435416 &  & -0.572964549890367 \\
						& 358 & -0.5739729304859902 &  & \\
					\hline
					2.0 &  54 & -0.2589156130046961 & -0.2589156130046975 &   \\
						&  66 & -0.3139262042590158 & -0.3134082887534144 & \\
						& 114 & -0.3583621351017488 &  &  -0.3577968843144996 \\
						& 162 & -0.3856712818606722 &  & \\
						& 186 & -0.3897132502824209 &  & \\
						& 246 & -0.3949909174034745 &  & \\
						& 294 & -0.3994500843659767 &  & \\
						& 342 & -0.4019210052569197 &  &  -0.4014136184665555 \\
						& 358 & -0.4022835667040489 &  & \\
				\end{tabular}
			\end{center}
			\caption{ }
			\label{table:CompareAudun}
		\end{table}

		\begin{subsection}{The Thermodynamic limit}
			Because of the truncation of possible single-particle states made to the wave function ansatz, coupled-cluster theory do not produce the exact wave function. We can however, see how the ground state changes when we add more states. One will notice that the energy will converge towards a limit, named the thermodynamical limit. This will be the best possible approximation possible result for coupled-cluster doubles. 

			\begin{figure}[H]
				\includegraphics[width=\textwidth]{../ElectronGas/Results/Figures/Thermodynamic_limit.png}
				\caption{Thermodynamic limit}
				\label{figure:thermodynamic_limit}
			\end{figure}
		\end{subsection}

	\end{section}

\end{chapter}



\begin{chapter}{Conclusion and future prospects}
	Looking back at the goals defined in the introduction I have succeded in 

	Laying out the ground work for devoloping many-body methods. I have presented and explained the implementation of full configuration interaction, Hartree-Fock method, Reileigh-Schr\"{o}dinger perturbation theory and coupled-cluster theory. I have also presented the three quantum mechanical systems that were investigated in the thesis. I have tried to write a complete and well-explained theory part, that hopefully can be useful for a future generation of students that are new to many-body quantum mechanics.  
 
	I moved on to implementing all four methods from scratch in a brute-force manner. The methods were applied to the small and uncomplicated pairing model. For this system, the coupled-cluster doubles iteration proved to calculate results closest to the true value, found by full configuration interaction. As expected, perturbation theory had problems for a strong interaction. When developing perturbation theory, one assumes the ratio $\frac{\Delta E}{E_{\text{ref}}}$ to be small, which demands a weak interaction. The code is available for further development and testing for everyone at github. 

	I further developed code for the infinite electron gas, which was tested and benchmarked to previous literature. Applying the same coupled-cluster doubles code on this system, I soon found out that even for small systems, a brute force implementation is way too demanding because of loops in eight dimensions. The first attempt at optimizing the coupled-cluster doubles code included only a factorization of the terms, known as \textit{intermediates}. This significantly reduced the computational cost. The code was tested on the pairing model to ensure correct implementation. The code also reproduced results from the literature. The code for intermediates and electron gas is also available for everyone to use at github. 

	As I wanted to compute results towards the thermodynamic limit, only using intermediates proved to be way to costly. The main bulk of my time has been spent on implementing a new solver that rewrites the coupled-cluster equations as matrix-matrix multiplications. Because of the packages LAPAK/BLAS, matrix-matrix multiplication offers a significant speed improvement. The matrices consume a lot of memory, so utilizing symmetries present in infinite matter, one can rewrite the multiplication as a set of small multiplications. This proved to be almost succesful, almost reproducing expected results. This code was used to solve large systems of both infinite electron and infinite nuclear matter, giving results close to the thermodynamic limit. Further optimalization was done by the parallelization of loops. As all the code used in my thesis, this code is available to the reader on github for testing and further development. 

	Further improvements on the solver can be achieved by adding singles, triples and quadruples to the equations for more precise calculations. Further optimalizations can possibly be done to memory handling. My work can be used as a foundation for further implementations or it can be used for educational purposes for future students. For this reason, I have tried to write a clean and well documented code that can be understood by an educated reader. It can be interesting to calculate results for infinite nuclear matter with a more complex interaction term than the Minnesota potential.
\end{chapter}


\medskip


\begin{thebibliography}{9}

	\bibitem{Baardsen}
	Gustav Baardsen
	\textit{Coupled-cluster theory for infinite matter} 2014

	\bibitem{Audun}
	Audun Skau Hansen
	\textit{Coupled Cluster studies of infinite systems,} Master thesis, University of Oslo, 2015

	\bibitem{ShavittAndBartlett}
	Isaiah Shavitt and Rodney J. Bartlett
	\textit{Many-Body Methods in Chemistry and Physics} 2009

	\bibitem{Szabo}
	Attila Szabo and Neil S. Ostlund
	\textit{Modern Quantum Chemistry. Introduction to Advanced Electronic Structure Theory} 1982

	\bibitem{Griffiths}
	David J. Griffiths
	\textit{Introduction to Quantum Mechanics} Second edition 2005.

	\bibitem{Sakurai}
	J.J. Sakurai
	\textit{Modern Quantum Mechanics} Revised Edition 1993.

	\bibitem{Hjorth-Jensen2016}
	Morten Hjorth-Jensen, Maria Paola Lombardo and Ubiraja van Kolck
	\textit{An Advanced Course in Computational Nuclear Physics} 2016.

	\bibitem{Raimes}
	Stanley Raimes
	\textit{Many-Electron Theory} 1972.

	\bibitem{Susskind2014}
	Leonard Susskind and Art Friedman
	\textit{Quantum Mechanics, The Theoretical Minimum} 2014.

	\bibitem{Goldstone}
	J. Goldstone
	\textit{Derivation of the Brueckner Many-Body Theory, Proc. R. Soc. (London)} 1957. 

	\bibitem{Crawford}
	T. Daniel Crawford and Henry F. Schaefer III
	\textit{An Introduction to Coupled Cluster Theory for Computational Chemists} 

	\bibitem{Kummel}
	Hermann G. Kummel. A biography of the coupled cluster method. 
	\textit{International Journal of Modern Physics B,} 17(28), 2003. 

	\bibitem{Day1967} 
	B. D. Day
	\textit{Rev. Mod. Phys.,}
	39:719, 1967.

	\bibitem{Thompson1977}
	D. R. Thompson, M. Lemere and Y.C. Tang.
	\textit{Nucl. Phys. A,} 286:53 1977.

	\bibitem{Shepherd2012}
	J. J. Shepherd, A. Grüneis, G.H. Booth, G. Kresse and A. Alavi 
	\textit{Phys. Rev. B,} 86:035111, 2012.

	\bibitem{Shepherd2013}
	J.J. Shepherd and A. Grüneis
	\textit{Phys. Rev. Lett.,} 110:226401, 2013.

	\bibitem{Drummond2008}
	N. D. Drummond, R. J. Needs, A. Sorouri and W. M. C. Foulkes
	\textit{Phys. Rev. B,} 78:125106

	\bibitem{Fraser et al}
	L. M. Fraser, W. M. C. Foulkes, G. Rajagopal, R. J. Needs, S.D. Kenny and A. J. Williamson
	\textit{Phys. Rev. B,} 53:1814, 1996

	\bibitem{Ewald}
	P.P. Ewald. Die berechnung optischer und elektrostatischer gitterpotentiale. 
	\textit{Annalen der Physik,} 369(3), 1921. ISSN 1521-3889. doi: 10.1002/andp.19213690304

	\bibitem{Langtangen}
	Hans Petter Langtangen
	\textit{A Primer on Scientific Programming with Python} Scond Edition, Springer 2011

	\bibitem{NumericalRecipes}
	William H. Press, Saul A. Teukolsky, William T. Vetterling, Brian P. Flannery
	\textit{Numerical Recipes, The Art of Scientific Computing} Third Edition, Cambridge 2007

	\bibitem{MHJFCI}
	Morten Hjorth-Jensen
	\textit{Nuclear Shell Model, Nuclear Talent course 2} 
	URL (14. july, 2016): http://nucleartalent.github.io/Course2ManyBodyMethods/doc/pub/fci/pdf/fci-print.pdf

	\bibitem{MHJonline}
	Carlo Barbieri, Wim Dickhoff, Gaute Hagen, Morten Hjorth-Jensen, Artur Polls
	\textit{Many-body Methods for Nuclear Physics, Nuclear Talent course 2} 
	URL: \textit{http://nucleartalent.github.io/Course2ManyBodyMethods/doc/web/course.html}

	\bibitem{MHJSlides}
	Morten Hjorth-Jensen
	\textit{Slides from the course FYS-KJM4480 2013/2014}
	URL: \textit{http://www.uio.no/studier/emner/matnat/fys/FYS-KJM4480/h13/undervisningsmateriale/Slides\%20from\%20lectures/fys4480.pdf}

	\bibitem{IntelOpenMP}
	Tim Mattson
	\textit{Intel Youtube Course in OpenMp: Introduction to OpenMP - Tim Mattson (Intel)}
	URL: \textit{https://www.youtube.com/playlist?list=PLLX-Q6B8xqZ8n8bwjGdzBJ25X2utwnoEG}.

	\bibitem{Smaug}
	\textit{Computational physics homepage on use of computational cluster, Smaug.}
	URL: \textit{http://comp-phys.net/cluster-info/using-smaug/}

	\bibitem{WholmenGithub}
	Fredrik Wilhelm Holmen
	\textit{https://github.com/wholmen/Master} 

	\bibitem{Armadillo}
	Conrad Sanderson. Armadillo: An open source c++ linear algebra library for fast prototyping and computationally intensive experiments, 2010.
	URL: \textit{http://arma.sourceforge.net/docs.html}.

\end{thebibliography}


\end{document}